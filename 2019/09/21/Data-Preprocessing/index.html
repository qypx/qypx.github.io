<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="机器学习,MachineLearningA-Z,">










<meta name="description" content="以下内容来自Udemy上的课程: Machine Learing A-Z: Hands-On Python &amp;amp; R in Data Science. datasets download 使用数据：  1. Missing dataCommon strategy: replace the missing data by the mean, median, or most frequent v">
<meta name="keywords" content="机器学习,MachineLearningA-Z">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Preprocessing（数据预处理）">
<meta property="og:url" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/index.html">
<meta property="og:site_name" content="qypx の blog">
<meta property="og:description" content="以下内容来自Udemy上的课程: Machine Learing A-Z: Hands-On Python &amp;amp; R in Data Science. datasets download 使用数据：  1. Missing dataCommon strategy: replace the missing data by the mean, median, or most frequent v">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/data.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1607053623367.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1607053581148.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/pic1.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605681111923.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/pic2.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result2.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605681883031.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/dummy-encoding.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result1.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result3.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result4.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/feature-scaling.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/show1.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605753529878.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605753552476.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605683366191.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605683445278.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605752923883.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result5.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result6.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result7.JPG">
<meta property="og:updated_time" content="2021-05-22T09:54:02.542Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Data Preprocessing（数据预处理）">
<meta name="twitter:description" content="以下内容来自Udemy上的课程: Machine Learing A-Z: Hands-On Python &amp;amp; R in Data Science. datasets download 使用数据：  1. Missing dataCommon strategy: replace the missing data by the mean, median, or most frequent v">
<meta name="twitter:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/data.JPG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://qypx.github.io/2019/09/21/Data-Preprocessing/">





<!-- 网页加载条 -->
<script src="https://neveryu.github.io/js/src/pace.min.js"></script>

  <title>Data Preprocessing（数据预处理） | qypx の blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">qypx の blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">机会是留给有准备的人的.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://qypx.github.io/2019/09/21/Data-Preprocessing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qypx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qypx の blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Data Preprocessing（数据预处理）</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-21T13:56:34+08:00">
                2019-09-21
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2021-05-22T17:54:02+08:00">
                2021-05-22
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读量
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>以下内容来自Udemy上的课程: <a href="https://www.udemy.com/machinelearning/" target="_blank" rel="noopener"><strong>Machine Learing A-Z: Hands-On Python &amp; R in Data Science</strong></a>.</p>
<p><a href="https://www.superdatascience.com/pages/machine-learning" target="_blank" rel="noopener">datasets download</a></p>
<p>使用数据：</p>
<p><img src="/2019/09/21/Data-Preprocessing/data.JPG" alt="data"></p>
<h3 id="1-Missing-data"><a href="#1-Missing-data" class="headerlink" title="1. Missing data"></a>1. Missing data</h3><p>Common strategy: replace the missing data by the mean, median, or most frequent value of the feature column.</p>
<h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><p>以均值代替：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line"><span class="comment"># 法一：SimpleImputer(新版sklearn，以前为 from sklearn.preprocessing import Imputer)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line">imputer = SimpleImputer(missing_values=np.nan, strategy = <span class="string">"mean"</span>)</span><br><span class="line">imputer.fit(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">X.iloc[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 法二，replace</span></span><br><span class="line"><span class="comment">#以Age为例</span></span><br><span class="line">X[<span class="string">"Age"</span>].replace(np.nan, X[<span class="string">"Age"</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 法三，fillna</span></span><br><span class="line"><span class="comment"># 以Age为例</span></span><br><span class="line">X[<span class="string">"Age"</span>] = X[<span class="string">"Age"</span>].fillna(X[<span class="string">"Age"</span>].mean())</span><br><span class="line"><span class="comment"># 也可 X["Age"].fillna(X["Age"].mean(), inplace=True)</span></span><br></pre></td></tr></table></figure>
<p>例：现有 df_age 如下：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1607053623367.png" alt="1607053623367"></p>
<p>Fill the missing data in column <strong>“age_boy”</strong> with 22 and fill the missing data in column <strong>“age_girl”</strong> with 21. The expected output is:</p>
<p><img src="/2019/09/21/Data-Preprocessing/1607053581148.png" alt="1607053581148"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_age = df_age.fillna(value=&#123;<span class="string">'age_boy'</span>:<span class="number">22</span>,<span class="string">'age_girl'</span>:<span class="number">21</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>删掉有缺失值的行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X.dropna(axis = <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 或写成 X = X.dropna(axis = 0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可指定当哪一变量出现缺失值时，执行删除的操作</span></span><br><span class="line">X.dropna(subset=[<span class="string">"Age"</span>], axis = <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>删掉有缺失值的列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.dropna(axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = read.csv(<span class="string">'Data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line">dataset$Age = ifelse(is.na(dataset$Age),</span><br><span class="line">                     ave(dataset$Age, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                     dataset$Age)</span><br><span class="line">dataset$Salary = ifelse(is.na(dataset$Salary),</span><br><span class="line">                        ave(dataset$Salary, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                        dataset$Salary)</span><br><span class="line">                        </span><br><span class="line"><span class="comment"># 法二</span></span><br><span class="line">dataset$Age = ifelse(is.na(dataset$Age),</span><br><span class="line">                     mean(dataset$Age, na.rm = <span class="literal">TRUE</span>),</span><br><span class="line">                     dataset$Age)</span><br><span class="line"></span><br><span class="line">dataset$Salary = ifelse(is.na(dataset$Salary),</span><br><span class="line">                        mean(dataset$Salary, na.rm = <span class="literal">TRUE</span>),</span><br><span class="line">                        dataset$Salary)</span><br></pre></td></tr></table></figure>
<h3 id="2-Categorical-data"><a href="#2-Categorical-data" class="headerlink" title="2. Categorical data"></a>2. Categorical data</h3><h4 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br></pre></td></tr></table></figure>
<p>原来的X：</p>
<p><img src="/2019/09/21/Data-Preprocessing/pic1.JPG" alt="pic1"></p>
<h5 id="2-1-LabelEncoder"><a href="#2-1-LabelEncoder" class="headerlink" title="2.1 LabelEncoder"></a>2.1 LabelEncoder</h5><blockquote>
<p>LabelEncoder官方文档<br><a href="https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html" target="_blank" rel="noopener">https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html</a></p>
</blockquote>
<p><img src="/2019/09/21/Data-Preprocessing/1605681111923.png" alt="1605681111923"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>经过LabelEncoder编码后的X：</p>
<p><img src="/2019/09/21/Data-Preprocessing/pic2.JPG" alt="pic2"></p>
<p>But the model will think that France has lower value than Spain -&gt; that’s not the case, we have no order here. 解决办法：使用后面介绍的OneHotEncoder方法。如果是S, M, L of a T-shirt（本身有顺序）, 不必使用OneHotEncoder方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Encoding the Dependent Variable</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">For the dependent variable, we are only going to use LabelEncoder, </span></span><br><span class="line"><span class="string">because since this is the dpendent variable, the machine learning model will know</span></span><br><span class="line"><span class="string">that it's a category, and that there is no oder between the two</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">labelencoder_y = LabelEncoder()</span><br><span class="line">y = labelencoder_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result2.JPG" alt="result2"></p>
<h5 id="2-2-factorize"><a href="#2-2-factorize" class="headerlink" title="2.2 factorize"></a>2.2 factorize</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">df = DataFrame([<span class="string">'A'</span>, <span class="string">'B'</span>, <span class="string">'B'</span>, <span class="string">'C'</span>], columns=[<span class="string">'Col'</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># factorize</span></span><br><span class="line">df[<span class="string">'Fact'</span>] = pd.factorize(df[<span class="string">'Col'</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># LabelEncoder</span></span><br><span class="line">le = preprocessing.LabelEncoder()</span><br><span class="line">df[<span class="string">'Lab'</span>] = le.fit_transform(df[<span class="string">'Col'</span>])</span><br><span class="line"></span><br><span class="line">print(df)</span><br><span class="line"><span class="comment">#   Col  Fact  Lab</span></span><br><span class="line"><span class="comment"># 0   A     0    0</span></span><br><span class="line"><span class="comment"># 1   B     1    1</span></span><br><span class="line"><span class="comment"># 2   B     1    1</span></span><br><span class="line"><span class="comment"># 3   C     2    2</span></span><br></pre></td></tr></table></figure>
<p>👆可以看到factorize与LabelEncoder结果是一样的</p>
<h5 id="2-3-OneHotEncoder"><a href="#2-3-OneHotEncoder" class="headerlink" title="2.3 OneHotEncoder"></a>2.3 OneHotEncoder</h5><blockquote>
<p>OneHotEncoder官方文档<br><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html" target="_blank" rel="noopener">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html</a></p>
</blockquote>
<p><img src="/2019/09/21/Data-Preprocessing/1605681883031.png" alt="1605681883031"></p>
<p><img src="/2019/09/21/Data-Preprocessing/dummy-encoding.JPG" alt="dummy encoding"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])  <span class="comment"># which column you want to encode</span></span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result1.JPG" alt="result1"></p>
<p>另一种写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">encoder = OneHotEncoder()</span><br><span class="line">onehotencoder = encoder.fit_transform(X.iloc[:,<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<h5 id="2-4-get-dummies"><a href="#2-4-get-dummies" class="headerlink" title="2.4 get_dummies()"></a>2.4 get_dummies()</h5><p>onehot encoding的另一种实现方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">new_col = pd.get_dummies(X[<span class="string">'Age'</span>])</span><br><span class="line"></span><br><span class="line">X_new = pd.concat([X,newcol], axis=<span class="number">1</span>)</span><br><span class="line">X_new.drop(<span class="string">'Age'</span>, axis = <span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<h5 id="2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies的区别"><a href="#2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies的区别" class="headerlink" title="2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别"></a>2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别</h5><blockquote>
<p>参考 <a href="https://medium.com/@vaibhavshukla182/want-to-know-the-diff-among-pd-factorize-a8591eb3347d" target="_blank" rel="noopener">https://medium.com/@vaibhavshukla182/want-to-know-the-diff-among-pd-factorize-a8591eb3347d</a></p>
</blockquote>
<p>这四种编码方式可以分为两类：</p>
<ul>
<li>Encode <strong>labels into categorical variables</strong>: Pandas <code>factorize</code> and scikit-learn <code>LabelEncoder</code>. The result will have <strong>1 dimension</strong>(It is important as it could be used while implementing any model). <span style="color:red">factorize与LabelEncoder都是将字符型变量(categorical varirables)编码为数值型1，2，3…（本来是一维，编码后依然是一维）</span></li>
<li>Encode <strong>categorical variable into dummy/indicator (binary) variables</strong>: Pandas <code>get_dummies</code> and scikit-learn <code>OneHotEncoder</code>. The result will have <strong>n dimensions</strong>, one by distinct value of the encoded categorical variable. <span style="color:red">get_dummies与OneHotEnocder都是将字符型变量编码为0，1哑变量（本来是一维，编码后变为多维）</span></li>
</ul>
<p>The main difference between pandas and scikit-learn encoders is that scikit-learn encoders are made to be used in <strong>scikit-learn pipelines</strong> with <code>fit</code> and <code>transform</code> methods. <span style="color:red">sklearn中的LabelEnocder，OneHotEncoder与pandas中的factorize, get_dummies的区别在于sklearn的两个方法可以使用fit和transform（在测试集上的编码应依赖于训练集）</span></p>
<h5 id="2-5-完整代码"><a href="#2-5-完整代码" class="headerlink" title="2.5 完整代码"></a>2.5 完整代码</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding categorical data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding the Independent Variable</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])  <span class="comment"># which column you want to encode</span></span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding the Dependent Variable</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">For the dependent variable, we are only going to use LabelEncoder, </span></span><br><span class="line"><span class="string">because since this is the dpendent variable, the machine learning model will know</span></span><br><span class="line"><span class="string">that it's a category, and that there is no oder between the two</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">labelencoder_y = LabelEncoder()</span><br><span class="line">y = labelencoder_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<h4 id="R-1"><a href="#R-1" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Encoding categorical data</span></span><br><span class="line">dataset$Country = factor(dataset$Country,</span><br><span class="line">                         levels = c(<span class="string">'France'</span>, <span class="string">'Spain'</span>, <span class="string">'Germany'</span>),</span><br><span class="line">                         labels = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">dataset$Purchased = factor(dataset$Purchased,</span><br><span class="line">                           levels = c(<span class="string">'No'</span>, <span class="string">'Yes'</span>),</span><br><span class="line">                           labels = c(<span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result3.JPG" alt="result3"></p>
<p><img src="/2019/09/21/Data-Preprocessing/result4.JPG" alt="result4"></p>
<h3 id="3-train-test-split"><a href="#3-train-test-split" class="headerlink" title="3. train_test_split"></a>3. train_test_split</h3><h4 id="Python-2"><a href="#Python-2" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values <span class="comment"># :-1 -&gt; take all the column except the last one</span></span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="R-2"><a href="#R-2" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = read.csv(<span class="string">'Data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages('caTools')</span></span><br><span class="line"><span class="keyword">library</span>(caTools)</span><br><span class="line">set.seed(<span class="number">123</span>)</span><br><span class="line">split = sample.split(dataset$Purchased, SplitRatio = <span class="number">0.8</span>) <span class="comment"># 这里取因变量</span></span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set = subset(dataset, split == <span class="literal">TRUE</span>)</span><br><span class="line">test_set = subset(dataset, split == <span class="literal">FALSE</span>)</span><br></pre></td></tr></table></figure>
<h3 id="4-Feature-Scaling"><a href="#4-Feature-Scaling" class="headerlink" title="4. Feature Scaling"></a>4. Feature Scaling</h3><p>Lots of machine learning models are based on Euclidean distance. Since the salary has a much wider range of values, the euclidean distance will be dominated by the salary. </p>
<p>Even if the machine learning models are not based on euclidean distance, we will still need to do feature scaling, because the algorithms will converge much faster, that will be the case for decision trees. （？决策树不需要归一化/标准化？）</p>
<p><strong><em>Feature Scaling:</em></strong> Putting our variables in the same range (in the same scale),  so that no variable is dominated by the other.</p>
<p><img src="/2019/09/21/Data-Preprocessing/feature-scaling.JPG" alt="feature scaling"></p>
<p><strong><em>Question 1: Do we need to fit and transform dummy variables?</em></strong></p>
<p><img src="/2019/09/21/Data-Preprocessing/show1.JPG" alt="show1"></p>
<p>It depends on the context. Depends on how much you want to keep interpretation in your models. Because if we scale dummy variables, it will be good because everything will be on the same scale, it will be good for our predicitons, but we will lose interpretation of knowing which observation belongs to which country.</p>
<p><strong><em>Qustion 2: Do we need to apply feature scaling to y?</em></strong></p>
<p>we don’t need to do it if it is a classification problem  with categorical dependent variable. But for regression, where the dependent variable will take a huge range of values, we will need to apply feature scaling to y as well.</p>
<blockquote>
<p>以下内容参考 <a href="https://www.jianshu.com/p/ba2a64a81c81" target="_blank" rel="noopener">https://www.jianshu.com/p/ba2a64a81c81</a></p>
</blockquote>
<h4 id="4-1-Normalization归一化-Min-Max"><a href="#4-1-Normalization归一化-Min-Max" class="headerlink" title="4.1 Normalization归一化 Min-Max"></a>4.1 Normalization归一化 Min-Max</h4><script type="math/tex; mode=display">
x_{new} = \frac{x_{old}-x_{min}}{x_{max}-x_{min}}</script><p>$x_{new}$取值范围：[0,1]</p>
<p>其他归一化方法：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605753529878.png" alt="1605753529878"></p>
<p><img src="/2019/09/21/Data-Preprocessing/1605753552476.png" alt="1605753552476"></p>
<h4 id="4-2-Standardization标准化-Z-score"><a href="#4-2-Standardization标准化-Z-score" class="headerlink" title="4.2 Standardization标准化 Z-score"></a>4.2 Standardization标准化 Z-score</h4><script type="math/tex; mode=display">
x_{new} = \frac{X_{old}-\mu}{\sigma}</script><p>The resulting values hover around 0, and typically range between -3 and +3, but can be higher or lower.</p>
<h4 id="4-3-归一化和标准化的区别"><a href="#4-3-归一化和标准化的区别" class="headerlink" title="4.3 归一化和标准化的区别"></a>4.3 归一化和标准化的区别</h4><p><strong>（1）转换区间</strong><br>归一化（Normalization）：把数据转换到(0,1)或者(-1,1)区间的数据映射方式<br>标准化（Standardization）：把数据转换到均值为0，标准差为1的数据映射方式</p>
<p><strong>（2）数据分布</strong><br>归一化：对数据的数值范围进行特定缩放，但不改变其数据分布</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605683366191.png" alt="1605683366191"></p>
<p>标准化：对数据的分布进行转换，使其符合某种分布（如正态分布）</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605683445278.png" alt="1605683445278"></p>
<h4 id="4-4-为什么要归一化-标准化"><a href="#4-4-为什么要归一化-标准化" class="headerlink" title="4.4 为什么要归一化/标准化"></a>4.4 为什么要归一化/标准化</h4><p><strong>（1）梯度下降的需要，加速算法收敛速度</strong><br>在使用梯度下降的方法求解最优化问题时，归一化/标准化后可以加快梯度下降的求解速度，即提升模型的收敛速度。</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605752923883.png" alt="1605752923883"></p>
<p>线性回归、逻辑回归、神经网络等使用梯度下降法求解最优参数的算法，输入数据需要做归一化/标准化处理，提升模型收敛速度。</p>
<p><strong>（2）距离计算的需要，保障算法准确度</strong><br>一些算法需要计算样本之间的距离（如欧式距离），例如KNN、kmeans等聚类算法。<strong>如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征</strong>，从而与实际情况相悖。</p>
<p><strong>（3）消除量纲和数量级影响</strong><br>各个指标之间由于计量单位和数量级不尽相同，从而使得各指标间不具有综合性，不能直接进行综合分析，这时就必须采用某种方法对各指标数值进行无量纲化处理，解决各指标数值不可综合性问题。</p>
<blockquote>
<p>去量纲指的是去除数据单位之间的不统一，将数据统一变换为无单位（统一单位）的数据集。</p>
</blockquote>
<h4 id="4-5-什么时候用标准化？什么时候用归一化？"><a href="#4-5-什么时候用标准化？什么时候用归一化？" class="headerlink" title="4.5  什么时候用标准化？什么时候用归一化？"></a>4.5  什么时候用标准化？什么时候用归一化？</h4><p>（1）一般建议优先使用标准化，在机器学习中，标准化是更常用的手段，归一化的应用场景是有限的。<br>（2）如果数据不稳定，存在极端的最大最小值，不要用归一化。<br>（3）在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，标准化(Z-score standardization)表现更好。<br>（4）在不涉及距离度量、协方差计算、数据不符合正态分布的时候，可以使用归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0, 255]的范围。</p>
<h4 id="4-6-不是所有模型都要求输入数据经过标准化-归一化处理"><a href="#4-6-不是所有模型都要求输入数据经过标准化-归一化处理" class="headerlink" title="4.6 不是所有模型都要求输入数据经过标准化/归一化处理"></a>4.6 不是所有模型都要求输入数据经过标准化/归一化处理</h4><p>不是所有的模型都需要做归一的，比如模型算法里面没有关于对距离的衡量，没有关于对变量间标准差的衡量。<br>（1）比如decision tree决策树，算法里面没有涉及到任何和距离等有关的，所以在做决策树模型时，通常是不需要将变量做标准化的<br>（2）概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率。</p>
<h4 id="4-7-Python"><a href="#4-7-Python" class="headerlink" title="4.7 Python"></a>4.7 Python</h4><p>以下代码中scale了dummy variable.</p>
<p>标准化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values <span class="comment"># :-1 -&gt; take all the column except the last one</span></span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="comment"># most of time we don't need to do feature scaling, beacuse feature scaling is a tool</span></span><br><span class="line"><span class="comment"># included most of time in the machine learning libraries</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train_scaled = sc_X.fit_transform(X_train)</span><br><span class="line">X_test_scaled = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>Feature scaling on X_test is the same as the feature scaling on the X_train(scaled on the same bases)</p>
<p><img src="/2019/09/21/Data-Preprocessing/result5.JPG" alt="result5"></p>
<p>The result is between -1 and 1.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sc_y = StandardScaler()</span><br><span class="line">y_train_scaled = sc_y.fit_transform(y_train.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>归一化MinMax：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="4-8-R"><a href="#4-8-R" class="headerlink" title="4.8 R"></a>4.8 R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages('caTools')</span></span><br><span class="line"><span class="keyword">library</span>(caTools)</span><br><span class="line">set.seed(<span class="number">123</span>)</span><br><span class="line">split = sample.split(dataset$Purchased, SplitRatio = <span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set = subset(dataset, split == <span class="literal">TRUE</span>)</span><br><span class="line">test_set = subset(dataset, split == <span class="literal">FALSE</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling 标准化</span></span><br><span class="line">training_set = scale(training_set)</span><br><span class="line">test_set = scale(test_set)</span><br></pre></td></tr></table></figure>
<p>语法：<code>scale(x, center = TRUE, scale = TRUE)</code></p>
<p>Arguments:<br><code>x</code>: a numeric matrix(like object).<br><code>center</code>: either a logical value or a numeric vector of length equal to the number of columns of <code>x</code>.<br><code>scale</code>: either a logical value or a numeric vector of length equal to the number of columns of <code>x</code>.</p>
<p>Details:<br>If <code>center</code> is <code>TRUE</code> then centering is done by subtracting the column means (omitting <code>NA</code>s) of <code>x</code> from their corresponding columns, and if <code>center</code> is <code>FALSE</code>, no centering is done.<br>If <code>scale</code> is <code>TRUE</code> then scaling is done by dividing the (centered) columns of <code>x</code> by their standard deviations if <code>center</code> is <code>TRUE</code>, and the root mean square otherwise. If <code>scale</code> is <code>FALSE</code>, no scaling is done.<br>The root-mean-square for a (possibly centered) column is defined as $\sqrt{sum(x^2)/(n-1)}$, where <em>x</em> is a vector of the non-missing values and <em>n</em> is the number of non-missing values. In the case <code>center = TRUE</code>, this is the same as the standard deviation, but in general it is not. (To scale by the standard deviations without centering, use <code>scale(x, center = FALSE, scale = apply(x, 2, sd, na.rm = TRUE))</code>.)</p>
<p>但直接这样运行会出错：</p>
<p><img src="/2019/09/21/Data-Preprocessing/result6.JPG" alt="result6"></p>
<p>原因：因子型变量不是 numeric的。</p>
<p><img src="/2019/09/21/Data-Preprocessing/result7.JPG" alt="result7"></p>
<p>解决方法：We’re going to exclude categories from the feature scaling, we’re not going to apply feature scaling on those columns.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set[,<span class="number">2</span>:<span class="number">3</span>] = scale(training_set[,<span class="number">2</span>:<span class="number">3</span>])</span><br><span class="line">test_set[,<span class="number">2</span>:<span class="number">3</span>] = scale(test_set[,<span class="number">2</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/MachineLearningA-Z/" rel="tag"># MachineLearningA-Z</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/17/Python-working-directory/" rel="next" title="Python working directory">
                <i class="fa fa-chevron-left"></i> Python working directory
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/12/15/Hadoop-Introduction/" rel="prev" title="Hadoop Introduction">
                Hadoop Introduction <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="qypx">
            
              <p class="site-author-name" itemprop="name">qypx</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">120</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">51</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/qypx" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          


          
          

          
          

          


          <!-- 新增的内容 -->
          <!-- require APlayer -->
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
          <script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
          <!-- require MetingJS -->
          <script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

          <meting-js server="netease" type="playlist" id="4870130923" list-folded="true" order="random">
          </meting-js>
          <!-- 新增的内容end -->

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Missing-data"><span class="nav-text">1. Missing data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python"><span class="nav-text">Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Categorical-data"><span class="nav-text">2. Categorical data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-1"><span class="nav-text">Python</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-LabelEncoder"><span class="nav-text">2.1 LabelEncoder</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-factorize"><span class="nav-text">2.2 factorize</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-OneHotEncoder"><span class="nav-text">2.3 OneHotEncoder</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-get-dummies"><span class="nav-text">2.4 get_dummies()</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies的区别"><span class="nav-text">2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-5-完整代码"><span class="nav-text">2.5 完整代码</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R-1"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-train-test-split"><span class="nav-text">3. train_test_split</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-2"><span class="nav-text">Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R-2"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Feature-Scaling"><span class="nav-text">4. Feature Scaling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Normalization归一化-Min-Max"><span class="nav-text">4.1 Normalization归一化 Min-Max</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-Standardization标准化-Z-score"><span class="nav-text">4.2 Standardization标准化 Z-score</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-归一化和标准化的区别"><span class="nav-text">4.3 归一化和标准化的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-为什么要归一化-标准化"><span class="nav-text">4.4 为什么要归一化/标准化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-什么时候用标准化？什么时候用归一化？"><span class="nav-text">4.5  什么时候用标准化？什么时候用归一化？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-不是所有模型都要求输入数据经过标准化-归一化处理"><span class="nav-text">4.6 不是所有模型都要求输入数据经过标准化/归一化处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-7-Python"><span class="nav-text">4.7 Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-8-R"><span class="nav-text">4.8 R</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qypx</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left"},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
