<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/qypx_robot/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/qypx_robot/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/qypx_robot/favicon-16x16.png">
  <link rel="mask-icon" href="/images/qypx_robot/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"qypx.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"right","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"default"},"fold":{"enable":true,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="以下内容来自Udemy上的课程: Machine Learing A-Z: Hands-On Python &amp; R in Data Science. datasets download 使用数据：  1. Missing dataCommon strategy: replace the missing data by the mean, median, or most frequent v">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Preprocessing（数据预处理）">
<meta property="og:url" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/index.html">
<meta property="og:site_name" content="qypx の blog">
<meta property="og:description" content="以下内容来自Udemy上的课程: Machine Learing A-Z: Hands-On Python &amp; R in Data Science. datasets download 使用数据：  1. Missing dataCommon strategy: replace the missing data by the mean, median, or most frequent v">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/data.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1607053623367.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1607053581148.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1720062264826.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605681111923.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1720062924953.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result2.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605681883031.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/dummy-encoding.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1720076241344.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1720076741388.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1720077082831.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result3.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result4.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/feature-scaling.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/show1.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605753529878.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605753552476.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605683366191.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605683445278.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/1605752923883.png">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result5.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result6.JPG">
<meta property="og:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/result7.JPG">
<meta property="article:published_time" content="2019-09-21T05:56:34.000Z">
<meta property="article:modified_time" content="2024-07-04T07:41:12.184Z">
<meta property="article:author" content="qypx">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="MachineLearningA-Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://qypx.github.io/2019/09/21/Data-Preprocessing/data.JPG">


<link rel="canonical" href="http://qypx.github.io/2019/09/21/Data-Preprocessing/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://qypx.github.io/2019/09/21/Data-Preprocessing/","path":"2019/09/21/Data-Preprocessing/","title":"Data Preprocessing（数据预处理）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Data Preprocessing（数据预处理） | qypx の blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">qypx の blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">机会是留给有准备的人的.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Missing-data"><span class="nav-text">1. Missing data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python"><span class="nav-text">Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Categorical-data"><span class="nav-text">2. Categorical data</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-1"><span class="nav-text">Python</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-1-LabelEncoder"><span class="nav-text">2.1 LabelEncoder</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-factorize"><span class="nav-text">2.2 factorize</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-3-OneHotEncoder"><span class="nav-text">2.3 OneHotEncoder</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-get-dummies"><span class="nav-text">2.4 get_dummies</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-text">2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R-1"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-train-test-split"><span class="nav-text">3. train_test_split</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Python-2"><span class="nav-text">Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#R-2"><span class="nav-text">R</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Feature-Scaling"><span class="nav-text">4. Feature Scaling</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-Normalization%E5%BD%92%E4%B8%80%E5%8C%96-Min-Max"><span class="nav-text">4.1 Normalization归一化 Min-Max</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-Standardization%E6%A0%87%E5%87%86%E5%8C%96-Z-score"><span class="nav-text">4.2 Standardization标准化 Z-score</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-%E5%BD%92%E4%B8%80%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-text">4.3 归一化和标准化的区别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BD%92%E4%B8%80%E5%8C%96-%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-text">4.4 为什么要归一化&#x2F;标准化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E7%94%A8%E6%A0%87%E5%87%86%E5%8C%96%EF%BC%9F%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E7%94%A8%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%9F"><span class="nav-text">4.5  什么时候用标准化？什么时候用归一化？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6-%E4%B8%8D%E6%98%AF%E6%89%80%E6%9C%89%E6%A8%A1%E5%9E%8B%E9%83%BD%E8%A6%81%E6%B1%82%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E7%BB%8F%E8%BF%87%E6%A0%87%E5%87%86%E5%8C%96-%E5%BD%92%E4%B8%80%E5%8C%96%E5%A4%84%E7%90%86"><span class="nav-text">4.6 不是所有模型都要求输入数据经过标准化&#x2F;归一化处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-7-Python"><span class="nav-text">4.7 Python</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-8-R"><span class="nav-text">4.8 R</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="qypx"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">qypx</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">128</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">57</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/qypx" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;qypx" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://qypx.github.io/2019/09/21/Data-Preprocessing/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="qypx">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qypx の blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Data Preprocessing（数据预处理） | qypx の blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Data Preprocessing（数据预处理）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-09-21 13:56:34" itemprop="dateCreated datePublished" datetime="2019-09-21T13:56:34+08:00">2019-09-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-07-04 15:41:12" itemprop="dateModified" datetime="2024-07-04T15:41:12+08:00">2024-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">机器学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>以下内容来自Udemy上的课程: <a href="https://www.udemy.com/machinelearning/"><strong>Machine Learing A-Z: Hands-On Python &amp; R in Data Science</strong></a>.</p>
<p><a href="https://www.superdatascience.com/pages/machine-learning">datasets download</a></p>
<p>使用数据：</p>
<p><img src="/2019/09/21/Data-Preprocessing/data.JPG" alt="data"></p>
<h3 id="1-Missing-data"><a href="#1-Missing-data" class="headerlink" title="1. Missing data"></a>1. Missing data</h3><p>Common strategy: replace the missing data by the mean, median, or most frequent value of the feature column.</p>
<h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><p>1.以均值代替：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">&#x27;Data.csv&#x27;</span>)</span><br><span class="line">X = dataset.drop(columns=<span class="string">&#x27;Purchase&#x27;</span>)</span><br><span class="line">y = dataset[<span class="string">&#x27;Purchase&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line"><span class="comment"># 法一：SimpleImputer(新版sklearn，以前为 from sklearn.preprocessing import Imputer)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line">imputer = SimpleImputer(missing_values=np.nan, strategy = <span class="string">&quot;mean&quot;</span>)</span><br><span class="line">imputer.fit(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>]) </span><br><span class="line"><span class="comment"># ↑如果写作imputer.fit(X)，会报错：ValueError: Cannot use mean strategy with non-numeric data。得传入数值型的（去掉第一列）</span></span><br><span class="line">X.iloc[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 法二，replace</span></span><br><span class="line"><span class="comment">#以Age为例</span></span><br><span class="line">X[<span class="string">&quot;Age&quot;</span>].replace(np.nan, X[<span class="string">&quot;Age&quot;</span>].mean(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 法三，fillna</span></span><br><span class="line"><span class="comment"># 以Age为例</span></span><br><span class="line">X[<span class="string">&quot;Age&quot;</span>] = X[<span class="string">&quot;Age&quot;</span>].fillna(X[<span class="string">&quot;Age&quot;</span>].mean())</span><br><span class="line"><span class="comment"># 也可写作</span></span><br><span class="line">X[<span class="string">&quot;Age&quot;</span>].fillna(X[<span class="string">&quot;Age&quot;</span>].mean(), inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>2.以指定值替代</p>
<p>例：现有 df_age 如下：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1607053623367.png" alt="1607053623367"></p>
<p>Fill the missing data in column <strong>“age_boy”</strong> with 22 and fill the missing data in column <strong>“age_girl”</strong> with 21. The expected output is:</p>
<p><img src="/2019/09/21/Data-Preprocessing/1607053581148.png" alt="1607053581148"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_age = df_age.fillna(value=&#123;<span class="string">&#x27;age_boy&#x27;</span>:<span class="number">22</span>,<span class="string">&#x27;age_girl&#x27;</span>:<span class="number">21</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>3.删掉有缺失值的行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X.dropna(axis = <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 或写成 X = X.dropna(axis = 0)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还可指定当哪一变量出现缺失值时，执行删除的操作</span></span><br><span class="line">X.dropna(subset=[<span class="string">&quot;Age&quot;</span>], axis = <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>4.删掉有缺失值的列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.dropna(axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset <span class="operator">=</span> read.csv<span class="punctuation">(</span><span class="string">&#x27;Data.csv&#x27;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line">dataset<span class="operator">$</span>Age <span class="operator">=</span> ifelse<span class="punctuation">(</span><span class="built_in">is.na</span><span class="punctuation">(</span>dataset<span class="operator">$</span>Age<span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                     ave<span class="punctuation">(</span>dataset<span class="operator">$</span>Age<span class="punctuation">,</span> FUN <span class="operator">=</span> <span class="keyword">function</span><span class="punctuation">(</span>x<span class="punctuation">)</span> mean<span class="punctuation">(</span>x<span class="punctuation">,</span> na.rm <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                     dataset<span class="operator">$</span>Age<span class="punctuation">)</span></span><br><span class="line">dataset<span class="operator">$</span>Salary <span class="operator">=</span> ifelse<span class="punctuation">(</span><span class="built_in">is.na</span><span class="punctuation">(</span>dataset<span class="operator">$</span>Salary<span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                        ave<span class="punctuation">(</span>dataset<span class="operator">$</span>Salary<span class="punctuation">,</span> FUN <span class="operator">=</span> <span class="keyword">function</span><span class="punctuation">(</span>x<span class="punctuation">)</span> mean<span class="punctuation">(</span>x<span class="punctuation">,</span> na.rm <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                        dataset<span class="operator">$</span>Salary<span class="punctuation">)</span></span><br><span class="line">                        </span><br><span class="line"><span class="comment"># 法二</span></span><br><span class="line">dataset<span class="operator">$</span>Age <span class="operator">=</span> ifelse<span class="punctuation">(</span><span class="built_in">is.na</span><span class="punctuation">(</span>dataset<span class="operator">$</span>Age<span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                     mean<span class="punctuation">(</span>dataset<span class="operator">$</span>Age<span class="punctuation">,</span> na.rm <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                     dataset<span class="operator">$</span>Age<span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line">dataset<span class="operator">$</span>Salary <span class="operator">=</span> ifelse<span class="punctuation">(</span><span class="built_in">is.na</span><span class="punctuation">(</span>dataset<span class="operator">$</span>Salary<span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                        mean<span class="punctuation">(</span>dataset<span class="operator">$</span>Salary<span class="punctuation">,</span> na.rm <span class="operator">=</span> <span class="literal">TRUE</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                        dataset<span class="operator">$</span>Salary<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<h3 id="2-Categorical-data"><a href="#2-Categorical-data" class="headerlink" title="2. Categorical data"></a>2. Categorical data</h3><h4 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用上一步处理缺失值后的数据</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">&#x27;Data.csv&#x27;</span>)</span><br><span class="line">X = dataset.drop(columns=<span class="string">&#x27;Purchase&#x27;</span>)</span><br><span class="line">y = dataset[<span class="string">&#x27;Purchase&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line">imputer = SimpleImputer(missing_values=np.nan, strategy = <span class="string">&quot;mean&quot;</span>)</span><br><span class="line">imputer.fit(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>]) </span><br><span class="line">X.iloc[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X.iloc[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>X：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1720062264826.png" alt="1720062264826"></p>
<h5 id="2-1-LabelEncoder"><a href="#2-1-LabelEncoder" class="headerlink" title="2.1 LabelEncoder"></a>2.1 LabelEncoder</h5><blockquote>
<p>LabelEncoder官方文档<br><a href="https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html">https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html</a></p>
</blockquote>
<p><img src="/2019/09/21/Data-Preprocessing/1605681111923.png" alt="1605681111923"></p>
<p>1.使用LabelEncoder对X编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X.iloc[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X.iloc[:, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>经过LabelEncoder编码后的X：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1720062924953.png" alt="1720062924953"></p>
<p>But the model will think that France has lower value than Spain -&gt; that’s not the case, we have no order here. 解决办法：使用后面介绍的OneHotEncoder方法。（如果是S, M, L of a T-shirt（本身有顺序）, 不必使用OneHotEncoder方法。）</p>
<p>2.使用LabelEncoder对y编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Encoding the Dependent Variable</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">For the dependent variable, we are only going to use LabelEncoder, </span></span><br><span class="line"><span class="string">because since this is the dpendent variable, the machine learning model will know</span></span><br><span class="line"><span class="string">that it&#x27;s a category, and that there is no oder between the two</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">labelencoder_y = LabelEncoder()</span><br><span class="line">y = labelencoder_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result2.JPG" alt="result2"></p>
<h5 id="2-2-factorize"><a href="#2-2-factorize" class="headerlink" title="2.2 factorize"></a>2.2 factorize</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = DataFrame([<span class="string">&#x27;A&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;B&#x27;</span>, <span class="string">&#x27;C&#x27;</span>], columns=[<span class="string">&#x27;Col&#x27;</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># factorize</span></span><br><span class="line">df[<span class="string">&#x27;Fact&#x27;</span>] = pd.factorize(df[<span class="string">&#x27;Col&#x27;</span>])[<span class="number">0</span>]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>比较与LabelEnocoder的结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LabelEncoder</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">le = preprocessing.LabelEncoder()</span><br><span class="line">df[<span class="string">&#x27;Lab&#x27;</span>] = le.fit_transform(df[<span class="string">&#x27;Col&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df)</span><br><span class="line"><span class="comment">#   Col  Fact  Lab</span></span><br><span class="line"><span class="comment"># 0   A     0    0</span></span><br><span class="line"><span class="comment"># 1   B     1    1</span></span><br><span class="line"><span class="comment"># 2   B     1    1</span></span><br><span class="line"><span class="comment"># 3   C     2    2</span></span><br></pre></td></tr></table></figure>
<p>👆可以看到factorize与LabelEncoder结果是一样的</p>
<h5 id="2-3-OneHotEncoder"><a href="#2-3-OneHotEncoder" class="headerlink" title="2.3 OneHotEncoder"></a>2.3 OneHotEncoder</h5><blockquote>
<p>OneHotEncoder官方文档<br><a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html</a></p>
</blockquote>
<p><img src="/2019/09/21/Data-Preprocessing/1605681883031.png" alt="1605681883031"></p>
<p><img src="/2019/09/21/Data-Preprocessing/dummy-encoding.JPG" alt="dummy encoding"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"></span><br><span class="line">onehotencoder=OneHotEncoder()</span><br><span class="line">X_encoded = onehotencoder.fit_transform(X.iloc[:,<span class="number">0</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)).toarray()</span><br><span class="line">X_onehot = pd.DataFrame(X_encoded, columns=onehotencoder.get_feature_names_out())</span><br><span class="line">X_new = pd.concat([X,X_onehot], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>X_new: (再把第一列drop掉)</p>
<p><img src="/2019/09/21/Data-Preprocessing/1720076241344.png" alt="1720076241344"></p>
<p>上述结果，还应该drop掉France, Germany, Spain的其中一列（只需要两列就够了），更好的写法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">onehotencoder=OneHotEncoder(drop=<span class="string">&#x27;first&#x27;</span>)</span><br><span class="line">X_encoded = onehotencoder.fit_transform(X.iloc[:,<span class="number">0</span>].values.reshape(-<span class="number">1</span>,<span class="number">1</span>)).toarray()</span><br><span class="line">X_onehot = pd.DataFrame(X_encoded, columns=onehotencoder.get_feature_names_out())</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/1720076741388.png" alt="1720076741388"></p>
<h5 id="2-4-get-dummies"><a href="#2-4-get-dummies" class="headerlink" title="2.4 get_dummies"></a>2.4 get_dummies</h5><p>onehot encoding的另一种实现方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = pd.get_dummies(X, drop_first=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以指定列：</span></span><br><span class="line">X = pd.get_dummies(X, columns=[<span class="string">&#x27;Country&#x27;</span>], drop_first=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/1720077082831.png" alt="1720077082831"></p>
<h5 id="2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies的区别"><a href="#2-4-LabelEncoder-OnehotEncoder-factorize-get-dummies的区别" class="headerlink" title="2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别"></a>2.4 LabelEncoder, OnehotEncoder, factorize, get_dummies的区别</h5><blockquote>
<p>参考<br> <a href="https://medium.com/@vaibhavshukla182/want-to-know-the-diff-among-pd-factorize-a8591eb3347d">https://medium.com/@vaibhavshukla182/want-to-know-the-diff-among-pd-factorize-a8591eb3347d</a></p>
</blockquote>
<p>这四种编码方式可以分为两类：</p>
<ul>
<li>Encode <strong>labels into categorical variables</strong>: Pandas <code>factorize</code> and scikit-learn <code>LabelEncoder</code>. 编码结果是1维的.<br> <span style="color:red">factorize与LabelEncoder都是将字符型变量(categorical varirables)编码为数值型1，2，3…（本来是一维，编码后依然是一维）</span></li>
<li>Encode <strong>categorical variable into dummy/indicator (binary) variables</strong>: Pandas <code>get_dummies</code> and scikit-learn <code>OneHotEncoder</code>. 编码结果是 n 维的.<br><span style="color:red">get_dummies与OneHotEnocder都是将字符型变量编码为0，1哑变量（本来是一维，编码后变为多维）</span></li>
</ul>
<p>The main difference between pandas and scikit-learn encoders is that scikit-learn encoders are made to be used in <strong>scikit-learn pipelines</strong> with <code>fit</code> and <code>transform</code> methods.<br> <span style="color:red">sklearn中的LabelEnocder，OneHotEncoder与pandas中的factorize, get_dummies的区别在于sklearn的两个方法可以使用fit和transform（在测试集上的编码应依赖于训练集）</span></p>
<h4 id="R-1"><a href="#R-1" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Encoding categorical data</span></span><br><span class="line">dataset<span class="operator">$</span>Country <span class="operator">=</span> factor<span class="punctuation">(</span>dataset<span class="operator">$</span>Country<span class="punctuation">,</span></span><br><span class="line">                         levels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&#x27;France&#x27;</span><span class="punctuation">,</span> <span class="string">&#x27;Spain&#x27;</span><span class="punctuation">,</span> <span class="string">&#x27;Germany&#x27;</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                         labels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">1</span><span class="punctuation">,</span> <span class="number">2</span><span class="punctuation">,</span> <span class="number">3</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br><span class="line">dataset<span class="operator">$</span>Purchased <span class="operator">=</span> factor<span class="punctuation">(</span>dataset<span class="operator">$</span>Purchased<span class="punctuation">,</span></span><br><span class="line">                           levels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="string">&#x27;No&#x27;</span><span class="punctuation">,</span> <span class="string">&#x27;Yes&#x27;</span><span class="punctuation">)</span><span class="punctuation">,</span></span><br><span class="line">                           labels <span class="operator">=</span> <span class="built_in">c</span><span class="punctuation">(</span><span class="number">0</span><span class="punctuation">,</span> <span class="number">1</span><span class="punctuation">)</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result3.JPG" alt="result3"></p>
<p><img src="/2019/09/21/Data-Preprocessing/result4.JPG" alt="result4"></p>
<h3 id="3-train-test-split"><a href="#3-train-test-split" class="headerlink" title="3. train_test_split"></a>3. train_test_split</h3><h4 id="Python-2"><a href="#Python-2" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">&#x27;Data.csv&#x27;</span>)</span><br><span class="line">X = dataset.drop(columns=<span class="string">&#x27;Purchase&#x27;</span>)</span><br><span class="line">y = dataset[<span class="string">&#x27;Purchase&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">1502</span>, stratify=y)</span><br></pre></td></tr></table></figure>
<h4 id="R-2"><a href="#R-2" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset <span class="operator">=</span> read.csv<span class="punctuation">(</span><span class="string">&#x27;Data.csv&#x27;</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages(&#x27;caTools&#x27;)</span></span><br><span class="line">library<span class="punctuation">(</span>caTools<span class="punctuation">)</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">123</span><span class="punctuation">)</span></span><br><span class="line">split <span class="operator">=</span> sample.split<span class="punctuation">(</span>dataset<span class="operator">$</span>Purchased<span class="punctuation">,</span> SplitRatio <span class="operator">=</span> <span class="number">0.8</span><span class="punctuation">)</span> <span class="comment"># 这里取因变量</span></span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set <span class="operator">=</span> subset<span class="punctuation">(</span>dataset<span class="punctuation">,</span> split <span class="operator">==</span> <span class="literal">TRUE</span><span class="punctuation">)</span></span><br><span class="line">test_set <span class="operator">=</span> subset<span class="punctuation">(</span>dataset<span class="punctuation">,</span> split <span class="operator">==</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<h3 id="4-Feature-Scaling"><a href="#4-Feature-Scaling" class="headerlink" title="4. Feature Scaling"></a>4. Feature Scaling</h3><p>Lots of machine learning models are based on Euclidean distance. Since the salary has a much wider range of values, the euclidean distance will be dominated by the salary. </p>
<p>Even if the machine learning models are not based on euclidean distance, we will still need to do feature scaling, because the algorithms will converge much faster.</p>
<p><strong><em>Feature Scaling:</em></strong> Putting our variables in the same range (in the same scale),  so that no variable is dominated by the other.</p>
<p><img src="/2019/09/21/Data-Preprocessing/feature-scaling.JPG" alt="feature scaling"></p>
<p><strong><em>Question 1: Do we need to fit and transform dummy variables?</em></strong></p>
<p><img src="/2019/09/21/Data-Preprocessing/show1.JPG" alt="show1"></p>
<p>It depends on the context. Depends on how much you want to keep interpretation in your models. Because if we scale dummy variables, it will be good because everything will be on the same scale, it will be good for our predictions, but we will lose interpretation of knowing which observation belongs to which country.</p>
<p><strong><em>Qustion 2: Do we need to apply feature scaling to y?</em></strong></p>
<p>we don’t need to do it if it is a classification problem  with categorical dependent variable. But for regression, where the dependent variable will take a huge range of values, we will need to apply feature scaling to y as well.</p>
<blockquote>
<p>以下内容参考 <a href="https://www.jianshu.com/p/ba2a64a81c81">https://www.jianshu.com/p/ba2a64a81c81</a></p>
</blockquote>
<h4 id="4-1-Normalization归一化-Min-Max"><a href="#4-1-Normalization归一化-Min-Max" class="headerlink" title="4.1 Normalization归一化 Min-Max"></a>4.1 Normalization归一化 Min-Max</h4><script type="math/tex; mode=display">
x_{new} = \frac{x_{old}-x_{min}}{x_{max}-x_{min}}</script><p>$x_{new}$取值范围：[0,1]</p>
<p>其他归一化方法：</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605753529878.png" alt="1605753529878"></p>
<p><img src="/2019/09/21/Data-Preprocessing/1605753552476.png" alt="1605753552476"></p>
<h4 id="4-2-Standardization标准化-Z-score"><a href="#4-2-Standardization标准化-Z-score" class="headerlink" title="4.2 Standardization标准化 Z-score"></a>4.2 Standardization标准化 Z-score</h4><script type="math/tex; mode=display">
x_{new} = \frac{X_{old}-\mu}{\sigma}</script><p>The resulting values hover around 0, and typically range between -3 and +3, but can be higher or lower.</p>
<h4 id="4-3-归一化和标准化的区别"><a href="#4-3-归一化和标准化的区别" class="headerlink" title="4.3 归一化和标准化的区别"></a>4.3 归一化和标准化的区别</h4><p><strong>（1）转换区间</strong><br>归一化（Normalization）：把数据转换到(0,1)或者(-1,1)区间的数据映射方式<br>标准化（Standardization）：把数据转换到均值为0，标准差为1的数据映射方式</p>
<p><strong>（2）数据分布</strong><br>归一化：对数据的数值范围进行特定缩放，但不改变其数据分布</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605683366191.png" alt="1605683366191"></p>
<p>标准化：对数据的分布进行转换，使其符合某种分布（如正态分布）</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605683445278.png" alt="1605683445278"></p>
<h4 id="4-4-为什么要归一化-标准化"><a href="#4-4-为什么要归一化-标准化" class="headerlink" title="4.4 为什么要归一化/标准化"></a>4.4 为什么要归一化/标准化</h4><p><strong>（1）梯度下降的需要，加速算法收敛速度</strong><br>在使用梯度下降的方法求解最优化问题时，归一化/标准化后可以加快梯度下降的求解速度，即提升模型的收敛速度。</p>
<p><img src="/2019/09/21/Data-Preprocessing/1605752923883.png" alt="1605752923883"></p>
<p>线性回归、逻辑回归、神经网络等使用梯度下降法求解最优参数的算法，输入数据需要做归一化/标准化处理，提升模型收敛速度。</p>
<p><strong>（2）距离计算的需要，保障算法准确度</strong><br>一些算法需要计算样本之间的距离（如欧式距离），例如KNN、kmeans等聚类算法。<strong>如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征</strong>，从而与实际情况相悖。</p>
<p><strong>（3）消除量纲和数量级影响</strong><br>各个指标之间由于计量单位和数量级不尽相同，从而使得各指标间不具有综合性，不能直接进行综合分析，这时就必须采用某种方法对各指标数值进行无量纲化处理，解决各指标数值不可综合性问题。</p>
<blockquote>
<p>去量纲指的是去除数据单位之间的不统一，将数据统一变换为无单位（统一单位）的数据集。</p>
</blockquote>
<h4 id="4-5-什么时候用标准化？什么时候用归一化？"><a href="#4-5-什么时候用标准化？什么时候用归一化？" class="headerlink" title="4.5  什么时候用标准化？什么时候用归一化？"></a>4.5  什么时候用标准化？什么时候用归一化？</h4><p>（1）一般建议优先使用标准化，在机器学习中，标准化是更常用的手段，归一化的应用场景是有限的。<br>（2）如果数据不稳定，存在极端的最大最小值，不要用归一化。<br>（3）在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用PCA技术进行降维的时候，标准化(Z-score standardization)表现更好。<br>（4）在不涉及距离度量、协方差计算、数据不符合正态分布的时候，可以使用归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0, 255]的范围。</p>
<h4 id="4-6-不是所有模型都要求输入数据经过标准化-归一化处理"><a href="#4-6-不是所有模型都要求输入数据经过标准化-归一化处理" class="headerlink" title="4.6 不是所有模型都要求输入数据经过标准化/归一化处理"></a>4.6 不是所有模型都要求输入数据经过标准化/归一化处理</h4><p>不是所有的模型都需要做归一的，比如模型算法里面没有关于对距离的衡量，没有关于对变量间标准差的衡量。<br>（1）比如decision tree决策树，算法里面没有涉及到任何和距离等有关的，所以在做决策树模型时，通常是不需要将变量做标准化的<br>（2）概率模型不需要归一化，因为它们不关心变量的值，而是关心变量的分布和变量之间的条件概率。</p>
<h4 id="4-7-Python"><a href="#4-7-Python" class="headerlink" title="4.7 Python"></a>4.7 Python</h4><p>标准化：（假设数据已经过缺失值处理与categorical data的转换）</p>
<p>（以下代码中scale了dummy variable.）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">&#x27;Data.csv&#x27;</span>)</span><br><span class="line">X = dataset.drop(columns=<span class="string">&#x27;Purchase&#x27;</span>)</span><br><span class="line">y = dataset[<span class="string">&#x27;Purchase&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="comment"># most of time we don&#x27;t need to do feature scaling, beacuse feature scaling is a tool</span></span><br><span class="line"><span class="comment"># included most of time in the machine learning libraries</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 标准化</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train_scaled = sc_X.fit_transform(X_train)</span><br><span class="line">X_test_scaled = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>Feature scaling on X_test is the same as the feature scaling on the X_train(scaled on the same bases)</p>
<p><img src="/2019/09/21/Data-Preprocessing/result5.JPG" alt="result5"></p>
<p>The result is between -1 and 1.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sc_y = StandardScaler()</span><br><span class="line">y_train_scaled = sc_y.fit_transform(y_train.reshape(-<span class="number">1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>归一化MinMax：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_train_scaled = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scaled = scaler.transform(X_test)</span><br></pre></td></tr></table></figure>
<h4 id="4-8-R"><a href="#4-8-R" class="headerlink" title="4.8 R"></a>4.8 R</h4><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages(&#x27;caTools&#x27;)</span></span><br><span class="line">library<span class="punctuation">(</span>caTools<span class="punctuation">)</span></span><br><span class="line">set.seed<span class="punctuation">(</span><span class="number">123</span><span class="punctuation">)</span></span><br><span class="line">split <span class="operator">=</span> sample.split<span class="punctuation">(</span>dataset<span class="operator">$</span>Purchased<span class="punctuation">,</span> SplitRatio <span class="operator">=</span> <span class="number">0.8</span><span class="punctuation">)</span></span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set <span class="operator">=</span> subset<span class="punctuation">(</span>dataset<span class="punctuation">,</span> split <span class="operator">==</span> <span class="literal">TRUE</span><span class="punctuation">)</span></span><br><span class="line">test_set <span class="operator">=</span> subset<span class="punctuation">(</span>dataset<span class="punctuation">,</span> split <span class="operator">==</span> <span class="literal">FALSE</span><span class="punctuation">)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling 标准化</span></span><br><span class="line">training_set <span class="operator">=</span> scale<span class="punctuation">(</span>training_set<span class="punctuation">)</span></span><br><span class="line">test_set <span class="operator">=</span> scale<span class="punctuation">(</span>test_set<span class="punctuation">)</span></span><br></pre></td></tr></table></figure>
<p>语法：<code>scale(x, center = TRUE, scale = TRUE)</code></p>
<p>Arguments:<br><code>x</code>: a numeric matrix(like object).<br><code>center</code>: either a logical value or a numeric vector of length equal to the number of columns of <code>x</code>.<br><code>scale</code>: either a logical value or a numeric vector of length equal to the number of columns of <code>x</code>.</p>
<p>Details:<br>If <code>center</code> is <code>TRUE</code> then centering is done by subtracting the column means (omitting <code>NA</code>s) of <code>x</code> from their corresponding columns, and if <code>center</code> is <code>FALSE</code>, no centering is done.<br>If <code>scale</code> is <code>TRUE</code> then scaling is done by dividing the (centered) columns of <code>x</code> by their standard deviations if <code>center</code> is <code>TRUE</code>, and the root mean square otherwise. If <code>scale</code> is <code>FALSE</code>, no scaling is done.<br>The root-mean-square for a (possibly centered) column is defined as $\sqrt{sum(x^2)/(n-1)}$, where <em>x</em> is a vector of the non-missing values and <em>n</em> is the number of non-missing values. In the case <code>center = TRUE</code>, this is the same as the standard deviation, but in general it is not. (To scale by the standard deviations without centering, use <code>scale(x, center = FALSE, scale = apply(x, 2, sd, na.rm = TRUE))</code>.)</p>
<p>但直接这样运行会出错：</p>
<p><img src="/2019/09/21/Data-Preprocessing/result6.JPG" alt="result6"></p>
<p>原因：因子型变量不是 numeric的。</p>
<p><img src="/2019/09/21/Data-Preprocessing/result7.JPG" alt="result7"></p>
<p>解决方法：We’re going to exclude categories from the feature scaling, we’re not going to apply feature scaling on those columns.</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">training_set<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span> <span class="operator">=</span> scale<span class="punctuation">(</span>training_set<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br><span class="line">test_set<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span> <span class="operator">=</span> scale<span class="punctuation">(</span>test_set<span class="punctuation">[</span><span class="punctuation">,</span><span class="number">2</span><span class="operator">:</span><span class="number">3</span><span class="punctuation">]</span><span class="punctuation">)</span></span><br></pre></td></tr></table></figure>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>qypx
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://qypx.github.io/2019/09/21/Data-Preprocessing/" title="Data Preprocessing（数据预处理）">http://qypx.github.io/2019/09/21/Data-Preprocessing/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
              <a href="/tags/MachineLearningA-Z/" rel="tag"># MachineLearningA-Z</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2019/09/17/Python-working-directory/" rel="prev" title="Python working directory">
                  <i class="fa fa-angle-left"></i> Python working directory
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2019/12/15/Hadoop-Introduction/" rel="next" title="Hadoop Introduction">
                  Hadoop Introduction <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-user"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">qypx</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  



  <script src="/js/third-party/fancybox.js"></script>



  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left"},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
