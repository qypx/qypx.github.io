<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Precision, Recall, ROC曲线等</title>
    <url>/2020/08/07/Precision-Recall-ROC%E6%9B%B2%E7%BA%BF%E7%AD%89/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>准确率 <script type="math/tex">Accuracy = \frac{TP+TN}{TP+TN+FP+FN}</script></p>
<p>精确率 <script type="math/tex">Precision = \frac{TP}{TP+FP}</script>，预测为positive中，实际为positive的比例</p>
<p>召回率 <script type="math/tex">Recall = \frac{TP}{TP+FN}</script>，实际为positive中，预测为positive的比例</p>
<script type="math/tex; mode=display">F1\_Score=\frac{2*Precision*Recall}{Precision+Recall}</script><p><img src="/2020/08/07/Precision-Recall-ROC曲线等/1596782796816.png" alt="1596782796816"></p>
<hr>
<p>TPR, <script type="math/tex">True\ Positive\ Rate = \frac{TP}{TP+FN}</script>，等价于 <script type="math/tex">Recall</script>，正样本中正确分类的比例</p>
<p>FPR, <script type="math/tex">False\ Positive\ Rate = \frac{FP}{FP+TN}</script>，负样本中错分的比例</p>
<p><img src="/2020/08/07/Precision-Recall-ROC曲线等/1596782970482.png" alt="1596782970482"></p>
<hr>
<p>灵敏度 <script type="math/tex">Sensitivity = \frac{TP}{TP+FN}</script>，等价于 <script type="math/tex">Recall</script>，正样本中正确分类的比例 (Accuracy with respect to positive cases, also called <script type="math/tex">True\ Positive\ Rate</script>) (预测为positive占实际真正为positive的比例)</p>
<p>特异度 <script type="math/tex">Specificity = \frac{TN}{TN+FP}</script>，负样本中正确分类的比例 (Accuracy with respect to negative cases) (将negative预测为positive占实际真正为negative的比例)</p>
<script type="math/tex; mode=display">FPR=1-Specificity</script><p><img src="/2020/08/07/Precision-Recall-ROC曲线等/1596783235673.png" alt="1596783235673"></p>
<hr>
<p>ROC曲线：横轴为 FPR, 纵轴为 TPR， 越靠近左上角越好。对于某个分类器，根据其在测试样本上的表现可以得到一个TPR和FPR点对。调整分类时使用的阈值，可以得到一个经过 (0,0), (1,1)的曲线。</p>
<p>AUC值：ROC曲线下的面积，取值范围在 0.5 到 1 之间。AUC更大的分类器效果更好。</p>
<p><img src="/2020/08/07/Precision-Recall-ROC曲线等/1596778766409.png" alt="1596778766409"></p>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统冷启动问题</title>
    <url>/2020/07/30/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E5%86%B7%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>来源于</p>
<p><a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
</blockquote>
<p>冷启动（ cold start ）在推荐系统中表示该系统积累数据量过少，无法给新用户作个性化推荐的问题，这是产品推荐的一大难题。每个有推荐功能的产品都会遇到冷启动的问题。一方面，当新商品时上架 会遇到冷启动的问题，没有收集到任何一个用户对其浏览、点击或者购买的行为，也无从判断如何将商品进行推荐；另一方面，新用户到来的时候，如果没有他在应用上的行为数据，也无法预测其兴趣，如果给用户的推荐千篇律，没有亮点，会使用户在一开始就对产品失去兴趣，从而放弃使用。所以在冷启动的时候要同时<strong>考虑用户的冷启动和物品的冷启动。</strong></p>
<h3 id="8-1-用户冷启动"><a href="#8-1-用户冷启动" class="headerlink" title="8.1 用户冷启动"></a>8.1 用户冷启动</h3><p>用户冷启动主要解决如何给新用户作个性化推荐的问题。当新用户到来时，我 没有他的行为数据，所以也无法根据他的历史行为预 其兴趣，从而无法借此给他做个性化推荐。解决方法参考以下：</p>
<ol>
<li>利用用户的账号信息。</li>
<li>利用用户的手机 IMEI 号进行冷启动。</li>
<li>制造选工页，让用户选择自己感兴趣的点后，即时生成粗粒度的推荐。</li>
</ol>
<h3 id="8-2-物品冷启动"><a href="#8-2-物品冷启动" class="headerlink" title="8.2 物品冷启动"></a>8.2 物品冷启动</h3><p>物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。解决方法参考以下：</p>
<ol>
<li>利用物品的内容、分类信息。</li>
<li>利用专家标注的数据。</li>
</ol>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐系统总体架构及特征数据</title>
    <url>/2020/07/29/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E6%80%BB%E4%BD%93%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>来源于</p>
<p><a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
</blockquote>
<p><strong>个性化推荐系统是建立在海量数据挖掘基础上的一种高级商务智能平台，以帮助电子商务网站为其顾客购物提供完全个性化的决策支持和信息服务。</strong></p>
<p>常见的推荐栏位例如：淘宝的猜你喜欢、看了又看、推荐商品，美团的首页推荐、附近推荐等。</p>
<p>推荐系统是比较偏向于工程类的系统，要做得更加的精确，需要的不仅仅是推荐算法，还有用户意图识别、文本分析、行为分析等，是一个综合性很强的系统。</p>
<h2 id="1-总体架构"><a href="#1-总体架构" class="headerlink" title="1. 总体架构"></a>1. 总体架构</h2><p>本节介绍的几种推荐系统架构，并不是互相独立的关系，实际的推荐系统可能会用到其中一种或者几种的架构。在实际设计的过程中，读者可以把本文介绍的架构作为一个设计的起点，更多地结合自身业务特点进行独立思 考，从而设计出适合自身业务的系统。</p>
<p>根据响应用户行为的速度不同，推荐系统可以大致分为基于<strong>离线训练和在线训练</strong>的推荐系统。</p>
<h3 id="1-1-离线推荐"><a href="#1-1-离线推荐" class="headerlink" title="1.1 离线推荐"></a>1.1 离线推荐</h3><p>基于离线训练的推荐系统架构是最常见的一种推荐系统架构。这里的“离线”训练指的是使用历史一段时间（ 比如周或者几周 ）的数据进行训练，模型迭代的周期较长（一般以小时为单位 ）。模型拟合的是用户的中长期兴趣。</p>
<p>如下图所示， 一个典型的基于离线训练的推荐系统架构由<strong>数据上报、离线训练、在线存储、实时计算和 A/B 测试</strong>这几个模块组成。其中，数据上报和离线训练组成了监督学习中的学习系统，而实时计算和 A/B 测试组成了预测系统。另外，除了模型之外，还有一个在线存储模块，用于存储模型和模型需要的特征信息供实时计算模块调用。图中的各个模块组成了训练和预测两条数据流，训练的数据流搜集业务的数据最后生成模型存储于在线存储模块；预测的数据流接受业务的预测请求，通过 A/B 测试模块访问实时计算模块获取预测结果。</p>
<p><img src="https://camo.githubusercontent.com/256d4abf6809d771af7205fd18eadae4e12936c2/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31302d32322d302e706e67" alt="img"></p>
<a id="more"></a>
<ol>
<li><p><strong>数据上报</strong>：数据上报模块的作用是搜集业务数据组成训练样本。一般分为收集、验证、清洗和转换几个步骤。将收集的数据转化为训练所需要的样本格式，保存到离线存储模块。</p>
<p><a href="https://camo.githubusercontent.com/04a5b6b6717428ef7ffd4e9e139239bbf0072422/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31302d33332d34362e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/04a5b6b6717428ef7ffd4e9e139239bbf0072422/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31302d33332d34362e706e67" alt="img"></a></p>
</li>
<li><p><strong>离线训练</strong>：离线训练模块又细分为<strong>离线存储</strong>和<strong>离线计算</strong>。实际业务中使用的推荐系统一般都需要处理海量的用户行为数据，所以离线存储模块需要有一个分布式的文件系统或者存储平台来存储这些数据。离线计算常见的操作有：样本抽样、特征工程、模型训练、相似度计算等。</p>
</li>
<li><p><strong>在线存储</strong>：因为线上的服务对于时延都有严格的要求。比如，某个用户打开手机 APP ，他肯定希望APP 能够快速响应，如果耗时过长，就会影响用户的体验。一般来说，这就要求推荐系统在几十毫秒以内处理完用户请求返回推荐结果，所以，针对线上的服务，需要有一个专门的在线存储模块，负责存储用于线上的模型和特征数据 。</p>
</li>
<li><p><strong>实时推荐</strong>：实时推荐模块的功能是对来自业务的新请求进行预测。1.获取用户特征；2.调用推荐模型；3.结果排序。</p>
<p>在实际应用中，因为业务的物品列表太大，如果实时计算对每个物品使用复杂的模型进行打分，就有可能耗时过长而影响用户满意度。所以，一种常见的做法是将推荐列表生成分为<strong>召回</strong>和<strong>排序</strong>两步。召回的作用是从大量的候选物品中（例如上百万）筛选出一批用户较可能喜欢的候选集 （一般是几百）。排序的作用是对召回得到的相对较小的候选集使用排序模型进行打分。更进一步，在排序得到推荐列表后，为了多样性和运营的一些考虑，还会加上第三步重排过滤，用于对精排后的推荐列表进行处理。</p>
</li>
<li><p><strong>A/B测试</strong>：对于互联网产品来说， A/B 测试基本上是一个必备的模块，对于推荐系统来说也不例外，它可以帮助开发人员评估新算法对客户行为的影响。除了 离线的指标外，一个新的推荐算法上线之前一般都会经过 A/B 测试来测试新算法的有效性。</p>
</li>
</ol>
<p>下图是与之对应的实际系统中各个组件的流转过程。<strong>需要注意的是生成推荐列表就已经做完了召回和排序的操作，业务层直接调用API就可以得到这个推荐列表。</strong></p>
<p><img src="https://camo.githubusercontent.com/e00fb75f81bd5377bcfd1de0cdb3891a7790b134/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31302d32352d32372e706e67" alt="img"></p>
<h3 id="2-2-在线训练"><a href="#2-2-在线训练" class="headerlink" title="2.2 在线训练"></a>2.2 在线训练</h3><p>对于业务来说，我们希望用户对于上个广告的反馈 （喜欢或者不喜欢，有没有点击），可以很快地用于下 一个广告的推荐中。这就要求我们用另一种方法来解决这个问题，这个方法就是在线训练。</p>
<p>基于在线训练的推荐系统架构适合于广告和电商等高维度大数据量且对实时性要求很高的场景，相比较基于离线训练的推荐系统，基于在线训练的推荐系统不区分训练和测试阶段，每个回合都在学习，通过实时的反馈来调整策略。 一方面，在线训练要求其样本、特征和模型的处理都是实时的，以便推荐的内容更快地反映用户实时的喜好；另一方面，因为在线训练井不需要将所有的训练数据都存储下来，所以不需要巨大的离线存储开销，使得系统具有很好的伸缩性，可以支持超大的数据量和模型。</p>
<p><img src="https://camo.githubusercontent.com/6d0bf23d50bf62aaf218595a74437800ae143d01/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31312d31312d31312e706e67" alt="img"></p>
<ol>
<li><strong>样本处理</strong>：和基于离线训练的推荐系统相比，在线训练在数据上报阶段的主要不同体现在样本处理上。对于离线训练来说，上报后的数据先是被存储到一个分布式文件系统，然后等待离线计算任务来对样本进行处理；对于在线训练来说，对样本的去重、过滤和采样等计算都需要实时进行。</li>
<li><strong>实时特性</strong>：实时特征模块通过实时处理样本数据拼接训练需要的特征构造训练样本，输入流式训练模块用于更新模型。该模块的主要的功能是特征拼接和特征工程。</li>
<li><strong>流式训练</strong>：流式训练模块的主要作用是使用实时训练样本来更新模型。推荐算法中增量更新部分的计算，通过流式计算的方式来进行更新。在线训练的优势之一，是可以支持模型的稀疏存储。训练方面，在线模型不一定都是从零开始训练，而是可以将离线训练得到的模型参数作为基础，在这个基础上进行增量训练。</li>
<li><strong>模型存储和加载</strong>：模型一般存储在参数服务器中。模型更新后，将模型文件推送到线上存储，并由线上服务模块动态加载。</li>
</ol>
<h2 id="2-特征数据"><a href="#2-特征数据" class="headerlink" title="2. 特征数据"></a>2. 特征数据</h2><p>要训练推荐模型，就需要先收集用户的行为数据生成特征向量以后才能进行训练，而一个特征向量由特征以及特征的权重组成，在利用用户行为计算特征向量时需要考虑以下因素。</p>
<ol>
<li><strong>用户行为的种类</strong>：在一个网站中，用户可以对物品产生很多不同种类的行为。用户可以浏览物品、单击物品的链接、收藏物品、给物品打分、购买物品、评论物品、给物品打上不同的标签、和好友分享物品、搜索不同的关键词等。这些行为都会对物品特征的权重产生影响，但不同行为的影响不同，大多时候很难确定什么行为更加重要，一般的标准就是用户付出代价越大的行为权重越高。</li>
<li><strong>用户行为产生的时间</strong>：一般来说，用户近期的行为比较重要，而用户很久之前的行为相对比较次要。因此，如果用户最近购买过某一个物品，那么这个物品对应的特征将会具有比较高的权重。</li>
<li><strong>用户行为的次数</strong>：有时用户对一个物品会产生很多次行为。比如用户会听一首歌很多次，看一部电视剧的很多集等。因此用户对同一个物品的同一种行为发生的次数也反映了用户对物品的兴趣，行为次数多的物品对应的特征权重越高。</li>
<li><strong>物品的热门程度</strong>：如果用户对一个很热门的物品产生了行为，往往不能代表用户的个性，因为用户可能是在跟风，可能对该物品并没有太大兴趣，特别是在用户对一个热门物品产生了偶尔几次不重要的行为（比如浏览行为）时，就更说明用户对这个物品可能没有什么兴趣，可能只是因为这个物品的链接到处都是，很容易点到而已。反之，如果用户对一个不热门的物品产生了行为，就说明了用户的个性需求。因此，推荐引擎在生成用户特征时会加重不热门物品对应的特征的权重。</li>
<li><strong>数据去燥</strong>：对样本做去噪。对于数据中混杂的刷单等类作弊行为的数据，要将其排除出训练数据,否则它会直接影响模型的效果；样本中的缺失值也要做处理。</li>
<li><strong>正负样本均衡</strong>：一般我们收集用户的行为数据都是属于正样本，造成了严重的不平衡。所以对于一个用户，从他没有过行为的物品中采样出一些物品作为负样本，但采样时，保证每个用户的正负样本数目相当。</li>
<li><strong>特征组合</strong>：我们需要考虑特征与特征之间的关系。例如在美团酒店搜索排序中，酒店的销量、价格、用户的消费水平等是强相关的因素，用户的年龄、位置可能是弱相关的因素，用户的ID是完全无关的因素。在确定了哪些因素可能与预测目标相关后，我们需要将此信息表示为数值类型,即为特征抽取的过程。除此之外，用户在App上的浏览、交易等行为记录中包含了大量的信息，特征抽取则主要是从这些信息抽取出相关因素，用数值变量进行表示。常用的统计特征有计数特征,如浏览次数、下单次数等;比率特征，如点击率、转化率等;统计量特征，如价格均值、标准差、分位数、偏度、峰度等。</li>
</ol>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>隐语义模型</title>
    <url>/2020/07/29/%E9%9A%90%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>来源于:</p>
<p> <a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
</blockquote>
<h3 id="1-基本思想"><a href="#1-基本思想" class="headerlink" title="1. 基本思想"></a>1. 基本思想</h3><p>推荐系统中一个重要的分支，隐语义建模。隐语义模型<strong>LFM</strong>：Latent Factor Model，其核心思想就是<span style="color:red">通过隐含特征联系用户兴趣和物品</span>。</p>
<p><strong>过程分为三个部分，将物品映射到隐含分类，确定用户对隐含分类的兴趣，然后选择用户感兴趣的分类中的物品推荐给用户。它是基于用户行为统计的自动聚类。</strong></p>
<p>隐语义模型在Top-N推荐中的应用十分广泛。常用的隐语义模型，LSA(Latent Semantic Analysis)，LDA(Latent Dirichlet Allocation)，主题模型(Topic Model)，矩阵分解(Matrix Factorization)等等。</p>
<p>首先通过一个例子来理解一下这个模型，比如说有两个用户A和B，目前有用户的阅读列表，用户A的兴趣涉及侦探小说，科普图书以及一些计算机技术书，而用户B的兴趣比较集中在数学和机器学习方面。那么如何给A和B推荐图书呢？</p>
<p>对于UserCF，首先需要找到和他们看了同样书的其他用户(兴趣相似的用户)，然后在给他们推荐那些用户喜欢的其他书。 对于ItemCF, 需要给他们推荐和他们已经看的书相似的书，比如用户B 看了很多数据挖掘方面的书，那么可以给他推荐机器学习或者模式识别方面的书。</p>
<p>还有一种方法就是使用隐语义模型，可以对书和物品的兴趣进行分类。对于某个用户，首先得到他的兴趣分类，然后从分类中挑选他可能喜欢的物品。</p>
<a id="more"></a>
<h3 id="2-模型理解"><a href="#2-模型理解" class="headerlink" title="2 模型理解"></a>2 模型理解</h3><ol>
<li>如何给物品进行分类？</li>
<li>如何确定用户对哪些类的物品感兴趣，以及感兴趣的程度？</li>
<li>对于一个给定的类，选择哪些属于这个类的物品推荐给用户，以及如何确定这些物品在一个类中的权重？</li>
</ol>
<p>为了解决上面的问题，研究人员提出：为什么我们不从数据出发，自动地找到那些类，然后进行个性化推荐，隐语义分析技术因为采取基于用户行为统计的自动聚类，较好地解决了上面的问题。隐语义分析技术从诞生到今天产生了很多著名的模型和方法，其中和推荐技术相关的有pLSA，LDA，隐含类别模型（latent class model）, 隐含主题模型（latent topic model）, 矩阵分解（matrix factorization）。</p>
<p>LFM通过如下公式计算用户 u 对物品 i 的兴趣：</p>
<p><img src="https://camo.githubusercontent.com/7f94ca282d949c428b6c6021803daa14f88d61fb/68747470733a2f2f6c617465782e636f6465636f67732e636f6d2f6769662e6c617465783f707265666572656e636528752c69293d725f25374275692537443d705f7525354554715f693d25354373756d5f253742663d3125374425354546705f253742752c6b253744715f253742692c6b253744" alt="img"></p>
<p>这个公式中 $p_{u,k}$ 和 $q_{i,k}$ 是模型的参数，其中 $p_{u,k}$  度量了用户 u 的兴趣和第 k 个隐类的关系，而 $q_{i,k}$  度量了第 k 个隐类和物品 i 之间的关系。那么，下面的问题就是如何计算这两个参数。</p>
<p>对最优化理论或者机器学习有所了解的读者，可能对如何计算这两个参数都比较清楚。这两个参数是从数据集中计算出来的。要计算这两个参数，需要一个训练集，对于每个用户u，训练集里都包含了用户u喜欢的物品和不感兴趣的物品，通过学习这个数据集，就可以获得上面的模型参数。</p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习相关资料</title>
    <url>/2020/07/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://createmomo.github.io/2018/01/23/Super-Machine-Learning-Revision-Notes/" target="_blank" rel="noopener">Super Machine Learning Revision Notes</a></p>
<p>总结了机器学习的一系列基本概念，算法等。</p>
<p>分为激活函数，梯度下降，参数，正则化，模型，实用窍门等几大板块。</p>
<hr>
<p><a href="https://yuanxiaosc.github.io/2019/08/16/机器学习中的常识性问题/" target="_blank" rel="noopener">机器学习中的常识性问题</a></p>
<p><img src="/2020/07/28/机器学习相关资料/1595861323230.png" alt="1595861323230"></p>
<a id="more"></a>
<hr>
<p>ds-cheatsheets</p>
<p><a href="https://github.com/FavioVazquez/ds-cheatsheets" target="_blank" rel="noopener">https://github.com/FavioVazquez/ds-cheatsheets</a></p>
<p>各种cheatsheet，关于python, R, big data, machine learning, deep learning, SQL, data visulization等等。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习相关资料</title>
    <url>/2020/07/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>吴恩达深度学习coursera课程笔记：</p>
<p><a href="https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng" target="_blank" rel="noopener">https://www.slideshare.net/TessFerrandez/notes-from-coursera-deep-learning-courses-by-andrew-ng</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/152362317" target="_blank" rel="noopener">22张深度学习精炼图笔记总结</a></p>
<p>内容包含深度学习基础、卷积网络和循环网络等。</p>
<hr>
<p>ML-NLP</p>
<p><a href="https://github.com/NLP-LOVE/ML-NLP" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP</a></p>
<p>包含机器学习，深度学习，NLP等内容及代码实现。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
        <tag>深度学习</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树</title>
    <url>/2020/07/25/%E5%86%B3%E7%AD%96%E6%A0%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>（注：更多关于Boosting系列算法可见OneNote）</p>
<p><img src="/2020/07/25/决策树/1595649034648.png" alt="1595649034648"></p>
<p><img src="/2020/07/25/决策树/1595649090585.png" alt="1595649090585"></p>
<p><img src="/2020/07/25/决策树/1595649112772.png" alt="1595649112772"></p>
<p><img src="/2020/07/25/决策树/1595649135709.png" alt="1595649135709"></p>
<p>信息增益，信息增益率 -&gt; 选最大</p>
<p>基尼系数 -&gt; 选最小</p>
<hr>
<blockquote>
<p>以下内容来源于公众号Datawhale</p>
<p><a href="https://mp.weixin.qq.com/s/jj3BtmnWRAwCS56ZU3ZXZA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/jj3BtmnWRAwCS56ZU3ZXZA</a></p>
</blockquote>
<h2 id="篇一：决策树-（ID3-C4-5-CART）"><a href="#篇一：决策树-（ID3-C4-5-CART）" class="headerlink" title="篇一：决策树 （ID3, C4.5, CART）"></a>篇一：决策树 （ID3, C4.5, CART）</h2><h3 id="ID3"><a href="#ID3" class="headerlink" title="ID3"></a>ID3</h3><p>ID3 算法是建立在奥卡姆剃刀（用较少的东西，同样可以做好事情）的基础上：越是小型的决策树越优于大的决策树。</p>
<h4 id="1-1-思想"><a href="#1-1-思想" class="headerlink" title="1.1 思想"></a>1.1 思想</h4><p>从信息论的知识中我们知道：期望信息越小，信息熵越大，从而样本纯度越低。ID3 算法的核心思想就是以信息增益来度量特征选择，<strong>选择<span style="color:red">信息增益</span>最大的特征进行分裂</strong>。算法采用自顶向下的贪婪搜索遍历可能的决策树空间（C4.5 也是贪婪搜索）。</p>
<p>其大致步骤为：</p>
<ol>
<li>初始化特征集合和数据集合；</li>
<li>计算数据集合信息熵和所有特征的条件熵，选择信息增益最大的特征作为当前决策节点；</li>
<li>更新数据集合和特征集合（删除上一步使用的特征，并按照特征值来划分不同分支的数据集合）；</li>
<li>重复 2，3 两步，若子集值包含单一特征，则为分支叶子节点。</li>
</ol>
<h4 id="1-2-划分标准"><a href="#1-2-划分标准" class="headerlink" title="1.2 划分标准"></a>1.2 划分标准</h4><p>ID3 使用的分类标准是信息增益，它表示得知特征 A 的信息而使得样本集合不确定性减少的程度。</p>
<p><img src="/2020/07/25/决策树/1595649657475.png" alt="1595649657475"></p>
<p><strong>信息增益越大表示使用特征 A 来划分所获得的“纯度提升越大”。</strong></p>
<h4 id="1-3-缺点"><a href="#1-3-缺点" class="headerlink" title="1.3 缺点"></a>1.3 缺点</h4><ul>
<li>ID3 没有剪枝策略，容易过拟合；</li>
<li>信息增益准则对可取值数目较多的特征有所偏好，类似“编号”的特征其信息增益接近于 1（但实际上这并不是一个好的特征选择）；</li>
<li>只能用于处理离散分布的特征；</li>
<li>没有考虑缺失值。</li>
</ul>
<h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h3><p><strong>C4.5 算法最大的特点是克服了 ID3 对特征数目的偏重这一缺点</strong>，引入<strong><span style="color:red">信息增益率</span></strong>来作为分类标准。</p>
<h4 id="2-1-思想"><a href="#2-1-思想" class="headerlink" title="2.1 思想"></a>2.1 思想</h4><p>C4.5 相对于 ID3 的缺点对应有以下改进方式：</p>
<ul>
<li><p>引入悲观剪枝策略进行后剪枝；</p>
</li>
<li><p>引入信息增益率作为划分标准；</p>
</li>
<li><p>将连续特征离散化，假设 n 个样本的连续特征 A 有 m 个取值，C4.5 将其排序并取相邻两样本值的平均数共 m-1 个划分点，分别计算以该划分点作为二元分类点时的信息增益，并选择信息增益最大的点作为该连续特征的二元离散分类点；</p>
</li>
<li><p>对于缺失值的处理可以分为两个子问题：1. 在特征值缺失的情况下进行划分特征的选择？（即如何计算特征的信息增益率）2. 选定该划分特征，对于缺失该特征值的样本如何处理？（即到底把这个样本划分到哪个结点里）</p>
</li>
<li><ul>
<li>针对问题一，C4.5 的做法是：对于具有缺失值特征，用没有缺失的样本子集所占比重来折算；</li>
<li>针对问题二，C4.5 的做法是：将样本同时划分到所有子节点，不过要调整样本的权重值，其实也就是以不同概率划分到不同节点中。</li>
</ul>
</li>
</ul>
<h4 id="2-2-划分标准"><a href="#2-2-划分标准" class="headerlink" title="2.2 划分标准"></a>2.2 划分标准</h4><p><img src="/2020/07/25/决策树/1595650023450.png" alt="1595650023450"></p>
<p>这里需要注意，信息增益率对可取值较少的特征有所偏好（分母越小，整体越大），因此 C4.5 并不是直接用增益率最大的特征进行划分，而是使用一个<em>启发式方法</em>：先从候选划分特征中找到信息增益高于平均值的特征，再从中选择增益率最高的。</p>
<h4 id="2-3-剪枝策略"><a href="#2-3-剪枝策略" class="headerlink" title="2.3 剪枝策略"></a>2.3 剪枝策略</h4><p>为什么要剪枝：过拟合的树在泛化能力的表现非常差。</p>
<h5 id="2-3-1-预剪枝"><a href="#2-3-1-预剪枝" class="headerlink" title="2.3.1 预剪枝"></a>2.3.1 预剪枝</h5><p>在节点划分前来确定是否继续增长，及早停止增长的主要方法有：</p>
<ul>
<li>节点内数据样本低于某一阈值；</li>
<li>所有节点特征都已分裂；</li>
<li>节点划分前准确率比划分后准确率高。</li>
</ul>
<p>预剪枝不仅可以降低过拟合的风险而且还可以减少训练时间，但另一方面它是基于“贪心”策略，会带来欠拟合风险。</p>
<h5 id="2-3-2-后剪枝"><a href="#2-3-2-后剪枝" class="headerlink" title="2.3.2 后剪枝"></a>2.3.2 后剪枝</h5><p>在已经生成的决策树上进行剪枝，从而得到简化版的剪枝决策树。</p>
<p><strong>C4.5 采用的悲观剪枝方法</strong>，用递归的方式从低往上针对每一个非叶子节点，评估用一个最佳叶子节点去代替这课子树是否有益。如果剪枝后与剪枝前相比其错误率是保持或者下降，则这棵子树就可以被替换掉。C4.5 通过训练数据集上的错误分类数量来估算未知样本上的错误率。</p>
<p>后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但同时其训练时间会大的多。</p>
<h4 id="2-4-缺点"><a href="#2-4-缺点" class="headerlink" title="2.4 缺点"></a>2.4 缺点</h4><ul>
<li>剪枝策略可以再优化；</li>
<li>C4.5 用的是多叉树，用二叉树效率更高；</li>
<li>C4.5 只能用于分类；</li>
<li>C4.5 使用的熵模型拥有大量耗时的对数运算，连续值还有排序运算；</li>
<li>C4.5 在构造树的过程中，对数值属性值需要按照其大小进行排序，从中选择一个分割点，所以只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时，程序无法运行。</li>
</ul>
<h3 id="CART"><a href="#CART" class="headerlink" title="CART"></a>CART</h3><p>ID3 和 C4.5 虽然在对训练样本集的学习中可以尽可能多地挖掘信息，但是其生成的决策树分支、规模都比较大，CART 算法的二分法可以简化决策树的规模，提高生成决策树的效率。</p>
<h4 id="3-1-思想"><a href="#3-1-思想" class="headerlink" title="3.1 思想"></a>3.1 思想</h4><p>CART 包含的基本过程有分裂，剪枝和树选择。</p>
<ul>
<li><strong>分裂</strong>：分裂过程是一个二叉递归划分过程，其输入和预测特征既可以是连续型的也可以是离散型的，CART 没有停止准则，会一直生长下去；</li>
<li><strong>剪枝</strong>：<strong>采用<em>代价复杂度剪枝</em></strong>，从最大树开始，每次选择训练数据熵对整体性能贡献最小的那个分裂节点作为下一个剪枝对象，直到只剩下根节点。CART 会产生一系列嵌套的剪枝树，需要从中选出一颗最优的决策树；</li>
<li><strong>树选择</strong>：用单独的测试集评估每棵剪枝树的预测性能（也可以用交叉验证）。</li>
</ul>
<p>CART 在 C4.5 的基础上进行了很多提升。</p>
<ul>
<li>C4.5 为多叉树，运算速度慢，CART 为二叉树，运算速度快；</li>
<li>C4.5 只能分类，CART 既可以分类也可以回归；</li>
<li>CART 使用 <strong><span style="color:red">Gini 系数</span></strong>作为变量的不纯度量，减少了大量的对数运算；</li>
<li>CART 采用代理测试来估计缺失值，而 C4.5 以不同概率划分到不同节点中；</li>
<li>CART 采用“基于代价复杂度剪枝”方法进行剪枝，而 C4.5 采用悲观剪枝方法。</li>
</ul>
<h4 id="3-2-划分标准"><a href="#3-2-划分标准" class="headerlink" title="3.2 划分标准"></a>3.2 划分标准</h4><p>熵模型拥有大量耗时的对数运算，基尼指数在简化模型的同时还保留了熵模型的优点。<strong>基尼指数代表了模型的不纯度，基尼系数越小，不纯度越低，特征越好。这和信息增益（率）正好相反。</strong></p>
<p><img src="/2020/07/25/决策树/1595650557293.png" alt="1595650557293"></p>
<p><img src="/2020/07/25/决策树/1595650609697.png" alt="1595650609697"></p>
<h4 id="3-3-缺失值处理"><a href="#3-3-缺失值处理" class="headerlink" title="3.3 缺失值处理"></a>3.3 缺失值处理</h4><p>上文说到，模型对于缺失值的处理会分为两个子问题：1. 在特征值缺失的情况下进行划分特征的选择？2. 选定该划分特征，对于缺失该特征值的样本如何处理？</p>
<p>对于问题 1，CART 一开始严格要求分裂特征评估时只能使用在该特征上没有缺失值的那部分数据，在后续版本中，CART 算法使用了一种惩罚机制来抑制提升值，从而反映出缺失值的影响（例如，如果一个特征在节点的 20% 的记录是缺失的，那么这个特征就会减少 20% 或者其他数值）。</p>
<p>对于问题 2，CART 算法的机制是为树的每个节点都找到代理分裂器，无论在训练数据上得到的树是否有缺失值都会这样做。在代理分裂器中，特征的分值必须超过默认规则的性能才有资格作为代理（即代理就是代替缺失值特征作为划分特征的特征），当 CART 树中遇到缺失值时，这个实例划分到左边还是右边是决定于其排名最高的代理，如果这个代理的值也缺失了，那么就使用排名第二的代理，以此类推，如果所有代理值都缺失，那么默认规则就是把样本划分到较大的那个子节点。代理分裂器可以确保无缺失训练数据上得到的树可以用来处理包含确实值的新数据。</p>
<h4 id="3-4-剪枝策略"><a href="#3-4-剪枝策略" class="headerlink" title="3.4 剪枝策略"></a>3.4 剪枝策略</h4><p>采用一种“基于代价复杂度的剪枝”方法进行后剪枝，这种方法会生成一系列树，每个树都是通过将前面的树的某个或某些子树替换成一个叶节点而得到的，这一系列树中的最后一棵树仅含一个用来预测类别的叶节点。然后用一种成本复杂度的度量准则来判断哪棵子树应该被一个预测类别值的叶节点所代替。这种方法需要使用一个单独的测试数据集来评估所有的树，根据它们在测试数据集熵的分类性能选出最佳的树。</p>
<p>我们来看具体看一下代价复杂度剪枝算法：</p>
<p><img src="/2020/07/25/决策树/1595650752017.png" alt="1595650752017"></p>
<p><img src="/2020/07/25/决策树/1595650778439.png" alt="1595650778439"></p>
<h4 id="3-5-类别不平衡"><a href="#3-5-类别不平衡" class="headerlink" title="3.5 类别不平衡"></a>3.5 类别不平衡</h4><p>CART 的一大优势在于：无论训练数据集有多失衡，它都可以将其自动消除不需要建模人员采取其他操作。</p>
<p>CART 使用了一种先验机制，其作用相当于对类别进行加权。这种先验机制嵌入于 CART 算法判断分裂优劣的运算里，在 CART 默认的分类模式中，总是要计算每个节点关于根节点的类别频率的比值，这就相当于对数据自动重加权，对类别进行均衡。</p>
<p><img src="/2020/07/25/决策树/1595650963697.png" alt="1595650963697"></p>
<p>通过这种计算方式就无需管理数据真实的类别分布。假设有 K 个目标类别，就可以确保根节点中每个类别的概率都是 1/K。这种默认的模式被称为“先验相等”。</p>
<p>先验设置和加权不同之处在于先验不影响每个节点中的各类别样本的数量或者份额。先验影响的是每个节点的类别赋值和树生长过程中分裂的选择。</p>
<h4 id="3-6-回归树"><a href="#3-6-回归树" class="headerlink" title="3.6 回归树"></a>3.6 回归树</h4><p>CART(Classification and Regression Tree，分类回归树)，从名字就可以看出其不仅可以用于分类，也可以应用于回归。其回归树的建立算法上与分类树部分相似，这里简单介绍下不同之处。</p>
<h5 id="3-6-1-连续值处理"><a href="#3-6-1-连续值处理" class="headerlink" title="3.6.1 连续值处理"></a>3.6.1 连续值处理</h5><p>对于连续值的处理，CART 分类树采用基尼系数的大小来度量特征的各个划分点。在回归模型中，我们使用常见的和方差度量方式，对于任意划分特征 A，对应的任意划分点 s 两边划分成的数据集$D_1$和 $D_2$，求出使$D_1$和$D_2$ 各自集合的均方差最小，同时$D_1$和$D_2$ 的均方差之和最小所对应的特征和特征值划分点。表达式为：</p>
<p><img src="/2020/07/25/决策树/1595651148743.png" alt="1595651148743"></p>
<p>其中， $c_1$为 $D_1$ 数据集的样本输出均值， $c_2$为 $D_2$ 数据集的样本输出均值。</p>
<h5 id="3-6-2-预测方式"><a href="#3-6-2-预测方式" class="headerlink" title="3.6.2 预测方式"></a>3.6.2 预测方式</h5><p>对于决策树建立后做预测的方式，上面讲到了 CART 分类树采用叶子节点里概率最大的类别作为当前节点的预测类别。而回归树输出不是类别，它采用的是用最终叶子的均值或者中位数来预测输出结果。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>最后通过总结的方式对比下 ID3、C4.5 和 CART 三者之间的差异。</p>
<ul>
<li><strong>划分标准的差异</strong>：ID3 使用信息增益偏向特征值多的特征，C4.5 使用信息增益率克服信息增益的缺点，偏向于可取值较少的特征，CART 使用基尼指数克服 C4.5 需要求 log 的巨大计算量，偏向于特征值较多的特征。</li>
<li><strong>使用场景的差异</strong>：ID3 和 C4.5 都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5 是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li>
<li><strong>样本数据的差异</strong>：ID3 只能处理离散数据且缺失值敏感，C4.5 和 CART 可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议 C4.5、大样本建议 CART。C4.5 处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART 本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li>
<li><strong>样本特征的差异</strong>：ID3 和 C4.5 层级之间只使用一次特征，CART 可多次重复使用特征；</li>
<li><strong>剪枝策略的差异</strong>：ID3 没有剪枝策略，C4.5 是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li>
</ul>
<hr>
<blockquote>
<p>以下内容来源于公众号Datawhale</p>
<p><a href="https://mp.weixin.qq.com/s/Nl_-PdF0nHBq8yGp6AdI-Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/Nl_-PdF0nHBq8yGp6AdI-Q</a></p>
</blockquote>
<h2 id="篇二：Random-Forest-Adaboost-GBDT算法"><a href="#篇二：Random-Forest-Adaboost-GBDT算法" class="headerlink" title="篇二：Random Forest, Adaboost, GBDT算法"></a>篇二：Random Forest, Adaboost, GBDT算法</h2><p>主要介绍基于集成学习的决策树，其主要通过不同学习框架生产基学习器（base learners），并综合所有基学习器的预测结果来改善单个基学习器的识别率和泛化性。</p>
<h3 id="集成学习"><a href="#集成学习" class="headerlink" title="集成学习"></a>集成学习</h3><p>常见的集成学习框架有三种：Bagging，Boosting 和 Stacking。</p>
<h4 id="1-1-Bagging"><a href="#1-1-Bagging" class="headerlink" title="1.1 Bagging"></a>1.1 Bagging</h4><p>Bagging 全称叫 Bootstrap aggregating，看到 Bootstrap 我们立刻想到著名的开源前端框架（抖个机灵，是 Bootstrap 抽样方法） ，每个基学习器都会对训练集进行<strong>有放回抽样</strong>得到子训练集，比较著名的采样法为 0.632 自助法。每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。Bagging 常用的综合方法是投票法，票数最多的类别为预测类别。</p>
<p><img src="/2020/07/25/决策树/1595652338160.png" alt="1595652338160"></p>
<h4 id="1-2-Boosting"><a href="#1-2-Boosting" class="headerlink" title="1.2 Boosting"></a>1.2 Boosting</h4><p>Boosting 训练过程为阶梯状，<strong>基模型的训练是有顺序的，每个基模型都会在前一个基模型学习的基础上进行学习</strong>，最终综合所有基模型的预测值产生最终的预测结果，用的比较多的综合方式为加权法。</p>
<p><img src="/2020/07/25/决策树/1595652444294.png" alt="1595652444294"></p>
<h4 id="1-3-Stacking"><a href="#1-3-Stacking" class="headerlink" title="1.3 Stacking"></a>1.3 Stacking</h4><p>Stacking 是先用全部数据训练好基模型，然后每个基模型都对每个训练样本进行预测，其预测值将作为训练样本的特征值，最终会得到新的训练样本，然后基于新的训练样本进行训练得到模型，然后得到最终预测结果。</p>
<blockquote>
<p>为什么集成学习会好于单个学习器呢？原因可能有三：</p>
<ol>
<li>训练样本可能无法选择出最好的单个学习器，由于没法选择出最好的学习器，所以干脆结合起来一起用；</li>
<li>假设能找到最好的学习器，但由于算法运算的限制无法找到最优解，只能找到次优解，采用集成学习可以弥补算法的不足；</li>
<li>可能算法无法得到最优解，而集成学习能够得到近似解。比如说最优解是一条对角线，而单个决策树得到的结果只能是平行于坐标轴的，但是集成学习可以去拟合这条对角线。</li>
</ol>
</blockquote>
<h3 id="偏差与方差"><a href="#偏差与方差" class="headerlink" title="偏差与方差"></a>偏差与方差</h3><p>如何从偏差和方差的角度来理解集成学习。</p>
<h4 id="2-1-集成学习的偏差与方差"><a href="#2-1-集成学习的偏差与方差" class="headerlink" title="2.1 集成学习的偏差与方差"></a>2.1 集成学习的偏差与方差</h4><p><strong>偏差（Bias）描述的是预测值和真实值之差；方差（Variance）描述的是预测值作为随机变量的离散程度。</strong>放一场很经典的图：</p>
<p><img src="/2020/07/25/决策树/1595652870653.png" alt="1595652870653"></p>
<p>模型的偏差与方差</p>
<ul>
<li><strong>偏差</strong>：描述样本拟合出的模型的预测结果的期望与样本真实结果的差距，要想偏差表现的好，就需要复杂化模型，增加模型的参数，但这样容易过拟合，过拟合对应上图的 High Variance，点会很分散。低偏差对应的点都打在靶心附近，所以喵的很准，但不一定很稳；</li>
<li><strong>方差</strong>：描述样本上训练出来的模型在测试集上的表现，要想方差表现的好，需要简化模型，减少模型的复杂度，但这样容易欠拟合，欠拟合对应上图 High Bias，点偏离中心。低方差对应就是点都打的很集中，但不一定是靶心附近，手很稳，但不一定瞄的准。</li>
</ul>
<p>我们常说集成学习中的基模型是弱模型，通常来说弱模型是偏差高（在训练集上准确度低）方差小（防止过拟合能力强）的模型。但是，并不是所有集成学习框架中的基模型都是弱模型。<strong>Bagging 和 Stacking 中的基模型为强模型（偏差低方差高），Boosting 中的基模型为弱模型</strong>。</p>
<p><img src="/2020/07/25/决策树/1595653661803.png" alt="1595653661803"></p>
<h4 id="2-2-Bagging-的偏差与方差"><a href="#2-2-Bagging-的偏差与方差" class="headerlink" title="2.2 Bagging 的偏差与方差"></a>2.2 Bagging 的偏差与方差</h4><p><img src="/2020/07/25/决策树/1595653718100.png" alt="1595653718100"></p>
<p>在此我们知道了为什么 Bagging 中的基模型一定要为强模型，如果 Bagging 使用弱模型则会导致整体模型的偏差提高，而准确度降低。</p>
<p>Random Forest 是经典的基于 Bagging 框架的模型，并在此基础上通过引入特征采样和样本采样来降低基模型间的相关性，在公式中显著降低方差公式中的第二项，略微升高第一项，从而使得整体降低模型整体方差。</p>
<h4 id="2-3-Boosting-的偏差与方差"><a href="#2-3-Boosting-的偏差与方差" class="headerlink" title="2.3 Boosting 的偏差与方差"></a>2.3 Boosting 的偏差与方差</h4><p><img src="/2020/07/25/决策树/1595653801559.png" alt="1595653801559"></p>
<p>基于 Boosting 框架的 Gradient Boosting Decision Tree 模型中基模型也为树模型，同 Random Forest，我们也可以对特征进行随机抽样来使基模型间的相关性降低，从而达到减少方差的效果。</p>
<h4 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4 小结"></a>2.4 小结</h4><ul>
<li>我们可以使用模型的偏差和方差来近似描述模型的准确度；</li>
<li>对于 Bagging 来说，整体模型的偏差与基模型近似，而随着模型的增加可以降低整体模型的方差，故其基模型需要为强模型；</li>
<li>对于 Boosting 来说，整体模型的方差近似等于基模型的方差，而整体模型的偏差由基模型累加而成，故基模型需要为弱模型。</li>
</ul>
<h3 id="Random-Forest"><a href="#Random-Forest" class="headerlink" title="Random Forest"></a>Random Forest</h3><p>RF 算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。</p>
<h4 id="3-1-思想-1"><a href="#3-1-思想-1" class="headerlink" title="3.1 思想"></a>3.1 思想</h4><p>Random Forest（随机森林）是 Bagging 的扩展变体，它在以决策树为基学习器构建 Bagging 集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括 RF 包括四个部分：</p>
<ol>
<li>随机选择样本（有放回抽样）；</li>
<li>随机选择特征；</li>
<li>构建决策树；</li>
<li>随机森林投票（平均）。</li>
</ol>
<p>随机选择样本和 Bagging 相同，采用的是 Bootstrap 自助采样法；随机选择特征是指在每个节点在分裂过程中都是随机选择特征的（区别与每棵树随机选择一批特征）。</p>
<p>这种随机性导致随机森林的偏差会有稍微的增加（相比于单棵不随机树），但是由于随机森林的“平均”特性，会使得它的方差减小，而且方差的减小补偿了偏差的增大，因此总体而言是更好的模型。</p>
<p>随机采样由于引入了两种采样方法保证了随机性，所以每棵树都是最大可能的进行生长就算不剪枝也不会出现过拟合。</p>
<h4 id="3-2-优缺点"><a href="#3-2-优缺点" class="headerlink" title="3.2 优缺点"></a>3.2 优缺点</h4><p>优点</p>
<ol>
<li>在数据集上表现良好，相对于其他算法有较大的优势</li>
<li>易于并行化，在大数据集上有很大的优势；</li>
<li>能够处理高维度数据，不用做特征选择。</li>
</ol>
<h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>AdaBoost（Adaptive Boosting，自适应增强），其自适应在于：前一个基本分类器分错的样本会得到加强，加权后的全体样本再次被用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。</p>
<h4 id="4-1-思想"><a href="#4-1-思想" class="headerlink" title="4.1 思想"></a>4.1 思想</h4><p>Adaboost 迭代算法有三步：</p>
<ol>
<li>初始化训练样本的权值分布，每个样本具有相同权重；</li>
<li>训练弱分类器，如果样本分类正确，则在构造下一个训练集中，它的权值就会被降低；反之提高。用更新过的样本集去训练下一个分类器；</li>
<li>将所有弱分类组合成强分类器，各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，降低分类误差率大的弱分类器的权重。</li>
</ol>
<h4 id="4-2-细节"><a href="#4-2-细节" class="headerlink" title="4.2 细节"></a>4.2 细节</h4><h5 id="4-2-1-损失函数"><a href="#4-2-1-损失函数" class="headerlink" title="4.2.1 损失函数"></a>4.2.1 损失函数</h5><p><img src="/2020/07/25/决策树/1595663386859.png" alt="1595663386859"></p>
<p><img src="/2020/07/25/决策树/1595663456133.png" alt="1595663456133"></p>
<p><img src="/2020/07/25/决策树/1595663508910.png" alt="1595663508910"></p>
<h5 id="4-2-2-正则化"><a href="#4-2-2-正则化" class="headerlink" title="4.2.2 正则化"></a>4.2.2 正则化</h5><p><img src="/2020/07/25/决策树/1595663617670.png" alt="1595663617670"></p>
<h4 id="4-3-优缺点"><a href="#4-3-优缺点" class="headerlink" title="4.3 优缺点"></a>4.3 优缺点</h4><p><strong>优点</strong></p>
<ol>
<li>分类精度高；</li>
<li>可以用各种回归分类模型来构建弱学习器，非常灵活；</li>
<li>不容易发生过拟合。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>对异常点敏感，异常点会获得较高权重。</li>
</ol>
<p>另：</p>
<p><strong>优点</strong> </p>
<p>（1）Adaboost提供一种框架，在框架内可以使用各种方法构建子分类器。可以使用简单的弱分类器，不用对特征进行筛选，也不存在过拟合的现象。 </p>
<p>（2）Adaboost算法不需要弱分类器的先验知识，最后得到的强分类器的分类精度依赖于所有弱分类器。无论是应用于人造数据还是真实数据，Adaboost都能显著的提高学习精度。 </p>
<p>（3）Adaboost算法不需要预先知道弱分类器的错误率上限，且最后得到的强分类器的分类精度依赖于所有弱分类器的分类精度，可以深挖分类器的能力。Adaboost可以根据弱分类器的反馈，自适应地调整假定的错误率，执行的效率高。 </p>
<p>（4）Adaboost可以在不改变训练数据，只改变数据权值分布，使得数据在不同学习器中产生不同作用，类似于重采样。 </p>
<p><strong>缺点</strong> </p>
<p>​     在Adaboost训练过程中，Adaboost会使得难于分类样本的权值呈指数增长，训练将会过于偏向这类困难的样本，导致Adaboost算法易受噪声干扰。此外，Adaboost依赖于弱分类器，而弱分类器的训练时间往往很长。</p>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>GBDT（Gradient Boosting Decision Tree）是一种迭代的决策树算法，该算法由多棵决策树组成，从名字中我们可以看出来它是属于 Boosting 策略。GBDT 是被公认的泛化能力较强的算法。</p>
<h4 id="5-1-思想"><a href="#5-1-思想" class="headerlink" title="5.1 思想"></a>5.1 思想</h4><p>GBDT 由三个概念组成：Regression Decision Tree（即 DT）、Gradient Boosting（即 GB），和SHringkage（一个重要演变）</p>
<h5 id="5-1-1-回归树（Regression-Decision-Tree）"><a href="#5-1-1-回归树（Regression-Decision-Tree）" class="headerlink" title="5.1.1 回归树（Regression Decision Tree）"></a>5.1.1 回归树（Regression Decision Tree）</h5><p>如果认为 GBDT 由很多分类树那就大错特错了（虽然调整后也可以分类）。对于分类树而言，其值加减无意义（如性别），而对于回归树而言，其值加减才是有意义的（如说年龄）。<strong>GBDT 的核心在于累加所有树的结果作为最终结果</strong>，所以 <strong><span style="color:red">GBDT 中的树都是回归树</span></strong>，不是分类树，这一点相当重要。</p>
<p>回归树在分枝时会穷举每一个特征的每个阈值以找到最好的分割点，衡量标准是最小化均方误差。</p>
<h5 id="5-1-2-梯度迭代（Gradient-Boosting）"><a href="#5-1-2-梯度迭代（Gradient-Boosting）" class="headerlink" title="5.1.2 梯度迭代（Gradient Boosting）"></a>5.1.2 梯度迭代（Gradient Boosting）</h5><p>上面说到 GBDT 的核心在于累加所有树的结果作为最终结果，<strong>GBDT 的每一棵树都是以之前树得到的残差来更新目标值，这样每一棵树的值加起来即为 GBDT 的预测值</strong>。</p>
<p><img src="/2020/07/25/决策树/1595667008154.png" alt="1595667008154"></p>
<blockquote>
<p>举个例子：比如说 A 用户年龄 20 岁，第一棵树预测 12 岁，那么残差就是 8，第二棵树用 8 来学习，假设其预测为 5，那么其残差即为 3，如此继续学习即可。</p>
</blockquote>
<p><img src="/2020/07/25/决策树/1595667099649.png" alt="1595667099649"></p>
<p><img src="/2020/07/25/决策树/1595667123278.png" alt="1595667123278"></p>
<p><img src="/2020/07/25/决策树/1595667175530.png" alt="1595667175530"></p>
<p>GBDT 的 Boosting 不同于 Adaboost 的 Boosting，GBDT 的每一步残差计算其实变相地增大了被分错样本的权重，而对与分对样本的权重趋于 0，这样后面的树就能专注于那些被分错的样本。</p>
<h5 id="5-1-13-缩减（Shrinkage）"><a href="#5-1-13-缩减（Shrinkage）" class="headerlink" title="5.1.13 缩减（Shrinkage）"></a>5.1.13 缩减（Shrinkage）</h5><p>Shrinkage 的思想认为，每走一小步逐渐逼近结果的效果要比每次迈一大步很快逼近结果的方式更容易避免过拟合。即它并不是完全信任每一棵残差树。</p>
<p><img src="/2020/07/25/决策树/1595667249030.png" alt="1595667249030"></p>
<p>Shrinkage 不直接用残差修复误差，而是只修复一点点，把大步切成小步。本质上 Shrinkage 为每棵树设置了一个 weight，累加时要乘以这个 weight，当 weight 降低时，基模型数会配合增大。</p>
<h4 id="5-2-优缺点"><a href="#5-2-优缺点" class="headerlink" title="5.2 优缺点"></a>5.2 优缺点</h4><p><strong>优点</strong></p>
<ol>
<li>可以自动进行特征组合，拟合非线性数据；</li>
<li>可以灵活处理各种类型的数据。</li>
</ol>
<p><strong>缺点</strong></p>
<ol>
<li>对异常点敏感。</li>
</ol>
<p>另：</p>
<p><img src="/2020/07/25/决策树/1595669502617.png" alt="1595669502617"></p>
<p><img src="/2020/07/25/决策树/1595669541744.png" alt="1595669541744"></p>
<h4 id="5-3-与-Adaboost-的对比"><a href="#5-3-与-Adaboost-的对比" class="headerlink" title="5.3 与 Adaboost 的对比"></a>5.3 与 Adaboost 的对比</h4><p>相同：</p>
<ol>
<li>都是 Boosting 家族成员，使用弱分类器；</li>
<li>都使用前向分布算法；</li>
</ol>
<p>不同：</p>
<ol>
<li>迭代思路不同：Adaboost 是通过提升错分数据点的权重来弥补模型的不足（利用错分样本），而 GBDT 是通过算梯度来弥补模型的不足（利用残差）；</li>
<li>损失函数不同：AdaBoost 采用的是指数损失，GBDT 使用的是绝对损失或者 Huber 损失函数；</li>
</ol>
<hr>
<blockquote>
<p>以下内容来源于公众号Datawhale</p>
<p><a href="https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/LoX987dypDg8jbeTJMpEPQ</a></p>
</blockquote>
<h2 id="篇三：XGBoost"><a href="#篇三：XGBoost" class="headerlink" title="篇三：XGBoost"></a>篇三：XGBoost</h2><p><img src="/2020/07/25/决策树/1595667573239.png" alt="1595667573239"></p>
<p>（注：以下内容只包含XGBoost部分，LightGBM部分可见原文链接）</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p>XGBoost 是大规模并行 boosting tree 的工具，它是目前最快最好的开源 boosting tree 工具包，比常见的工具包快 10 倍以上。Xgboost 和 GBDT 两者都是 boosting 方法，除了工程实现、解决问题上的一些差异外，最大的不同就是目标函数的定义。</p>
<h4 id="1-1-数学原理"><a href="#1-1-数学原理" class="headerlink" title="1.1 数学原理"></a>1.1 数学原理</h4><h5 id="1-1-1-目标函数"><a href="#1-1-1-目标函数" class="headerlink" title="1.1.1 目标函数"></a>1.1.1 目标函数</h5><p><img src="/2020/07/25/决策树/1595667719081.png" alt="1595667719081"></p>
<p><img src="/2020/07/25/决策树/1595667791401.png" alt="1595667791401"></p>
<p><img src="/2020/07/25/决策树/1595667837751.png" alt="1595667837751"></p>
<p><img src="/2020/07/25/决策树/1595667861205.png" alt="1595667861205"></p>
<p>$g_i=\frac{\partial\ l(y_i,\hat{y_i}^{(t-1)})}{\partial\,\hat{y_i}^{(t-1)}}$, $h_i=\frac{\partial^2 l(y_i,\hat{y_i}^{(t-1)})}{\partial^2 \hat{y_i}^{(t-1)}}$</p>
<p><img src="/2020/07/25/决策树/1595667888425.png" alt="1595667888425"></p>
<p>又因为有 </p>
<script type="math/tex; mode=display">
\sum_{i=1}^{t} \Omega(f_i)=\Omega(f_t)+\sum_{i=1}^{t-1}\Omega(f_i)</script><p>并且$\sum_{i=1}^{t-1}\Omega(f_i)$在前t-1棵树已知下为常数，所以目标函数可写为：</p>
<script type="math/tex; mode=display">
Obj^{(t)}≈\sum_{i=1}^{n}[g_if_t(x_i)+\frac{1}{2}h_if_t^2(x_i)]+\Omega(f_t)</script><h5 id="1-1-2-基于决策树的目标函数"><a href="#1-1-2-基于决策树的目标函数" class="headerlink" title="1.1.2 基于决策树的目标函数"></a>1.1.2 基于决策树的目标函数</h5><p>我们知道 Xgboost 的基模型不仅支持决策树，还支持线性模型，这里我们主要介绍基于决策树的目标函数。</p>
<p><img src="/2020/07/25/决策树/1595667950419.png" alt="1595667950419"></p>
<hr>
<p>另一种描述：</p>
<blockquote>
<p>参考 <a href="https://mp.weixin.qq.com/s/AAKPSIHk1iUqCeUibrORqQ" target="_blank" rel="noopener">我的XGBoost学习经历及动手实践</a></p>
</blockquote>
<p>现在定义$\Omega(f_t)$：假设我们待训练的第t棵树有T个叶子结点，叶子结点的输出向量表示如下：</p>
<script type="math/tex; mode=display">
[w_1,w_2,...,w_T]</script><p>假设 $q(x):R^d \rightarrow \{1,2,3,…,T\}$ 表示样本到叶子结点的映射，那么$f_t(x)=w_{q(x)},w∈R^T$.那么我们定义：</p>
<script type="math/tex; mode=display">
\Omega(f_t)=\gamma T+\frac{1}{2}\lambda\sum_{j=1}^Tw_j^2</script><p>其中$T$为叶子结点数，$w_j$为叶子结点$j$的输出，$\gamma$为系数。</p>
<hr>
<p><img src="/2020/07/25/决策树/1595667972342.png" alt="1595667972342"></p>
<p><img src="/2020/07/25/决策树/1595667995025.png" alt="1595667995025"></p>
<p><img src="/2020/07/25/决策树/1595668020156.png" alt="1595668020156"></p>
<hr>
<p>另一种描述：</p>
<blockquote>
<p>参考 <a href="https://mp.weixin.qq.com/s/AAKPSIHk1iUqCeUibrORqQ" target="_blank" rel="noopener">我的XGBoost学习经历及动手实践</a></p>
</blockquote>
<p><img src="/2020/07/25/决策树/1595822346216.png" alt="1595822346216"></p>
<hr>
<p><img src="/2020/07/25/决策树/1595668057942.png" alt="1595668057942"></p>
<h5 id="1-1-3-最优切分点划分算法"><a href="#1-1-3-最优切分点划分算法" class="headerlink" title="1.1.3 最优切分点划分算法"></a>1.1.3 最优切分点划分算法</h5><p>我们刚刚的假设前提是已知前t-1棵树，现在我们讨论怎么生成树。根据决策树的生成策略，在每次分裂节点的时候我们需要考虑能使得损失函数减小最快的节点，也就是分裂后损失函数减去分裂前损失函数我们称之为Gain：</p>
<p><img src="/2020/07/25/决策树/1595822888787.png" alt="1595822888787"></p>
<p>Gain越大越能说明分裂后目标函数值减小越多。</p>
<p>如何找到叶子的节点的最优切分点：Xgboost 支持两种分裂节点的方法——贪心算法和近似算法。</p>
<h6 id="1）贪心算法-精确贪心算法-Basic-Exact-Greedy-Algorithm"><a href="#1）贪心算法-精确贪心算法-Basic-Exact-Greedy-Algorithm" class="headerlink" title="1）贪心算法 (精确贪心算法 Basic Exact Greedy Algorithm)"></a>1）贪心算法 (精确贪心算法 Basic Exact Greedy Algorithm)</h6><p>在决策树（CART）里面，我们使用的是精确贪心算法，也就是将所有特征的所有取值排序（耗时耗内存巨大），然后比较每一个点的Gini，找出变化最大的节点。当特征是连续特征时，我们对连续值离散化，取两点的平均值为分割节点。可以看到，这里的排序算法需要花费大量的时间，因为要遍历整个样本所有特征，而且还要排序。</p>
<p>步骤：</p>
<ol>
<li>从深度为 0 的树开始，对每个叶节点枚举所有的可用特征；</li>
<li>针对每个特征，把属于该节点的训练样本根据该特征值进行升序排列，通过线性扫描的方式来决定该特征的最佳分裂点，并记录该特征的分裂收益；</li>
<li>选择收益最大的特征作为分裂特征，用该特征的最佳分裂点作为分裂位置，在该节点上分裂出左右两个新的叶节点，并为每个新节点关联对应的样本集</li>
<li>回到第 1 步，递归执行到满足特定条件为止</li>
</ol>
<p>那么如何计算每个特征的分裂收益呢？</p>
<p><img src="/2020/07/25/决策树/1595668137245.png" alt="1595668137245"></p>
<p><img src="/2020/07/25/决策树/1595668154967.png" alt="1595668154967"></p>
<p><img src="/2020/07/25/决策树/1595823332714.png" alt="1595823332714"></p>
<h6 id="2）近似算法-Approximate-Algorithm"><a href="#2）近似算法-Approximate-Algorithm" class="headerlink" title="2）近似算法 (Approximate Algorithm)"></a>2）近似算法 (Approximate Algorithm)</h6><p>贪婪算法可以得到最优解，但当数据量太大时则无法读入内存进行计算，近似算法主要针对贪婪算法这一缺点给出了近似最优解。</p>
<p>对于每个特征，只考察分位点可以减少计算复杂度。</p>
<p>该算法会首先根据特征分布的分位数提出候选划分点，然后将连续型特征映射到由这些候选点划分的桶中，然后聚合统计信息找到所有区间的最佳分裂点。</p>
<hr>
<p>另一种描述：</p>
<blockquote>
<p>参考 <a href="https://mp.weixin.qq.com/s/AAKPSIHk1iUqCeUibrORqQ" target="_blank" rel="noopener">我的XGBoost学习经历及动手实践</a></p>
</blockquote>
<p>该算法首先根据特征分布的百分位数(percentiles)提出候选分裂点，将连续特征映射到由这些候选点分割的桶中，汇总统计信息并根据汇总的信息在提案中找到最佳解决方案。对于某个特征k，算法首先根据特征分布的分位数找到特征切割点的候选集合$S_k=\{S_{k_1},S_{k_2},…,S_{k_l}\}$ , 然后将特征k的值根据集合$S_k$ 划分到桶(bucket)中，接着对每个桶内的样本统计值G、H进行累加，最后在这些累计的统计量上寻找最佳分裂点。</p>
<hr>
<p>在提出候选切分点时有两种策略：</p>
<ul>
<li>Global：学习每棵树前就提出候选切分点，并在每次分裂时都采用这种分割；</li>
<li>Local：每次分裂前将重新提出候选切分点。</li>
</ul>
<p>直观上来看，Local 策略需要更多的计算步骤，而 Global 策略因为节点没有划分所以需要更多的候选点。</p>
<p>下图给出不同种分裂策略的 AUC 变换曲线，横坐标为迭代次数，纵坐标为测试集 AUC，eps 为近似算法的精度，其倒数为桶的数量。</p>
<p><img src="/2020/07/25/决策树/1595668243451.png" alt="1595668243451"></p>
<p>我们可以看到 Global 策略在候选点数多时（eps 小）可以和 Local 策略在候选点少时（eps 大）具有相似的精度。此外我们还发现，在 eps 取值合理的情况下，分位数策略可以获得与贪婪算法相同的精度。</p>
<p><img src="/2020/07/25/决策树/1595668320876.png" alt="1595668320876"></p>
<p><img src="/2020/07/25/决策树/1595668340241.png" alt="1595668340241"></p>
<h5 id="1-1-4-加权分位数缩略图"><a href="#1-1-4-加权分位数缩略图" class="headerlink" title="1.1.4 加权分位数缩略图"></a>1.1.4 加权分位数缩略图</h5><p><img src="/2020/07/25/决策树/1595668403168.png" alt="1595668403168"></p>
<p><img src="/2020/07/25/决策树/1595668446774.png" alt="1595668446774"></p>
<h5 id="1-1-5-稀疏感知算法"><a href="#1-1-5-稀疏感知算法" class="headerlink" title="1.1.5 稀疏感知算法"></a>1.1.5 稀疏感知算法</h5><p>在决策树的第一篇文章中我们介绍 CART 树在应对数据缺失时的分裂策略，XGBoost 也给出了其解决方案。</p>
<p>XGBoost 在构建树的节点过程中只考虑非缺失值的数据遍历，而为每个节点增加了一个缺省方向，当样本相应的特征值缺失时，可以被归类到缺省方向上，最优的缺省方向可以从数据中学到。至于如何学到缺省值的分支，其实很简单，分别枚举特征缺省的样本归为左右分支后的增益，选择增益最大的枚举项即为最优缺省方向。</p>
<p>在构建树的过程中需要枚举特征缺失的样本，乍一看该算法的计算量增加了一倍，但其实该算法在构建树的过程中只考虑了特征未缺失的样本遍历，而特征值缺失的样本无需遍历只需直接分配到左右节点，故算法所需遍历的样本量减少，下图可以看到稀疏感知算法比 basic 算法速度块了超过 50 倍。</p>
<p><img src="/2020/07/25/决策树/1595668537184.png" alt="1595668537184"></p>
<h4 id="1-2-工程实现"><a href="#1-2-工程实现" class="headerlink" title="1.2 工程实现"></a>1.2 工程实现</h4><h5 id="1-2-1-块结构设计"><a href="#1-2-1-块结构设计" class="headerlink" title="1.2.1 块结构设计"></a>1.2.1 块结构设计</h5><p>我们知道，决策树的学习最耗时的一个步骤就是在每次寻找最佳分裂点是都需要对特征的值进行排序。而 XGBoost 在训练之前对根据特征对数据进行了排序，然后保存到块结构中，并在每个块结构中都采用了稀疏矩阵存储格式（Compressed Sparse Columns Format，CSC）进行存储，后面的训练过程中会重复地使用块结构，可以大大减小计算量。</p>
<ul>
<li>每一个块结构包括一个或多个已经排序好的特征；</li>
<li>缺失特征值将不进行排序；</li>
<li>每个特征会存储指向样本梯度统计值的索引，方便计算一阶导和二阶导数值；</li>
</ul>
<p><img src="/2020/07/25/决策树/1595668680481.png" alt="1595668680481"></p>
<p>这种块结构存储的特征之间相互独立，方便计算机进行并行计算。在对节点进行分裂时需要选择增益最大的特征作为分裂，这时各个特征的增益计算可以同时进行，这也是 Xgboost 能够实现分布式或者多线程计算的原因。</p>
<h5 id="1-2-2-缓存访问优化算法"><a href="#1-2-2-缓存访问优化算法" class="headerlink" title="1.2.2 缓存访问优化算法"></a>1.2.2 缓存访问优化算法</h5><p>块结构的设计可以减少节点分裂时的计算量，但特征值通过索引访问样本梯度统计值的设计会导致访问操作的内存空间不连续，这样会造成缓存命中率低，从而影响到算法的效率。</p>
<p>为了解决缓存命中率低的问题，XGBoost 提出了缓存访问优化算法：为每个线程分配一个连续的缓存区，将需要的梯度信息存放在缓冲区中，这样就是实现了非连续空间到连续空间的转换，提高了算法效率。</p>
<p>此外适当调整块大小，也可以有助于缓存优化。</p>
<h5 id="1-2-3-“核外”块计算"><a href="#1-2-3-“核外”块计算" class="headerlink" title="1.2.3 “核外”块计算"></a>1.2.3 “核外”块计算</h5><p>当数据量过大时无法将数据全部加载到内存中，只能先将无法加载到内存中的数据暂存到硬盘中，直到需要时再进行加载计算，而这种操作必然涉及到因内存与硬盘速度不同而造成的资源浪费和性能瓶颈。为了解决这个问题，XGBoost 独立一个线程专门用于从硬盘读入数据，以实现处理数据和读入数据同时进行。</p>
<p>此外，XGBoost 还用了两种方法来降低硬盘读写的开销：</p>
<ul>
<li>块压缩：对 Block 进行按列压缩，并在读取时进行解压；</li>
<li>块拆分：将每个块存储到不同的磁盘中，从多个磁盘读取可以增加吞吐量。</li>
</ul>
<h4 id="1-3-优缺点"><a href="#1-3-优缺点" class="headerlink" title="1.3 优缺点"></a>1.3 优缺点</h4><h5 id="1-3-1-优点"><a href="#1-3-1-优点" class="headerlink" title="1.3.1 优点"></a>1.3.1 优点</h5><ol>
<li>精度更高：GBDT 只用到一阶泰勒展开，而 XGBoost  对损失函数进行了二阶泰勒展开。XGBoost 引入二阶导一方面是为了增加精度，另一方面也是为了能够自定义损失函数，二阶泰勒展开可以近似大量损失函数；</li>
<li>灵活性更强：GBDT 以 CART 作为基分类器，XGBoost 不仅支持 CART 还支持线性分类器，（使用线性分类器的 XGBoost 相当于带 L1 和 L2 正则化项的Logistic回归（分类问题）或者线性回归（回归问题））。此外，XGBoost 工具支持自定义损失函数，只需函数支持一阶和二阶求导；</li>
<li>正则化：XGBoost 在目标函数中加入了正则项，用于控制模型的复杂度。正则项里包含了树的叶子节点个数、叶子节点权重的 L2 范式。正则项降低了模型的方差，使学习出来的模型更加简单，有助于防止过拟合；</li>
<li>Shrinkage（缩减）：相当于学习速率。XGBoost 在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间；</li>
<li>列抽样：XGBoost 借鉴了随机森林的做法，支持列抽样，不仅能降低过拟合，还能减少计算；</li>
<li>缺失值处理：XGBoost 采用的稀疏感知算法极大的加快了节点分裂的速度；</li>
<li>可以并行化操作：块结构可以很好的支持并行计算。</li>
</ol>
<h5 id="1-3-2-缺点"><a href="#1-3-2-缺点" class="headerlink" title="1.3.2 缺点"></a>1.3.2 缺点</h5><ol>
<li>虽然利用预排序和近似算法可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要遍历数据集；</li>
<li>预排序过程的空间复杂度过高，不仅需要存储特征值，还需要存储特征对应样本的梯度统计值的索引，相当于消耗了两倍的内存。</li>
</ol>
<h3 id="XGBoost动手实践"><a href="#XGBoost动手实践" class="headerlink" title="XGBoost动手实践"></a>XGBoost动手实践</h3><p>本部分内容来源于 <a href="https://mp.weixin.qq.com/s/AAKPSIHk1iUqCeUibrORqQ" target="_blank" rel="noopener">我的XGBoost学习经历及动手实践</a></p>
<h4 id="1-引入基本工具库"><a href="#1-引入基本工具库" class="headerlink" title="1. 引入基本工具库"></a>1. 引入基本工具库</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 引入基本工具库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.style.use(<span class="string">"ggplot"</span>)</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h4 id="2-XGBoost原生工具库的上手"><a href="#2-XGBoost原生工具库的上手" class="headerlink" title="2. XGBoost原生工具库的上手"></a>2. XGBoost原生工具库的上手</h4><p>更详细的参数设置见后面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb  <span class="comment"># 引入工具库</span></span><br><span class="line"><span class="comment"># read in data</span></span><br><span class="line"><span class="comment"># XGBoost的专属数据格式，但是也可以用dataframe或者ndarray</span></span><br><span class="line">dtrain = xgb.DMatrix(<span class="string">'demo/data/agaricus.txt.train'</span>)   </span><br><span class="line">dtest = xgb.DMatrix(<span class="string">'demo/data/agaricus.txt.test'</span>)  </span><br><span class="line"></span><br><span class="line"><span class="comment"># specify parameters via map</span></span><br><span class="line"><span class="comment"># 设置XGB的参数，使用字典形式传入</span></span><br><span class="line">param = &#123;<span class="string">'max_depth'</span>:<span class="number">2</span>, <span class="string">'eta'</span>:<span class="number">1</span>, <span class="string">'objective'</span>:<span class="string">'binary:logistic'</span> &#125;    </span><br><span class="line"></span><br><span class="line">num_round = <span class="number">2</span>     <span class="comment"># 使用线程数</span></span><br><span class="line">bst = xgb.train(param, dtrain, num_round)   <span class="comment"># 训练</span></span><br><span class="line"><span class="comment"># make prediction</span></span><br><span class="line">preds = bst.predict(dtest)   <span class="comment"># 预测</span></span><br></pre></td></tr></table></figure>
<h4 id="3-XGBoost的参数设置"><a href="#3-XGBoost的参数设置" class="headerlink" title="3. XGBoost的参数设置"></a>3. XGBoost的参数设置</h4><p>(括号内的名称为sklearn接口对应的参数名字)</p>
<p><span style="background:yellow">更详细的介绍见 <a href="https://xgboost.readthedocs.io/en/latest/parameter.html" target="_blank" rel="noopener">官方文档</a>.</span></p>
<p>XGBoost的参数分为三种：</p>
<h5 id="3-1-通用参数"><a href="#3-1-通用参数" class="headerlink" title="3.1. 通用参数"></a>3.1. 通用参数</h5><blockquote>
<ul>
<li>booster: 使用哪个弱学习器训练，默认gbtree，可选gbtree，gblinear或 dart<ul>
<li>booster参数：控制每一步的booster (tree/regression). 因为tree的性能比线性回归好得多，因此我们很少用线性回归. <code>gbtree</code> and <code>dart</code> use tree based models while <code>gblinear</code> uses linear functions.</li>
</ul>
</li>
<li>nthread：用于运行XGBoost的并行线程数，默认为最大可用线程数</li>
<li>verbosity：打印消息的详细程度。默认值为1，有效值为0（静默），1（警告），2（信息），3（调试）。</li>
</ul>
</blockquote>
<p>tree booster：</p>
<blockquote>
<ul>
<li><p>Tree Booster的参数：</p>
</li>
<li><ul>
<li><p>eta（learning_rate）：learning_rate，在更新中使用步长收缩以防止过度拟合，默认= 0.3，范围：[0,1]；典型值一般设置为：0.01-0.2</p>
</li>
<li><p>gamma（min_split_loss）：默认= 0，分裂节点时，损失函数减小值只有大于等于gamma节点才分裂，gamma值越大，算法越保守，越不容易过拟合，但性能就不一定能保证，需要平衡。范围：[0，∞]</p>
</li>
<li><p>max_depth：默认= 6，一棵树的最大深度。增加此值将使模型更复杂，并且更可能过度拟合。范围：[0，∞]</p>
</li>
<li><p>min_child_weight：默认值= 1，如果新分裂的节点的样本权重和小于min_child_weight则停止分裂 。这个可以用来减少过拟合，但是也不能太高，会导致欠拟合。范围：[0，∞]</p>
</li>
<li><p>max_delta_step：默认= 0，允许每个叶子输出的最大增量步长。如果将该值设置为0，则表示没有约束。如果将其设置为正值，则可以帮助使更新步骤更加保守。通常不需要此参数，但是当类极度不平衡时，它可能有助于逻辑回归。将其设置为1-10的值可能有助于控制更新。范围：[0，∞]</p>
</li>
<li><p>subsample：默认值= 1，构建每棵树对样本的采样率，如果设置成0.5，XGBoost会随机选择一半的样本作为训练集。范围：（0,1]</p>
</li>
<li><p>sampling_method：默认= uniform，用于对训练实例进行采样的方法。</p>
</li>
<li><ul>
<li>uniform：每个训练实例的选择概率均等。通常将subsample&gt; = 0.5 设置 为良好的效果。</li>
<li>gradient_based：每个训练实例的选择概率与规则化的梯度绝对值成正比，具体来说就是 $\sqrt{g^2+\lambda h^2}$，subsample可以设置为低至0.1，而不会损失模型精度。</li>
</ul>
</li>
<li><p>colsample_bytree：默认= 1，列采样率，也就是特征采样率。范围为（0，1]</p>
</li>
<li><p>lambda（reg_lambda）：默认=1，L2正则化权重项。增加此值将使模型更加保守。</p>
</li>
<li><p>alpha（reg_alpha）：默认= 0，权重的L1正则化项。增加此值将使模型更加保守。</p>
</li>
<li><p>tree_method：默认=auto，XGBoost中使用的树构建算法。可选：<code>auto</code>, <code>exact</code>, <code>approx</code>, <code>hist</code>, <code>gpu_hist</code></p>
</li>
<li><ul>
<li>auto：使用启发式选择最快的方法。</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>对于小型数据集，将使用精确贪婪<code>exact</code>。</li>
<li>对于较大的数据集，将选择近似算法<code>approx</code>。建议尝试<code>hist</code>，<code>gpu_hist</code>，对于大量的数据有更高的性能。<code>gpu_hist</code>支持 external memory 外部存储器。</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>exact：精确的贪婪算法。枚举所有拆分的候选点。</li>
<li>approx：使用分位数和梯度直方图的近似贪婪算法。</li>
<li>hist：更快的直方图优化的近似贪婪算法。（LightGBM也是使用直方图算法）</li>
<li>gpu_hist：GPU hist算法的实现。</li>
</ul>
</li>
<li><p>scale_pos_weight: 默认值1，控制正负权重的平衡，这对于不平衡的类别很有用。Kaggle竞赛一般设置 sum(negative instances) / sum(positive instances)，在类别高度不平衡的情况下，将参数设置大于0，可以加快收敛。</p>
</li>
<li><p>num_parallel_tree：默认=1，每次迭代期间构造的并行树的数量。此选项用于支持增强型随机森林。</p>
</li>
<li><p>monotone_constraints：可变单调性的约束，在某些情况下，如果有非常强烈的先验信念认为真实的关系具有一定的质量，则可以使用约束条件来提高模型的预测性能。（例如params_constrained[‘monotone_constraints’] = “(1,-1)”，(1,-1)告诉XGBoost对第一个预测变量施加增加的约束，对第二个预测变量施加减小的约束。）</p>
</li>
</ul>
</li>
</ul>
</blockquote>
<p>linear booster：</p>
<blockquote>
<ul>
<li><p>Linear Booster的参数：</p>
</li>
<li><ul>
<li><p>lambda（reg_lambda）：默认= 0，L2正则化权重项。增加此值将使模型更加保守。归一化为训练示例数。(Normalised to number of training examples.)</p>
</li>
<li><p>alpha（reg_alpha）：默认= 0，权重的L1正则化项。增加此值将使模型更加保守。归一化为训练示例数。</p>
</li>
<li><p>updater：默认= shotgun。</p>
</li>
<li><ul>
<li>shotgun：基于shotgun算法的平行坐标下降算法。使用“ hogwild”并行性，因此每次运行都产生不确定的解决方案。</li>
<li>coord_descent：普通坐标下降算法。同样是多线程的，但仍会产生确定性的解决方案。</li>
</ul>
</li>
<li><p>feature_selector：默认= cyclic。特征选择和排序方法</p>
</li>
<li><ul>
<li>cyclic：通过每次循环一个特征来实现的。</li>
<li>shuffle：类似于cyclic，但是在每次更新之前都有随机的特征变换。</li>
<li>random：一个随机(有放回)特征选择器。</li>
<li>greedy：选择梯度最大的特征。（贪婪选择）</li>
<li>thrifty：近似贪婪特征选择（近似于greedy）</li>
</ul>
</li>
<li><p>top_k：默认值为0，要选择的最重要特征数（在greedy和thrifty内）。The number of top features to select in <code>greedy</code> and <code>thrifty</code> feature selector. The value of 0 means using all the features.</p>
</li>
</ul>
</li>
</ul>
</blockquote>
<h5 id="3-2-任务参数"><a href="#3-2-任务参数" class="headerlink" title="3.2. 任务参数"></a>3.2. 任务参数</h5><p>学习目标参数。这个参数用来控制理想的优化目标和每一步结果的度量方法。</p>
<blockquote>
<ul>
<li><p>objective：默认=<code>reg:squarederror</code>，表示最小平方误差。</p>
</li>
<li><ul>
<li><p><code>reg:squarederror</code>：最小平方误差。</p>
</li>
<li><p><code>reg:squaredlogerror</code>：对数平方损失。</p>
</li>
<li><p><code>reg:logistic</code>：逻辑回归</p>
</li>
<li><p><code>reg:pseudohubererror</code>： 使用伪Huber损失进行回归，这是绝对损失的两倍可微选择。</p>
</li>
<li><p><code>binary:logistic</code>：logistic regression for binary classification, output probability.</p>
</li>
<li><p><code>binary:logitraw</code>：logistic regression for binary classification, output score before logistic transformation.</p>
</li>
<li><p><code>binary:hinge</code>：二元分类的铰链损失(hinge loss)。这使预测为0或1，而不是产生概率。（SVM就是铰链损失函数）</p>
</li>
<li><p><code>count:poisson</code>：计数数据的泊松回归，输出泊松分布的平均值。</p>
</li>
<li><p><code>survival:cox</code>：针对正确的（right censored）生存时间数据进行Cox回归（负值被视为正确的生存时间）。</p>
</li>
<li><p><code>survival:aft</code>：用于检查生存时间数据的加速故障时间模型。</p>
</li>
<li><p><code>aft_loss_distribution</code>：Probabilty Density Function used by <code>survival:aft</code> objective and <code>aft-nloglik</code> metric.</p>
</li>
<li><p><code>multi:softmax</code>：设置XGBoost以使用softmax目标进行多类分类，还需要设置num_class（类数）</p>
</li>
<li><p><code>multi:softprob</code>：与softmax相同，但输出向量，可以进一步重整为矩阵。结果包含属于每个类别的每个数据点的预测概率。</p>
</li>
<li><p><code>rank:pairwise</code>：使用LambdaMART进行成对排名，从而使成对损失最小化。</p>
</li>
<li><p><code>rank:ndcg</code>：使用LambdaMART进行列表式排名，使标准化折让累积收益（NDCG）最大化。</p>
</li>
<li><p><code>rank:map</code>：使用LambdaMART进行列表平均排名，使平均平均精度（MAP）最大化。</p>
</li>
<li><p><code>reg:gamma</code>：使用对数链接(log-link)进行伽马回归。输出是伽马分布的平均值。</p>
</li>
<li><p><code>reg:tweedie</code>：使用对数链接进行Tweedie回归。</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>eval_metric：验证数据的评估指标，将根据objective分配默认指标 (rmse for regression, and error for classification, mean average precision for ranking)，用户可以添加多个评估指标 (Python users: remember to pass the metrics in as list of parameters pairs instead of map)</p>
</li>
<li><ul>
<li><p>rmse，均方根误差；</p>
</li>
<li><p>rmsle：均方根对数误差；Default metric of <code>reg:squaredlogerror</code> objective.</p>
</li>
<li><p>mae：平均绝对误差；</p>
</li>
<li><p>mphe：平均伪Huber错误；</p>
</li>
<li><p>logloss：负对数似然；</p>
</li>
<li><p>error：二元分类错误率； It is calculated as <code>#(wrong cases)/#(all cases)</code></p>
</li>
<li><p>merror：多类分类错误率；</p>
</li>
<li><p>mlogloss：多类logloss；</p>
</li>
<li><p>auc：曲线下面积；</p>
</li>
<li><p>aucpr：PR曲线下的面积；</p>
</li>
<li><p>ndcg：归一化累计折扣；</p>
</li>
<li><p>map：平均精度；</p>
</li>
</ul>
</li>
</ul>
<ul>
<li>seed ：随机数种子，[默认= 0]。</li>
</ul>
</blockquote>
<h5 id="3-3-命令行参数"><a href="#3-3-命令行参数" class="headerlink" title="3.3. 命令行参数"></a>3.3. 命令行参数</h5><p>这里不说了，因为很少用命令行控制台版本。(only used in the console version of XGBoost)</p>
<h4 id="4-XGBoost的调参说明"><a href="#4-XGBoost的调参说明" class="headerlink" title="4. XGBoost的调参说明"></a>4. XGBoost的调参说明</h4><p>参数调优的一般步骤：</p>
<ul>
<li>1.确定（较大）学习速率和提升参数调优的初始值</li>
<li>2.max_depth 和 min_child_weight 参数调优</li>
<li>3.gamma参数调优</li>
<li>4.subsample 和 colsample_bytree 参数调优</li>
<li>5.正则化参数alpha调优</li>
<li>6.降低学习速率和使用更多的决策树</li>
</ul>
<h4 id="5-XGBoost详细攻略"><a href="#5-XGBoost详细攻略" class="headerlink" title="5. XGBoost详细攻略"></a>5. XGBoost详细攻略</h4><p>更详细内容见<a href="https://xgboost.readthedocs.io/en/latest/python/python_intro.html" target="_blank" rel="noopener">官方文档</a></p>
<h5 id="1-安装XGBoost"><a href="#1-安装XGBoost" class="headerlink" title="1). 安装XGBoost"></a>1). 安装XGBoost</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pip3 install xgboost</span><br><span class="line">或</span><br><span class="line">pip install xgboost</span><br><span class="line"></span><br><span class="line">更新</span><br><span class="line">pip install --upgrade xgboost</span><br></pre></td></tr></table></figure>
<h5 id="2-数据接口（XGBoost可处理的数据格式DMatrix）"><a href="#2-数据接口（XGBoost可处理的数据格式DMatrix）" class="headerlink" title="2). 数据接口（XGBoost可处理的数据格式DMatrix）"></a>2). 数据接口（XGBoost可处理的数据格式DMatrix）</h5><p>The XGBoost python module is able to load data from:</p>
<ul>
<li>LibSVM text format file</li>
<li>Comma-separated values (CSV) file</li>
<li>NumPy 2D array</li>
<li>SciPy 2D sparse array</li>
<li>cuDF DataFrame</li>
<li>Pandas data frame, and</li>
<li>XGBoost binary buffer file.</li>
</ul>
<p>(See <a href="https://xgboost.readthedocs.io/en/latest/tutorials/input_format.html" target="_blank" rel="noopener">Text Input Format of DMatrix</a> for detailed description of text input format.)</p>
<p>The data is stored in a <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.DMatrix" target="_blank" rel="noopener"><code>DMatrix</code></a> object.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.LibSVM文本格式文件</span></span><br><span class="line"><span class="comment"># To load a libsvm text file or a XGBoost binary file into DMatrix:</span></span><br><span class="line">dtrain = xgb.DMatrix(<span class="string">'train.svm.txt'</span>)</span><br><span class="line">dtest = xgb.DMatrix(<span class="string">'test.svm.buffer'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.CSV文件(不能含类别文本变量，如果存在文本变量请做特征处理如one-hot)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Categorical features not supported</span></span><br><span class="line"><span class="string">Note that XGBoost does not provide specialization for categorical features; if your data contains categorical features, load it as a NumPy array first and then perform corresponding preprocessing steps like one-hot encoding.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Use Pandas to load CSV files with headers</span></span><br><span class="line"><span class="string">Currently, the DMLC data parser cannot parse CSV files with headers. Use Pandas (see below) to read CSV files with headers.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">dtrain = xgb.DMatrix(<span class="string">'train.csv?format=csv&amp;label_column=0'</span>)</span><br><span class="line">dtest = xgb.DMatrix(<span class="string">'test.csv?format=csv&amp;label_column=0'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.NumPy数组</span></span><br><span class="line">data = np.random.rand(<span class="number">5</span>, <span class="number">10</span>)  <span class="comment"># 5 entities, each contains 10 features</span></span><br><span class="line">label = np.random.randint(<span class="number">2</span>, size=<span class="number">5</span>)  <span class="comment"># binary target</span></span><br><span class="line">dtrain = xgb.DMatrix(data, label=label)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.scipy.sparse数组</span></span><br><span class="line">csr = scipy.sparse.csr_matrix((dat, (row, col)))</span><br><span class="line">dtrain = xgb.DMatrix(csr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.pandas数据框dataframe</span></span><br><span class="line">data = pandas.DataFrame(np.arange(<span class="number">12</span>).reshape((<span class="number">4</span>,<span class="number">3</span>)), columns=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br><span class="line">label = pandas.DataFrame(np.random.randint(<span class="number">2</span>, size=<span class="number">4</span>))</span><br><span class="line">dtrain = xgb.DMatrix(data, label=label)</span><br></pre></td></tr></table></figure>
<p>笔者推荐：先保存到XGBoost二进制文件中将使加载速度更快，然后再加载进来</p>
<p>Saving <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.DMatrix" target="_blank" rel="noopener"><code>DMatrix</code></a> into a XGBoost binary file will make loading faster:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.保存DMatrix到XGBoost二进制文件中</span></span><br><span class="line">dtrain = xgb.DMatrix(<span class="string">'train.svm.txt'</span>)</span><br><span class="line">dtrain.save_binary(<span class="string">'train.buffer'</span>)</span><br><span class="line"><span class="comment"># 2. 缺失值可以用DMatrix构造函数中的默认值替换：</span></span><br><span class="line">dtrain = xgb.DMatrix(data, label=label, missing=<span class="number">-999.0</span>)</span><br><span class="line"><span class="comment"># 3.可以在需要时设置权重：</span></span><br><span class="line">w = np.random.rand(<span class="number">5</span>, <span class="number">1</span>)</span><br><span class="line">dtrain = xgb.DMatrix(data, label=label, missing=<span class="number">-999.0</span>, weight=w)</span><br></pre></td></tr></table></figure>
<h5 id="3-参数的设置方式"><a href="#3-参数的设置方式" class="headerlink" title="3). 参数的设置方式"></a>3). 参数的设置方式</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 加载并处理数据</span></span><br><span class="line">df_wine = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'</span>,header=<span class="literal">None</span>)</span><br><span class="line">df_wine.columns = [<span class="string">'Class label'</span>, <span class="string">'Alcohol'</span>,<span class="string">'Malic acid'</span>, <span class="string">'Ash'</span>,<span class="string">'Alcalinity of ash'</span>,<span class="string">'Magnesium'</span>, <span class="string">'Total phenols'</span>,</span><br><span class="line">                   <span class="string">'Flavanoids'</span>, <span class="string">'Nonflavanoid phenols'</span>,<span class="string">'Proanthocyanins'</span>,<span class="string">'Color intensity'</span>, <span class="string">'Hue'</span>,<span class="string">'OD280/OD315 of diluted wines'</span>,<span class="string">'Proline'</span>]</span><br><span class="line">df_wine = df_wine[df_wine[<span class="string">'Class label'</span>] != <span class="number">1</span>]  <span class="comment"># drop 1 class</span></span><br><span class="line">y = df_wine[<span class="string">'Class label'</span>].values</span><br><span class="line">X = df_wine[[<span class="string">'Alcohol'</span>,<span class="string">'OD280/OD315 of diluted wines'</span>]].values</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split  <span class="comment"># 切分训练集与测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder   <span class="comment"># 标签化分类变量</span></span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">y = le.fit_transform(y)</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=<span class="number">0.2</span>,random_state=<span class="number">1</span>,stratify=y)</span><br><span class="line"></span><br><span class="line">dtrain = xgb.DMatrix(X_train, label=y_train)</span><br><span class="line">dtest = xgb.DMatrix(X_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.Booster 参数</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'booster'</span>: <span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'multi:softmax'</span>,  <span class="comment"># 多分类的问题</span></span><br><span class="line">    <span class="string">'num_class'</span>: <span class="number">10</span>,               <span class="comment"># 类别数，与 multisoftmax 并用</span></span><br><span class="line">    <span class="string">'gamma'</span>: <span class="number">0.1</span>,                  <span class="comment"># 用于控制是否后剪枝的参数,越大越保守，一般0.1、0.2这样子。</span></span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">12</span>,               <span class="comment"># 构建树的深度，越大越容易过拟合</span></span><br><span class="line">    <span class="string">'lambda'</span>: <span class="number">2</span>,                   <span class="comment"># 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。</span></span><br><span class="line">    <span class="string">'subsample'</span>: <span class="number">0.7</span>,              <span class="comment"># 随机采样训练样本</span></span><br><span class="line">    <span class="string">'colsample_bytree'</span>: <span class="number">0.7</span>,       <span class="comment"># 生成树时进行的列采样</span></span><br><span class="line">    <span class="string">'min_child_weight'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">'silent'</span>: <span class="number">1</span>,                   <span class="comment"># 设置成1则没有运行信息输出，最好是设置为0.? slient还是verbosity?</span></span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.007</span>,                  <span class="comment"># 如同学习率</span></span><br><span class="line">    <span class="string">'seed'</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="string">'nthread'</span>: <span class="number">4</span>,                  <span class="comment"># cpu 线程数</span></span><br><span class="line">    <span class="string">'eval_metric'</span>:<span class="string">'auc'</span></span><br><span class="line">&#125;</span><br><span class="line">plst = params.items()</span><br><span class="line"><span class="comment"># evallist = [(dtest, 'eval'), (dtrain, 'train')]   # 指定验证集</span></span><br></pre></td></tr></table></figure>
<p>XGBoost can use either a list of pairs or a dictionary to set <a href="https://xgboost.readthedocs.io/en/latest/parameter.html" target="_blank" rel="noopener">parameters</a>. For instance:</p>
<ul>
<li><p>Booster parameters</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">param = &#123;<span class="string">'max_depth'</span>: <span class="number">2</span>, <span class="string">'eta'</span>: <span class="number">1</span>, <span class="string">'objective'</span>: <span class="string">'binary:logistic'</span>&#125;</span><br><span class="line">param[<span class="string">'nthread'</span>] = <span class="number">4</span></span><br><span class="line">param[<span class="string">'eval_metric'</span>] = <span class="string">'auc'</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>You can also specify multiple eval metrics:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">param[<span class="string">'eval_metric'</span>] = [<span class="string">'auc'</span>, <span class="string">'ams@0'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># alternatively:</span></span><br><span class="line"><span class="comment"># plst = param.items()</span></span><br><span class="line"><span class="comment"># plst += [('eval_metric', 'ams@0')]</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Specify validations set to watch performance</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">evallist = [(dtest, <span class="string">'eval'</span>), (dtrain, <span class="string">'train'</span>)]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="4-训练"><a href="#4-训练" class="headerlink" title="4). 训练"></a>4). 训练</h5><p>注：貌似现在不需要<code>plst = param.items()</code>，直接传 <code>param</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 2.训练</span></span><br><span class="line">num_round = <span class="number">10</span></span><br><span class="line">bst = xgb.train(plst, dtrain, num_round)</span><br><span class="line"><span class="comment">#bst = xgb.train(plst, dtrain, num_round, evallist )</span></span><br></pre></td></tr></table></figure>
<h5 id="5-保存模型"><a href="#5-保存模型" class="headerlink" title="5). 保存模型"></a>5). 保存模型</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 3.保存模型</span></span><br><span class="line"><span class="comment"># After training, the model can be saved.</span></span><br><span class="line">bst.save_model(<span class="string">'0001.model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The model and its feature map can also be dumped to a text file.</span></span><br><span class="line"><span class="comment"># dump model</span></span><br><span class="line">bst.dump_model(<span class="string">'dump.raw.txt'</span>)</span><br><span class="line"><span class="comment"># dump model with feature map</span></span><br><span class="line"><span class="comment">#bst.dump_model('dump.raw.txt', 'featmap.txt')</span></span><br></pre></td></tr></table></figure>
<h5 id="6-加载保存的模型"><a href="#6-加载保存的模型" class="headerlink" title="6) . 加载保存的模型"></a>6) . 加载保存的模型</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 4.加载保存的模型：</span></span><br><span class="line">bst = xgb.Booster(&#123;<span class="string">'nthread'</span>: <span class="number">4</span>&#125;)  <span class="comment"># init model</span></span><br><span class="line">bst.load_model(<span class="string">'0001.model'</span>)  <span class="comment"># load data</span></span><br></pre></td></tr></table></figure>
<h5 id="7-设置早停机制"><a href="#7-设置早停机制" class="headerlink" title="7). 设置早停机制"></a>7). 设置早停机制</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 5.也可以设置早停机制（需要设置验证集）</span></span><br><span class="line">train(..., evals=evals, early_stopping_rounds=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p>The model will train until the validation score stops improving. Validation error needs to decrease at least every <code>early_stopping_rounds</code> to continue training.</p>
<p>If early stopping occurs, the model will have three additional fields: <code>bst.best_score</code>, <code>bst.best_iteration</code> and <code>bst.best_ntree_limit</code>. Note that <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train" target="_blank" rel="noopener"><code>xgboost.train()</code></a> will return a model from the last iteration, not the best one.</p>
<p>This works with both metrics to minimize (RMSE, log loss, etc.) and to maximize (MAP, NDCG, AUC). Note that if you specify more than one evaluation metric the last one in <code>param[&#39;eval_metric&#39;]</code> is used for early stopping.</p>
<h5 id="8-预测"><a href="#8-预测" class="headerlink" title="8). 预测"></a>8). 预测</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 6.预测</span></span><br><span class="line">ypred = bst.predict(dtest)</span><br></pre></td></tr></table></figure>
<p>If early stopping is enabled during training, you can get predictions from the best iteration with <code>bst.best_ntree_limit</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)</span><br></pre></td></tr></table></figure>
<h5 id="9-绘图"><a href="#9-绘图" class="headerlink" title="9). 绘图"></a>9). 绘图</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 1.绘制重要性</span></span><br><span class="line"><span class="comment"># This function requires matplotlib to be installed.</span></span><br><span class="line">xgb.plot_importance(bst)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.绘制输出树</span></span><br><span class="line"><span class="comment"># This function requires graphviz and matplotlib.</span></span><br><span class="line"><span class="comment">#xgb.plot_tree(bst, num_trees=2)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.使用xgboost.to_graphviz()将目标树转换为graphviz</span></span><br><span class="line"><span class="comment"># When you use IPython, you can use the xgboost.to_graphviz() function, which converts the target tree to a graphviz instance. The graphviz instance is automatically rendered in IPython.</span></span><br><span class="line"><span class="comment">#xgb.to_graphviz(bst, num_trees=2)</span></span><br></pre></td></tr></table></figure>
<h4 id="6-实战案例"><a href="#6-实战案例" class="headerlink" title="6. 实战案例"></a>6. 实战案例</h4><h5 id="1-分类案例"><a href="#1-分类案例" class="headerlink" title="1). 分类案例"></a>1). 分类案例</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score   <span class="comment"># 准确率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载样本数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X,y = iris.data,iris.target</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">1234565</span>) <span class="comment"># 数据集分割</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 算法参数</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'booster'</span>: <span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'multi:softmax'</span>,</span><br><span class="line">    <span class="string">'num_class'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">'gamma'</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">6</span>,</span><br><span class="line">    <span class="string">'lambda'</span>: <span class="number">2</span>,</span><br><span class="line">    <span class="string">'subsample'</span>: <span class="number">0.7</span>,</span><br><span class="line">    <span class="string">'colsample_bytree'</span>: <span class="number">0.75</span>,</span><br><span class="line">    <span class="string">'min_child_weight'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">'silent'</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'seed'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'nthread'</span>: <span class="number">4</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">plst = params.items()</span><br><span class="line"></span><br><span class="line">dtrain = xgb.DMatrix(X_train, y_train) <span class="comment"># 生成数据集格式</span></span><br><span class="line">num_rounds = <span class="number">500</span></span><br><span class="line">model = xgb.train(plst, dtrain, num_rounds) <span class="comment"># xgboost模型训练</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line">dtest = xgb.DMatrix(X_test)</span><br><span class="line">y_pred = model.predict(dtest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = accuracy_score(y_test,y_pred)</span><br><span class="line">print(<span class="string">"accuarcy: %.2f%%"</span> % (accuracy*<span class="number">100.0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示重要特征</span></span><br><span class="line">plot_importance(model)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">accuarcy: 96.67%</span><br></pre></td></tr></table></figure>
<p><img src="/2020/07/25/决策树/1595830272543.png" alt="1595830272543"></p>
<h5 id="2-回归案例"><a href="#2-回归案例" class="headerlink" title="2). 回归案例"></a>2). 回归案例</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> plot_importance</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">boston = load_boston()</span><br><span class="line">X,y = boston.data,boston.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># XGBoost训练过程</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'booster'</span>: <span class="string">'gbtree'</span>,</span><br><span class="line">    <span class="string">'objective'</span>: <span class="string">'reg:squarederror'</span>,</span><br><span class="line">    <span class="string">'gamma'</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'max_depth'</span>: <span class="number">5</span>,</span><br><span class="line">    <span class="string">'lambda'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">'subsample'</span>: <span class="number">0.7</span>,</span><br><span class="line">    <span class="string">'colsample_bytree'</span>: <span class="number">0.7</span>,</span><br><span class="line">    <span class="string">'min_child_weight'</span>: <span class="number">3</span>,</span><br><span class="line">    <span class="string">'silent'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">'eta'</span>: <span class="number">0.1</span>,</span><br><span class="line">    <span class="string">'seed'</span>: <span class="number">1000</span>,</span><br><span class="line">    <span class="string">'nthread'</span>: <span class="number">4</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dtrain = xgb.DMatrix(X_train, y_train)</span><br><span class="line">num_rounds = <span class="number">300</span></span><br><span class="line">plst = params.items()</span><br><span class="line">model = xgb.train(plst, dtrain, num_rounds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line">dtest = xgb.DMatrix(X_test)</span><br><span class="line">ans = model.predict(dtest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示重要特征</span></span><br><span class="line">plot_importance(model)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/07/25/决策树/1595837055748.png" alt="1595837055748"></p>
<h5 id="3-XGBoost调参（结合sklearn网格搜索）"><a href="#3-XGBoost调参（结合sklearn网格搜索）" class="headerlink" title="3). XGBoost调参（结合sklearn网格搜索）"></a><strong>3). XGBoost调参</strong>（结合sklearn网格搜索）</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X,y = iris.data,iris.target</span><br><span class="line">col = iris.target_names</span><br><span class="line">train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=<span class="number">0.3</span>, random_state=<span class="number">1</span>)   <span class="comment"># 分训练集和验证集</span></span><br><span class="line"></span><br><span class="line">parameters = &#123;</span><br><span class="line">              <span class="string">'max_depth'</span>: [<span class="number">5</span>, <span class="number">10</span>, <span class="number">15</span>, <span class="number">20</span>, <span class="number">25</span>],</span><br><span class="line">              <span class="string">'learning_rate'</span>: [<span class="number">0.01</span>, <span class="number">0.02</span>, <span class="number">0.05</span>, <span class="number">0.1</span>, <span class="number">0.15</span>],</span><br><span class="line">              <span class="string">'n_estimators'</span>: [<span class="number">500</span>, <span class="number">1000</span>, <span class="number">2000</span>, <span class="number">3000</span>, <span class="number">5000</span>],</span><br><span class="line">              <span class="string">'min_child_weight'</span>: [<span class="number">0</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>],</span><br><span class="line">              <span class="string">'max_delta_step'</span>: [<span class="number">0</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">              <span class="string">'subsample'</span>: [<span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.85</span>, <span class="number">0.95</span>],</span><br><span class="line">              <span class="string">'colsample_bytree'</span>: [<span class="number">0.5</span>, <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.9</span>],</span><br><span class="line">              <span class="string">'reg_alpha'</span>: [<span class="number">0</span>, <span class="number">0.25</span>, <span class="number">0.5</span>, <span class="number">0.75</span>, <span class="number">1</span>],</span><br><span class="line">              <span class="string">'reg_lambda'</span>: [<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>],</span><br><span class="line">              <span class="string">'scale_pos_weight'</span>: [<span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">xlf = xgb.XGBClassifier(max_depth=<span class="number">10</span>,</span><br><span class="line">            learning_rate=<span class="number">0.01</span>,</span><br><span class="line">            n_estimators=<span class="number">2000</span>,</span><br><span class="line">            silent=<span class="literal">True</span>,</span><br><span class="line">            objective=<span class="string">'multi:softmax'</span>,</span><br><span class="line">            num_class=<span class="number">3</span> ,</span><br><span class="line">            nthread=<span class="number">-1</span>,</span><br><span class="line">            gamma=<span class="number">0</span>,</span><br><span class="line">            min_child_weight=<span class="number">1</span>,</span><br><span class="line">            max_delta_step=<span class="number">0</span>,</span><br><span class="line">            subsample=<span class="number">0.85</span>,</span><br><span class="line">            colsample_bytree=<span class="number">0.7</span>,</span><br><span class="line">            colsample_bylevel=<span class="number">1</span>,</span><br><span class="line">            reg_alpha=<span class="number">0</span>,</span><br><span class="line">            reg_lambda=<span class="number">1</span>,</span><br><span class="line">            scale_pos_weight=<span class="number">1</span>,</span><br><span class="line">            seed=<span class="number">0</span>,</span><br><span class="line">            missing=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">gs = GridSearchCV(xlf, param_grid=parameters, scoring=<span class="string">'accuracy'</span>, cv=<span class="number">3</span>)</span><br><span class="line">gs.fit(train_x, train_y)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"Best score: %0.3f"</span> % gs.best_score_)</span><br><span class="line">print(<span class="string">"Best parameters set: %s"</span> % gs.best_params_ )</span><br></pre></td></tr></table></figure>
<h2 id="决策树算法十问及经典面试问题"><a href="#决策树算法十问及经典面试问题" class="headerlink" title="决策树算法十问及经典面试问题"></a>决策树算法十问及经典面试问题</h2><p>（见 <a href="https://mp.weixin.qq.com/s/vkbZweJ5oRo4IPt-3kg64g" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/vkbZweJ5oRo4IPt-3kg64g</a> ）</p>
<h3 id="简介和算法"><a href="#简介和算法" class="headerlink" title="简介和算法"></a>简介和算法</h3><blockquote>
<p>决策树是机器学习最常用的算法之一，它将算法组织成一颗树的形式。其实这就是将平时所说的if-then语句构建成了树的形式。这个决策树主要包括三个部分：内部节点、叶节点和边。内部节点是划分的属性，边代表划分的条件，叶节点表示类别。构建决策树 就是一个递归的选择内部节点，计算划分条件的边，最后到达叶子节点的过程。</p>
</blockquote>
<p><img src="/2020/07/25/决策树/1595669193083.png" alt="1595669193083"></p>
<h3 id="核心公式"><a href="#核心公式" class="headerlink" title="核心公式"></a>核心公式</h3><p><img src="/2020/07/25/决策树/1595669223727.png" alt="1595669223727"></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">model</th>
<th style="text-align:center">feature select</th>
<th style="text-align:center">树的类型</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">ID3</td>
<td style="text-align:center">{分类:信息增益}</td>
<td style="text-align:center">多叉树</td>
</tr>
<tr>
<td style="text-align:center">C4.5</td>
<td style="text-align:center">{分类:信息增益率}</td>
<td style="text-align:center">多叉树</td>
</tr>
<tr>
<td style="text-align:center">CART (分类树)</td>
<td style="text-align:center">{分类:基尼指数}</td>
<td style="text-align:center">二叉树</td>
</tr>
<tr>
<td style="text-align:center">CART (回归树)</td>
<td style="text-align:center">{回归:平方误差}</td>
<td style="text-align:center">二叉树</td>
</tr>
</tbody>
</table>
</div>
<h3 id="算法十问"><a href="#算法十问" class="headerlink" title="算法十问"></a>算法十问</h3><p>1.决策树和条件概率分布的关系？</p>
<blockquote>
<p>决策树可以表示成给定条件下类的条件概率分布. 决策树中的每一条路径都对应是划分的一个条件概率分布. 每一个叶子节点都是通过多个条件之后的划分空间，在叶子节点中计算每个类的条件概率，必然会倾向于某一个类，即这个类的概率最大.</p>
</blockquote>
<p>2.ID3和C4.5算法可以处理实数特征吗？如果可以应该怎么处理？如果不可以请给出理由？</p>
<p><img src="/2020/07/25/决策树/1595669343135.png" alt="1595669343135"></p>
<p>3.既然信息增益可以计算，为什么C4.5还使用信息增益比？</p>
<blockquote>
<p>在使用信息增益的时候，如果某个特征有很多取值，使用这个取值多的特征会的大的信息增益，这个问题是出现很多分支，将数据划分更细，模型复杂度高，出现过拟合的机率更大。使用信息增益比就是为了解决偏向于选择取值较多的特征的问题. 使用信息增益比对取值多的特征加上的惩罚，对这个问题进行了校正.</p>
</blockquote>
<p>4.基尼指数可以表示数据不确定性，信息熵也可以表示数据的不确定性. 为什么CART使用基尼指数？</p>
<blockquote>
<p>信息熵0, logK都是值越大，数据的不确定性越大. 信息熵需要计算对数，计算量大；信息熵是可以处理多个类别，基尼指数就是针对两个类计算的，由于CART树是一个二叉树，每次都是选择yes or no进行划分，从这个角度也是应该选择简单的基尼指数进行计算.</p>
</blockquote>
<p>5.决策树怎么剪枝？</p>
<blockquote>
<p>一般算法在构造决策树的都是尽可能的细分，直到数据不可划分才会到达叶子节点，停止划分. 因为给训练数据巨大的信任，这种形式形式很容易造成过拟合，为了防止过拟合需要进行决策树剪枝. 一般分为预剪枝和后剪枝，预剪枝是在决策树的构建过程中加入限制，比如控制叶子节点最少的样本个数，提前停止. 后剪枝是在决策树构建完成之后，根据加上正则项的结构风险最小化自下向上进行的剪枝操作. 剪枝的目的就是防止过拟合，是模型在测试数据上变现良好，更加鲁棒.</p>
</blockquote>
<p>6.ID3算法，为什么不选择具有最高预测精度的属性特征，而是使用信息增益？</p>
<p>7.为什么使用贪心和其发生搜索建立决策树，为什么不直接使用暴力搜索建立最优的决策树？</p>
<blockquote>
<p>决策树目的是构建一个与训练数据拟合很好，并且复杂度小的决策树. 因为从所有可能的决策树中直接选择最优的决策树是NP完全问题，在使用中一般使用启发式方法学习相对最优的决策树.</p>
</blockquote>
<p>8.如果特征很多，决策树中最后没有用到的特征一定是无用吗？</p>
<blockquote>
<p>不是无用的，从两个角度考虑，一是特征替代性，如果可以已经使用的特征A和特征B可以提点特征C，特征C可能就没有被使用，但是如果把特征C单独拿出来进行训练，依然有效. 其二，决策树的每一条路径就是计算条件概率的条件，前面的条件如果包含了后面的条件，只是这个条件在这棵树中是无用的，如果把这个条件拿出来也是可以帮助分析数据。</p>
</blockquote>
<p>9.决策树的优点？</p>
<blockquote>
<p>优点: 决策树模型可读性好，具有描述性，有助于人工分析；效率高，决策树只需要一次性构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。缺点: 对中间值的缺失敏感；可能产生过度匹配的问题，即过拟合。</p>
</blockquote>
<p>10.基尼系数存在的问题?</p>
<blockquote>
<p>基尼指数偏向于多值属性;当类数较大时，基尼指数求解比较困难;基尼指数倾向于支持在两个分区中生成大小相同的测试。</p>
</blockquote>
<h3 id="面试真题"><a href="#面试真题" class="headerlink" title="面试真题"></a>面试真题</h3><ol>
<li>决策树如何防止过拟合？</li>
<li>信息增益比相对信息增益有什么好处？</li>
<li>如果由异常值或者数据分布不均匀，会对决策树有什么影响？</li>
<li>手动构建CART的回归树的前两个节点，给出公式每一步的公式推到？</li>
<li>决策树和其他模型相比有什么优点？</li>
<li>决策树的目标函数是什么？</li>
</ol>]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Time Series</title>
    <url>/2020/04/02/Time-Series/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>来源：<a href="https://courses.analyticsvidhya.com/courses/creating-time-series-forecast-using-python" target="_blank" rel="noopener">Time Series Forecasting using Python - Analytics Vidhya</a></p>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="What-is-Time-Series-Analysis"><a href="#What-is-Time-Series-Analysis" class="headerlink" title="What is Time Series Analysis?"></a>What is Time Series Analysis?</h3><p> As the name ‘time series forecasting’ suggests, it involves working on time (years, days, hours, minutes) based data, to derive hidden insights to make informed decision making.</p>
<h3 id="Importance-of-Time-Series-Analysis"><a href="#Importance-of-Time-Series-Analysis" class="headerlink" title="Importance of Time Series Analysis"></a>Importance of Time Series Analysis</h3><p>Time series models are very useful models when you have serially correlated data as shown above. Most businesses work on time series data to analyze </p>
<ul>
<li>Sales numbers for the next year </li>
<li>Website Traffic</li>
<li>Competition Position</li>
<li>Demand of products</li>
<li>Stock Market Analysis</li>
<li>Census Analysis</li>
<li>Budgetary Analysis</li>
</ul>
<p>This is just the tip of the iceberg and there are numerous prediction problems that involve a time component and concepts of time series analysis come into picture.</p>
<h3 id="Why-is-Time-Series-Forecasting-Challenging"><a href="#Why-is-Time-Series-Forecasting-Challenging" class="headerlink" title="Why is Time Series Forecasting Challenging?"></a>Why is Time Series Forecasting Challenging?</h3><p>But what makes a time series more challenging than say a regular regression problem? There are 2 things:</p>
<ul>
<li><strong>Time Dependence of a time series -</strong> The basic assumption of a linear regression model that the observations are independent doesn’t hold in this case.</li>
<li><strong>Seasonality in a time series -</strong> Along with an increasing or decreasing trend, most time series have some form of seasonal trends, i.e. variations specific to a particular time frame. </li>
</ul>
<a id="more"></a>
<h2 id="Introduction-to-Time-Series"><a href="#Introduction-to-Time-Series" class="headerlink" title="Introduction to Time Series"></a>Introduction to Time Series</h2><p><em>Time Series is generally data which is collected over time and is dependent on it.</em></p>
<p><img src="/2020/04/02/Time-Series/1585797313470.png" alt="1585797313470"></p>
<p>Here we see that the count of cars is independent of time, hence it is not a time series. While the CO2 level increases with respect to time, hence it is a time series.</p>
<p>Some of the examples of time series are:</p>
<p>Stock Price :</p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/865/5c1/2c7/1549344770403.jpg" alt="img"></p>
<p>Passenger Count of an airlines :</p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/a5d/87f/854/1549344770489.jpg" alt="img"></p>
<p>Temperature over time :</p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/1e6/e15/479/1549344770578.jpg" alt="img"></p>
<p>Number of visitors in a hotel :</p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/8e3/d40/890/1549344770669.jpg" alt="img"></p>
<h3 id="Trend"><a href="#Trend" class="headerlink" title="Trend"></a>Trend</h3><p>Trend is a general direction in which something is developing or changing.</p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/7d7/791/f5e/1549344821475.jpg" alt="Example"></p>
<p>Example</p>
<p>Here the red line represents an increasing trend of the time series.</p>
<h3 id="Seasonality"><a href="#Seasonality" class="headerlink" title="Seasonality"></a><strong>Seasonality</strong></h3><p>Another clear pattern can also be seen in the above time series, i.e., the pattern is repeating at regular time interval which is known as the seasonality. Any predictable change or pattern in a time series that recurs or repeats over a specific time period can be said to be seasonality. </p>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/115/9ee/826/1549344821557.jpg" alt="Example"></p>
<p>Example</p>
<p>We can see that the time series is repeating its pattern after every 12 months i.e there is a peak every year during the month of January and a trough every year in the month of September, hence this time series has a seasonality of 12 months.</p>
<h3 id="Difference-between-a-time-series-and-regression-problem"><a href="#Difference-between-a-time-series-and-regression-problem" class="headerlink" title="Difference between a time series and regression problem"></a><strong>Difference between a time series and regression problem</strong></h3><ul>
<li>The main difference is that a time series is time dependent. So the basic assumption of a linear regression model that the observations are independent doesn’t hold in this case.</li>
<li>Along with an increasing or decreasing trend, most Time Series have some form of seasonality trends,i.e. variations specific to a particular time frame.</li>
</ul>
<p>So, predicting a time series using regression techniques is not a good approach.</p>
<p>Time series analysis comprises methods for analyzing time series data in order to extract meaningful statistics and other characteristics of the data. Time series forecasting is the use of a model to predict future values based on previously observed values.</p>
<h2 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h2><p> <a href="https://datahack.analyticsvidhya.com/contest/practice-problem-time-series-2/" target="_blank" rel="noopener">https://datahack.analyticsvidhya.com/contest/practice-problem-time-series-2/</a></p>
<h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement"></a>Problem Statement</h3><p>Unicorn Investors wants to make an investment in a new form of transportation - JetRail. JetRail uses Jet propulsion technology to run rails and move people at a high speed! The investment would only make sense, if they can get more than 1 Million monthly users with in next 18 months. In order to help Unicorn Ventures in their decision, you need to forecast the traffic on JetRail for the next 7 months. You are provided with traffic data of JetRail since inception in the test file.</p>
<h3 id="Exploratory-Analysis"><a href="#Exploratory-Analysis" class="headerlink" title="Exploratory Analysis"></a>Exploratory Analysis</h3><p>原本的datetime: train.Datetime是Object格式，首先change the data type to datetime format</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train[<span class="string">'Datetime'</span>] = pd.to_datetime(train.Datetime,format=<span class="string">'%d-%m-%Y %H:%M'</span>) </span><br><span class="line"><span class="comment"># format是原格式的形式</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train.index = train[<span class="string">'Datetime'</span>] <span class="comment"># indexing the Datetime to get the time period on the x-axis.</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line">ts = df[<span class="string">'Count'</span>] </span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>)) </span><br><span class="line">plt.plot(ts, label=<span class="string">'Passenger Count'</span>) </span><br><span class="line">plt.title(<span class="string">'Time Series'</span>) </span><br><span class="line">plt.xlabel(<span class="string">"Time(year-month)"</span>) </span><br><span class="line">plt.ylabel(<span class="string">"Passenger count"</span>) </span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://s3.amazonaws.com/thinkific/file_uploads/118220/images/a58/220/12e/1549346696050.jpg" alt="png"></p>
<h3 id="Split-data"><a href="#Split-data" class="headerlink" title="Split data"></a>Split data</h3><p>将训练数据划分为训练集与验证集</p>
<p>The starting date of the dataset is 25-08-2012 as we have seen in the exploration part and the end date is 25-09-2014.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Train=train.ix[<span class="string">'2012-08-25'</span>:<span class="string">'2014-06-24'</span>] valid=train.ix[<span class="string">'2014-06-25'</span>:<span class="string">'2014-09-25'</span>]</span><br></pre></td></tr></table></figure>
<ul>
<li>We have done time based validation here by selecting the last 3 months for the validation data and rest in the train data. If we would have done it randomly it may work well for the train dataset but will not work effectively on validation dataset.</li>
<li>Lets understand it in this way: If we choose the split randomly it will take some values from the starting and some from the last years as well. It is similar to predicting the old values based on the future values which is not the case in real scenario. So, this kind of split is used while working with time related problems.</li>
</ul>
<p>划分标准：将最后3个月的数据划分为验证集，而不是随机划分。因为若是随机划分，则存在用future value去预测old value的情况，而这在现实情况中是不可能的。</p>
<h3 id="ARIMA-model"><a href="#ARIMA-model" class="headerlink" title="ARIMA model"></a>ARIMA model</h3><p>ARIMA Model的介绍可见：<a href="https://www.youtube.com/watch?v=0xHf-SJ9Z9U" target="_blank" rel="noopener">https://www.youtube.com/watch?v=0xHf-SJ9Z9U</a></p>
<ul>
<li>ARIMA stands for Auto Regression Integrated Moving Average. It is specified by three ordered parameters (p,d,q).</li>
<li>Here p is the order of the autoregressive model(number of time lags)</li>
<li>d is the degree of differencing(number of times the data have had past values subtracted)</li>
<li>q is the order of moving average model. We will discuss more about these parameters in next section.</li>
</ul>
<p>The ARIMA forecasting for a stationary time series is nothing but a linear (like a linear regression) equation.</p>
<h4 id="What-is-a-stationary-time-series"><a href="#What-is-a-stationary-time-series" class="headerlink" title="What is a stationary time series?"></a>What is a stationary time series?</h4><p>There are three basic criterion for a series to be classified as stationary series :</p>
<ul>
<li>The mean of the time series should not be a function of time. It should be constant.</li>
<li>The variance of the time series should not be a function of time.</li>
<li>THe covariance of the ith term and the (i+m)th term should not be a function of time.</li>
</ul>
<h4 id="Why-do-we-have-to-make-the-time-series-stationary"><a href="#Why-do-we-have-to-make-the-time-series-stationary" class="headerlink" title="Why do we have to make the time series stationary?"></a>Why do we have to make the time series stationary?</h4><p>We make the series stationary to make the variables independent. Variables can be dependent in various ways, but can only be independent in one way. So, we will get more information when they are independent. Hence the time series must be stationary.</p>
<p>If the time series is not stationary, firstly we have to make it stationary. For doing so, we need to remove the trend and seasonality from the data. To learn more about stationarity you can refer this article: <a href="https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2015/12/complete-tutorial-time-series-modeling/</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>时间序列</tag>
      </tags>
  </entry>
  <entry>
    <title>数据挖掘</title>
    <url>/2020/04/01/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>来源：书籍：数据挖掘：R语言实战</p>
<h2 id="1-数据挖掘"><a href="#1-数据挖掘" class="headerlink" title="1. 数据挖掘"></a>1. 数据挖掘</h2><h3 id="数据挖掘的过程"><a href="#数据挖掘的过程" class="headerlink" title="数据挖掘的过程"></a>数据挖掘的过程</h3><p><img src="/2020/04/01/数据挖掘/1585702561613.png" alt="1"></p>
<p><img src="/2020/04/01/数据挖掘/1585702611608.png" alt="1585702611608"></p>
<p><img src="/2020/04/01/数据挖掘/1585702665564.png" alt="1585702665564"></p>
<p><img src="/2020/04/01/数据挖掘/1585702697687.png" alt="1585702697687"></p>
<h3 id="数据挖掘的对象"><a href="#数据挖掘的对象" class="headerlink" title="数据挖掘的对象"></a>数据挖掘的对象</h3><p><img src="/2020/04/01/数据挖掘/1585702748399.png" alt="1585702748399"></p>
<a id="more"></a>
<h3 id="数据挖掘的方法"><a href="#数据挖掘的方法" class="headerlink" title="数据挖掘的方法"></a>数据挖掘的方法</h3><p><img src="/2020/04/01/数据挖掘/1585702952640.png" alt="1585702952640"></p>
<p><img src="/2020/04/01/数据挖掘/1585702973741.png" alt="1585702973741"></p>
<p><img src="/2020/04/01/数据挖掘/1585702996306.png" alt="1585702996306"></p>
<h2 id="2-数据概览"><a href="#2-数据概览" class="headerlink" title="2. 数据概览"></a>2. 数据概览</h2><h3 id="R的数据分类"><a href="#R的数据分类" class="headerlink" title="R的数据分类"></a>R的数据分类</h3><p><img src="/2020/04/01/数据挖掘/1585708306115.png" alt="1585708306115"></p>
<p><img src="/2020/04/01/数据挖掘/1585708352907.png" alt="1585708352907"></p>
<p><img src="/2020/04/01/数据挖掘/1585708426054.png" alt="1585708426054"></p>
<p><img src="/2020/04/01/数据挖掘/1585708478937.png" alt="1585708478937"></p>
<p><img src="/2020/04/01/数据挖掘/1585708516071.png" alt="1585708516071"></p>
<h3 id="用R简单处理数据"><a href="#用R简单处理数据" class="headerlink" title="用R简单处理数据"></a>用R简单处理数据</h3><p>这一部分我们以MASS软件包中的Insurance数据集为例，通过对其基本信息及变量类型等<br>方面的探索，介绍几个常用的R函数。在着手处理每一个数据集时，包括进行数据预处理及后续分析的过程中，这些函数通常会被反复使用，可以说是展开数据挖掘的必经步骤。</p>
<p><img src="/2020/04/01/数据挖掘/1585708954877.png" alt="1585708954877"></p>
<p><img src="/2020/04/01/数据挖掘/1585708983273.png" alt="1585708983273"></p>
<p><img src="/2020/04/01/数据挖掘/1585709046088.png" alt="1585709046088"></p>
<p><img src="/2020/04/01/数据挖掘/1585709085363.png" alt="1585709085363"></p>
<p><img src="/2020/04/01/数据挖掘/1585709217345.png" alt="1585709217345"></p>
<p><img src="/2020/04/01/数据挖掘/1585709257400.png" alt="1585709257400"></p>
<h3 id="数据抽样"><a href="#数据抽样" class="headerlink" title="数据抽样"></a>数据抽样</h3><p>抽样技术是我们在和数据打交道过程中常常需要用到的基本技能之一。</p>
<p>比如：在收集数据过程中，绝大多数情况下，并不采取普查的方式获取总体中所有样本的数据信息，而是以各类抽样方法抽取其中的若干代表性样本来进行数据获取和分析：而在获得待分析数据集后，往往需要再次通过抽样技术选取出训练集与测试集，以便比较选择出最优的挖掘算法。</p>
<p>以下我们主要介绍简单随机抽样、分层抽样及整群抽样这三种基本抽样方法在R中的实现。其中主要用到<code>base</code>软件包中的<code>sample()</code>函数，该软件包是R中使用前不需加载的默认软件包之一，其中含有许多基本统计函数；以及<code>sampling</code>软件包中的<code>strata()</code>、<code>cluster()</code>函数，该软件包专用于实现调查抽样技术，其中含有大量各类抽样方法及相关指标的计算等函数。</p>
<h4 id="简单随机抽样"><a href="#简单随机抽样" class="headerlink" title="简单随机抽样"></a>简单随机抽样</h4><p><img src="/2020/04/01/数据挖掘/1585706632444.png" alt="1585706632444"></p>
<h5 id="有放回的随机抽样"><a href="#有放回的随机抽样" class="headerlink" title="有放回的随机抽样"></a>有放回的随机抽样</h5><p><img src="/2020/04/01/数据挖掘/1585706684055.png" alt="1585706684055"></p>
<p><img src="/2020/04/01/数据挖掘/1585706725890.png" alt="1585706725890"></p>
<p><img src="/2020/04/01/数据挖掘/1585706752383.png" alt="1585706752383"></p>
<h5 id="无放回的随机抽样"><a href="#无放回的随机抽样" class="headerlink" title="无放回的随机抽样"></a>无放回的随机抽样</h5><p><img src="/2020/04/01/数据挖掘/1585706789410.png" alt="1585706789410"></p>
<h4 id="分层抽样"><a href="#分层抽样" class="headerlink" title="分层抽样"></a>分层抽样</h4><p><img src="/2020/04/01/数据挖掘/1585707032237.png" alt="1585707032237"></p>
<p><img src="/2020/04/01/数据挖掘/1585707055590.png" alt="1585707055590"></p>
<p><img src="/2020/04/01/数据挖掘/1585707081081.png" alt="1585707081081"></p>
<p><img src="/2020/04/01/数据挖掘/1585707104352.png" alt="1585707104352"></p>
<p><img src="/2020/04/01/数据挖掘/1585707127382.png" alt="1585707127382"></p>
<p><img src="/2020/04/01/数据挖掘/1585707162805.png" alt="1585707162805"></p>
<p><img src="/2020/04/01/数据挖掘/1585707188396.png" alt="1585707188396"></p>
<h4 id="整群抽样"><a href="#整群抽样" class="headerlink" title="整群抽样"></a>整群抽样</h4><p><img src="/2020/04/01/数据挖掘/1585707442032.png" alt="1585707442032"></p>
<p><img src="/2020/04/01/数据挖掘/1585707564705.png" alt="1585707564705"></p>
<p><img src="/2020/04/01/数据挖掘/1585707593282.png" alt="1585707593282"></p>
<p><img src="/2020/04/01/数据挖掘/1585707615607.png" alt="1585707615607"></p>
<h3 id="训练集与测试集"><a href="#训练集与测试集" class="headerlink" title="训练集与测试集"></a>训练集与测试集</h3><p>一般我们控制两者的比例为3:1左右，这是为了在保证建立模型的训练集样本足够的前提下，尽量使测试集的评价结果可信。</p>
<p><img src="/2020/04/01/数据挖掘/1585709638657.png" alt="1585709638657"></p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="/2020/04/01/数据挖掘/1585709698423.png" alt="1585709698423"></p>
<p><img src="/2020/04/01/数据挖掘/1585709720262.png" alt="1585709720262"></p>
<h2 id="3-用R获取数据"><a href="#3-用R获取数据" class="headerlink" title="3. 用R获取数据"></a>3. 用R获取数据</h2><h3 id="获取内置数据集"><a href="#获取内置数据集" class="headerlink" title="获取内置数据集"></a>获取内置数据集</h3><h4 id="datasets数据集"><a href="#datasets数据集" class="headerlink" title="datasets数据集"></a>datasets数据集</h4><p><img src="/2020/04/01/数据挖掘/1585709889840.png" alt="1585709889840"></p>
<p><img src="/2020/04/01/数据挖掘/1585709919129.png" alt="1585709919129"></p>
<p><img src="/2020/04/01/数据挖掘/1585709942978.png" alt="1585709942978"></p>
<p><img src="/2020/04/01/数据挖掘/1585709978867.png" alt="1585709978867"></p>
<h4 id="包的数据集"><a href="#包的数据集" class="headerlink" title="包的数据集"></a>包的数据集</h4><p>除了datasets软件包外，R中许多其他软件包也自带有少量数据集，我们首先通过如下程序代码，来获得如图3.3所示的所有数据集的列表。</p>
<p><img src="/2020/04/01/数据挖掘/1585710056729.png" alt="1585710056729"></p>
<p>我们要知道，某一软件包中的数据集，往往正是由于适合诠释该软件包内相关函数的功能而收集并添置的，也就是说，某一软件包中的数据集在格式、内容，甚至取值等方面，在某种程度上是迎合于该软件包的功能需要的。</p>
<p><img src="/2020/04/01/数据挖掘/1585710151137.png" alt="1585710151137"></p>
<h3 id="获取其他格式的数据"><a href="#获取其他格式的数据" class="headerlink" title="获取其他格式的数据"></a>获取其他格式的数据</h3><p>这一节我们主要介绍如何用R读取由固定分隔符作为数据间隔的文件，如CSV和TXT;如何读取Excel文件中的数据；如何从SPSS、Minitab、STATA、SYSTAT等统计软件中获取多种格式的数据。为了完成上述任务，我们将用到utlls、RODBC、gdata、foreign及Hmisc加载包中的多种函数。</p>
<h4 id="CSV与TXT格式"><a href="#CSV与TXT格式" class="headerlink" title="CSV与TXT格式"></a>CSV与TXT格式</h4><p>下面我们使用到utils软件包中的read.csv(）和read.table(）函数，utils包中含有大量R中最实<br>用的函数，其中包括帮助函数help()以及安装软件包函数installed.packages()等。</p>
<h5 id="读取CSV格式"><a href="#读取CSV格式" class="headerlink" title="读取CSV格式"></a>读取CSV格式</h5><p><img src="/2020/04/01/数据挖掘/1585710410455.png" alt="1585710410455"></p>
<p><img src="/2020/04/01/数据挖掘/1585710532350.png" alt="1585710532350"></p>
<p><img src="/2020/04/01/数据挖掘/1585710551806.png" alt="1585710551806"></p>
<h5 id="读取TXT格式"><a href="#读取TXT格式" class="headerlink" title="读取TXT格式"></a>读取TXT格式</h5><p><img src="/2020/04/01/数据挖掘/1585710664703.png" alt="1585710664703"></p>
<h4 id="从Excel直接获取数据"><a href="#从Excel直接获取数据" class="headerlink" title="从Excel直接获取数据"></a>从Excel直接获取数据</h4><p><img src="/2020/04/01/数据挖掘/1585710773419.png" alt="1585710773419"></p>
<p><img src="/2020/04/01/数据挖掘/1585710795936.png" alt="1585710795936"></p>
<p><img src="/2020/04/01/数据挖掘/1585710816961.png" alt="1585710816961"></p>
<h4 id="从其他统计软件中获取数据"><a href="#从其他统计软件中获取数据" class="headerlink" title="从其他统计软件中获取数据"></a>从其他统计软件中获取数据</h4><p>我们将使用foreign软件包中的相关函数，该软件包的主要功能即是读写SPSS、SAS、Minitab、<br>Stata、Systat等统计软件中的数据。</p>
<h5 id="从SPSS获取数据"><a href="#从SPSS获取数据" class="headerlink" title="从SPSS获取数据"></a>从SPSS获取数据</h5><p><img src="/2020/04/01/数据挖掘/1585710963416.png" alt="1585710963416"></p>
<p><img src="/2020/04/01/数据挖掘/1585710992751.png" alt="1585710992751"></p>
<p><img src="/2020/04/01/数据挖掘/1585711020984.png" alt="1585711020984"></p>
<p><img src="/2020/04/01/数据挖掘/1585711042365.png" alt="1585711042365"></p>
<h5 id="从SAS、Minitab、STATA、SYSTAT中获取数据"><a href="#从SAS、Minitab、STATA、SYSTAT中获取数据" class="headerlink" title="从SAS、Minitab、STATA、SYSTAT中获取数据"></a>从SAS、Minitab、STATA、SYSTAT中获取数据</h5><p><img src="/2020/04/01/数据挖掘/1585711134273.png" alt="1585711134273"></p>
<h3 id="获取数据库数据"><a href="#获取数据库数据" class="headerlink" title="获取数据库数据"></a>获取数据库数据</h3><p><img src="/2020/04/01/数据挖掘/1585711399514.png" alt="1585711399514"></p>
<p><img src="/2020/04/01/数据挖掘/1585711419648.png" alt="1585711419648"></p>
<p><img src="/2020/04/01/数据挖掘/1585711437360.png" alt="1585711437360"></p>
<p><img src="/2020/04/01/数据挖掘/1585711487670.png" alt="1585711487670"></p>
<p><img src="/2020/04/01/数据挖掘/1585711516518.png" alt="1585711516518"></p>
<p><img src="/2020/04/01/数据挖掘/1585711542616.png" alt="1585711542616"></p>
<h3 id="获取网页数据"><a href="#获取网页数据" class="headerlink" title="获取网页数据"></a>获取网页数据</h3><p><img src="/2020/04/01/数据挖掘/1585711889961.png" alt="1585711889961"></p>
<p><a href="http://stockdata.stock.hexun.com/2008en/zxcwzb.aspx?stockid=000002&amp;type=1&amp;date=2013.06.30" target="_blank" rel="noopener">http://stockdata.stock.hexun.com/2008en/zxcwzb.aspx?stockid=000002&amp;type=1&amp;date=2013.06.30</a></p>
<p><img src="/2020/04/01/数据挖掘/1585711961289.png" alt="1585711961289"></p>
<p><img src="/2020/04/01/数据挖掘/1585712253379.png" alt="1585712253379"></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="keyword">library</span>(XML)</span><br><span class="line">ul = <span class="string">"http://stockdata.stock.hexun.com/2008en/zxcwzb.aspx?stockid=000002&amp;type=1&amp;date=2013.06.30"</span></span><br><span class="line">tables1 = readHTMLTable(ul)</span><br><span class="line">names(tables1)</span><br></pre></td></tr></table></figure>
<p>[1] “NULL”  “NULL”  “NULL”  “NULL”</p>
<p>如上我们知道所读取结果共有4个部分，因此，可以分别查看tables1中4个维度中所储存的<br>信息，以下仅输出其中的第2、3维度的数据。</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">tables1[[<span class="number">2</span>]]</span><br></pre></td></tr></table></figure>
<p><img src="/2020/04/01/数据挖掘/1585712408039.png" alt="1585712408039"></p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">tables1[[<span class="number">3</span>]]</span><br></pre></td></tr></table></figure>
<p><img src="/2020/04/01/数据挖掘/1585712457342.png" alt="1585712457342"></p>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p><img src="/2020/04/01/数据挖掘/1585712504471.png" alt="1585712504471"></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>数据挖掘</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title>线性表,顺序表与数组</title>
    <url>/2020/03/05/%E7%BA%BF%E6%80%A7%E8%A1%A8-%E9%A1%BA%E5%BA%8F%E8%A1%A8%E4%B8%8E%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://blog.csdn.net/foreverhuylee/article/details/37813053?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">https://blog.csdn.net/foreverhuylee/article/details/37813053?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task</a></p>
<ol>
<li><p>数组就是相同数据类型的元素按一定顺序排列的集合。</p>
<p>一句话：就是物理上存储在一组联系的地址上。也称为数据结构中的物理结构。</p>
</li>
<li><p>线性表中数据元素之间的关系是一对一的关系，即除了第一个和最后一个数据元素之外，其它数据元素都是首尾相接的。</p>
<p>一句话：线性表是数据结构中的逻辑结构。可以存储在数组上，也可以存储在链表上。</p>
</li>
<li><p>线性表的结点按逻辑次序依次存放在一组地址连续的存储单元里的方法。用顺序存储方法存储的线性表简称为顺序表。</p>
<p>一句话：用数组来存储的线性表就是顺序表。</p>
</li>
</ol>
]]></content>
      <tags>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title>牛客-剑指offer</title>
    <url>/2020/03/05/%E7%89%9B%E5%AE%A2-%E5%89%91%E6%8C%87offer/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="二维数组中的查找"><a href="#二维数组中的查找" class="headerlink" title="二维数组中的查找"></a>二维数组中的查找</h4><p><a href="https://www.nowcoder.com/practice/abc3fe2ce8e146608e868a70efebf62e?tpId=13&amp;tqId=11154&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/abc3fe2ce8e146608e868a70efebf62e?tpId=13&amp;tqId=11154&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>在一个二维数组中（每个一维数组的长度相同），每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。</p>
<p><u>方法</u>：</p>
<p>从左下找</p>
<p><a href="https://www.nowcoder.com/questionTerminal/abc3fe2ce8e146608e868a70efebf62e?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/abc3fe2ce8e146608e868a70efebf62e?answerType=1&amp;f=discussion</a></p>
<p>对于左下角的值 m，m 是该行最小的数，是该列最大的数<br>每次将 m 和目标值 target 比较：</p>
<ol>
<li>当 m &lt; target，由于 m 已经是该行最大的元素，想要更大只有从列考虑，取值右移一位 </li>
<li>当 m &gt; target，由于 m 已经是该列最小的元素，想要更小只有从行考虑，取值上移一位 </li>
<li>当 m = target，找到该值，返回 true </li>
</ol>
<p>用某行最小或某列最大与 target 比较，每次可剔除一整行或一整列</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">Find</span><span class="params">(<span class="keyword">int</span> target, <span class="keyword">int</span> [][] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> r = array.length;</span><br><span class="line">        <span class="keyword">int</span> c = array[<span class="number">0</span>].length;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 左下角</span></span><br><span class="line">        <span class="keyword">int</span> cur_r = r - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> cur_c = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(cur_r &gt;= <span class="number">0</span> &amp;&amp; cur_c &lt;= c-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> cur = array[cur_r][cur_c];</span><br><span class="line">            <span class="keyword">if</span>(target == cur)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(target &lt; cur)</span><br><span class="line">                cur_r--;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(target &gt; cur)</span><br><span class="line">                cur_c++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>复杂度</u>：</p>
<p>时间复杂度：O(行高 + 列宽)<br>空间复杂度：O(1)</p>
<hr>
<h4 id="从尾到头打印链表"><a href="#从尾到头打印链表" class="headerlink" title="从尾到头打印链表"></a>从尾到头打印链表</h4><p><a href="https://www.nowcoder.com/practice/d0267f7f55b3412ba93bd35cfa8e8035?tpId=13&amp;tqId=11156&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/d0267f7f55b3412ba93bd35cfa8e8035?tpId=13&amp;tqId=11156&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入一个链表，按链表从尾到头的顺序返回一个ArrayList。</p>
<p><u>法一</u>：将链表翻转，再依次加入ArrayList</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*    public class ListNode &#123;</span></span><br><span class="line"><span class="comment">*        int val;</span></span><br><span class="line"><span class="comment">*        ListNode next = null;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*        ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">*            this.val = val;</span></span><br><span class="line"><span class="comment">*        &#125;</span></span><br><span class="line"><span class="comment">*    &#125;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayList&lt;Integer&gt; <span class="title">printListFromTailToHead</span><span class="params">(ListNode listNode)</span> </span>&#123;</span><br><span class="line">        ListNode cur = listNode;</span><br><span class="line">        ListNode prev = <span class="keyword">null</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(cur != <span class="keyword">null</span>)&#123;</span><br><span class="line">            ListNode tmp = cur.next;</span><br><span class="line">            cur.next = prev;</span><br><span class="line">            prev = cur;</span><br><span class="line">            cur = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        ArrayList&lt;Integer&gt; arr = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">while</span>(prev != <span class="keyword">null</span>)&#123;</span><br><span class="line">            arr.add(prev.val);</span><br><span class="line">            prev = prev.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>法二</u>：利用ArrayList的方法<code>add(int index, E element)</code>,每次将链表中的元素添加至索引0处</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">*    public class ListNode &#123;</span></span><br><span class="line"><span class="comment">*        int val;</span></span><br><span class="line"><span class="comment">*        ListNode next = null;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*        ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">*            this.val = val;</span></span><br><span class="line"><span class="comment">*        &#125;</span></span><br><span class="line"><span class="comment">*    &#125;</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayList&lt;Integer&gt; <span class="title">printListFromTailToHead</span><span class="params">(ListNode listNode)</span> </span>&#123;</span><br><span class="line">        ListNode cur = listNode;</span><br><span class="line">        ArrayList&lt;Integer&gt; arr = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(cur != <span class="keyword">null</span>)&#123;</span><br><span class="line">            arr.add(<span class="number">0</span>,cur.val);</span><br><span class="line">            cur = cur.next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> arr;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>复杂度</u>：</p>
<p>时间复杂度：O(n)<br>空间复杂度：O(n)</p>
<a id="more"></a>
<hr>
<h4 id="重建二叉树"><a href="#重建二叉树" class="headerlink" title="重建二叉树"></a>重建二叉树</h4><p><a href="https://www.nowcoder.com/practice/8a19cbe657394eeaac2f6ea9b0f6fcf6?tpId=13&amp;tqId=11157&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/8a19cbe657394eeaac2f6ea9b0f6fcf6?tpId=13&amp;tqId=11157&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入某二叉树的前序遍历和中序遍历的结果，请重建出该二叉树。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。例如输入前序遍历序列{1,2,4,7,3,5,6,8}和中序遍历序列{4,7,2,1,5,3,8,6}，则重建二叉树并返回。</p>
<p><u>方法</u>：</p>
<p>递归</p>
<p>根据中序遍历和前序遍历可以确定二叉树，具体过程为：</p>
<ol>
<li>根据前序序列第一个结点确定根结点</li>
<li>根据根结点在中序序列中的位置分割出左右两个子序列</li>
<li>对左子树和右子树分别递归使用同样的方法继续分解</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for binary tree</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">reConstructBinaryTree</span><span class="params">(<span class="keyword">int</span> [] pre,<span class="keyword">int</span> [] in)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(pre.length==<span class="number">0</span> || in.length==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        TreeNode root = <span class="keyword">new</span> TreeNode(pre[<span class="number">0</span>]);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; in.length;i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(in[i]==pre[<span class="number">0</span>])&#123;</span><br><span class="line">                <span class="comment">//copyOfRange 函数，左闭右开</span></span><br><span class="line">                root.left = reConstructBinaryTree(Arrays.copyOfRange(pre,<span class="number">1</span>,i+<span class="number">1</span>),Arrays.copyOfRange(in,<span class="number">0</span>,i));</span><br><span class="line">                root.right = reConstructBinaryTree(Arrays.copyOfRange(pre,i+<span class="number">1</span>,pre.length),Arrays.copyOfRange(in,i+<span class="number">1</span>,in.length));</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>复杂度</u>：</p>
<p>时间复杂度：O(n)<br>空间复杂度：O(n)</p>
<hr>
<h4 id="用两个栈实现队列"><a href="#用两个栈实现队列" class="headerlink" title="用两个栈实现队列"></a>用两个栈实现队列</h4><p><a href="https://www.nowcoder.com/practice/54275ddae22f475981afa2244dd448c6?tpId=13&amp;tqId=11158&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/54275ddae22f475981afa2244dd448c6?tpId=13&amp;tqId=11158&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述：</u></p>
<p>用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    Stack&lt;Integer&gt; stack1 = <span class="keyword">new</span> Stack&lt;Integer&gt;();</span><br><span class="line">    Stack&lt;Integer&gt; stack2 = <span class="keyword">new</span> Stack&lt;Integer&gt;();</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> node)</span> </span>&#123;</span><br><span class="line">        stack1.push(node);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(stack2.empty())&#123; </span><br><span class="line">        <span class="comment">// 注意这里有个stack2要是empty的条件，若stack2不是empty却往里push stack1中的元素，会出错</span></span><br><span class="line">            <span class="keyword">while</span>(!stack1.empty())&#123;</span><br><span class="line">                stack2.push(stack1.pop());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack2.pop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="旋转数组的最小数字"><a href="#旋转数组的最小数字" class="headerlink" title="旋转数组的最小数字"></a>旋转数组的最小数字</h4><p><a href="https://www.nowcoder.com/practice/9f3231a991af4f55b95579b44b7a01ba?tpId=13&amp;tqId=11159&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/9f3231a991af4f55b95579b44b7a01ba?tpId=13&amp;tqId=11159&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。<br>输入一个非递减排序的数组的一个旋转，输出旋转数组的最小元素。<br>例如数组{3,4,5,1,2}为{1,2,3,4,5}的一个旋转，该数组的最小值为1。<br>NOTE：给出的所有元素都大于0，若数组大小为0，请返回0。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minNumberInRotateArray</span><span class="params">(<span class="keyword">int</span> [] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(array.length==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> end = array.length-<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(array[start]&lt;array[end])</span><br><span class="line">            <span class="keyword">return</span> array[start];</span><br><span class="line">        <span class="keyword">while</span>(start &lt; end)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (start+end)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(mid&gt;<span class="number">1</span> &amp;&amp; array[mid-<span class="number">1</span>]&gt;array[mid])</span><br><span class="line">                <span class="keyword">return</span> array[mid];</span><br><span class="line">            <span class="keyword">if</span>(array[mid]&gt;array[<span class="number">0</span>])</span><br><span class="line">                <span class="comment">// 往右</span></span><br><span class="line">                start = mid+<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(array[mid]&lt;array[<span class="number">0</span>])</span><br><span class="line">                <span class="comment">// 往左</span></span><br><span class="line">                end = mid-<span class="number">1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                start++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> array[start];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="斐波那契数列"><a href="#斐波那契数列" class="headerlink" title="斐波那契数列"></a>斐波那契数列</h4><p><a href="https://www.nowcoder.com/practice/c6c7742f5ba7442aada113136ddea0c3?tpId=13&amp;tqId=11160&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/c6c7742f5ba7442aada113136ddea0c3?tpId=13&amp;tqId=11160&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项（从0开始，第0项为0）。</p>
<p>n&lt;=39</p>
<p><u>方法</u>：</p>
<p>优化动态规划</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">Fibonacci</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(n==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> F1 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> F2 = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">while</span>(i&lt;=n)&#123;</span><br><span class="line">            <span class="keyword">int</span> F3 = F1 + F2;</span><br><span class="line">            F1 = F2;</span><br><span class="line">            F2 = F3;</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>复杂度</u>：</p>
<p>时间复杂度：O(n)<br>空间复杂度：O(1)</p>
<hr>
<h4 id="跳台阶"><a href="#跳台阶" class="headerlink" title="跳台阶"></a>跳台阶</h4><p><a href="https://www.nowcoder.com/practice/8c82a5b80378478f9484d87d1c5f12a4?tpId=13&amp;tqId=11161&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/8c82a5b80378478f9484d87d1c5f12a4?tpId=13&amp;tqId=11161&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>一只青蛙一次可以跳上1级台阶，也可以跳上2级。求该青蛙跳上一个n级的台阶总共有多少种跳法（先后次序不同算不同的结果）。</p>
<p><u>方法</u>：</p>
<p>优化动态规划</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">JumpFloor</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> F1 = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> F2 = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> F3 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= target; i++)&#123;</span><br><span class="line">            F3 = F1 + F2;</span><br><span class="line">            F1 = F2;</span><br><span class="line">            F2 = F3;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> F2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><u>复杂度</u>：</p>
<p>时间复杂度：O(n)<br>空间复杂度：O(1)</p>
<hr>
<h4 id="变态跳台阶"><a href="#变态跳台阶" class="headerlink" title="变态跳台阶"></a>变态跳台阶</h4><p><a href="https://www.nowcoder.com/practice/22243d016f6b47f2a6928b4313c85387?tpId=13&amp;tqId=11162&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/22243d016f6b47f2a6928b4313c85387?tpId=13&amp;tqId=11162&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>一只青蛙一次可以跳上1级台阶，也可以跳上2级……它也可以跳上n级。求该青蛙跳上一个n级的台阶总共有多少种跳法。</p>
<p><u>方法</u>：</p>
<p>易知 f(n)=f(n-1)+f(n-2)+……f(1)<br>f(n-1)=f(n-2)+……f(1)<br>两式相减得f(n)=2f(n-1)</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">JumpFloorII</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> f1 = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> f2 = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= target; i++)&#123;</span><br><span class="line">            f2 = <span class="number">2</span>*f1;</span><br><span class="line">            f1 = f2;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="矩形覆盖"><a href="#矩形覆盖" class="headerlink" title="矩形覆盖"></a>矩形覆盖</h4><p><a href="https://www.nowcoder.com/practice/72a5a919508a4251859fb2cfb987a0e6?tpId=13&amp;tqId=11163&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/72a5a919508a4251859fb2cfb987a0e6?tpId=13&amp;tqId=11163&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>:</p>
<p>我们可以用2*1的小矩形横着或者竖着去覆盖更大的矩形。请问用n个2*1的小矩形无重叠地覆盖一个2*n的大矩形，总共有多少种方法？</p>
<p>比如n=3时，2*3的矩形块有3种覆盖方法：</p>
<p><img src="/2020/03/05/牛客-剑指offer/1583470479650.png" alt="1583470479650"></p>
<p><u>方法：迭代</u></p>
<p>类似斐波那契数列</p>
<p>f(n) = f(n-1) + f(n-2)</p>
<p><img src="/2020/03/05/牛客-剑指offer/20200306-162012.jpg" alt="20200306-162012"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">RectCover</span><span class="params">(<span class="keyword">int</span> target)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(target==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> f0=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> f1=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> f2=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i &lt;= target; i++)&#123;</span><br><span class="line">            f2 = f0 + f1;</span><br><span class="line">            f0 = f1;</span><br><span class="line">            f1 = f2;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> f1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="二进制中1的个数"><a href="#二进制中1的个数" class="headerlink" title="二进制中1的个数"></a>二进制中1的个数</h4><p><a href="https://www.nowcoder.com/practice/8ee967e43c2c4ec193b040ea7fbb10b8?tpId=13&amp;tqId=11164&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/8ee967e43c2c4ec193b040ea7fbb10b8?tpId=13&amp;tqId=11164&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入一个整数，输出该数二进制表示中1的个数。其中负数用补码表示。</p>
<p>（注：输入的是二进制表示形式）</p>
<p><u>方法</u>：</p>
<p>一个二进制数减去1，再和原二进制数做<code>与运算</code>，会把该数最右边的1变为0，那么一个整数的二进制有多少个1，就可以进行多少次这样的操作。</p>
<p><a href="https://www.nowcoder.com/questionTerminal/8ee967e43c2c4ec193b040ea7fbb10b8?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/8ee967e43c2c4ec193b040ea7fbb10b8?answerType=1&amp;f=discussion</a></p>
<p>举个例子：一个二进制数1100，减去1后，结果为1011。我们发现减1的结果是把最右边的一个1开始的所有位都取反了。这个时候如果我们再把原来的整数和减去1之后的结果做与运算，从原来整数最右边一个1那一位开始所有位都会变成0。如1100&amp;1011=1000.  </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">NumberOf1</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(n!=<span class="number">0</span>)&#123;</span><br><span class="line">            n = n &amp; (n-<span class="number">1</span>);</span><br><span class="line">            count++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="数值的整数次方"><a href="#数值的整数次方" class="headerlink" title="数值的整数次方"></a>数值的整数次方</h4><p><a href="https://www.nowcoder.com/practice/1a834e5e3e1a4b7ba251417554e07c00?tpId=13&amp;tqId=11165&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/1a834e5e3e1a4b7ba251417554e07c00?tpId=13&amp;tqId=11165&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>给定一个double类型的浮点数base和int类型的整数exponent。求base的exponent次方。</p>
<p>保证base和exponent不同时为0</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">Power</span><span class="params">(<span class="keyword">double</span> base, <span class="keyword">int</span> exponent)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> flag = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(exponent&lt;<span class="number">0</span>)&#123;</span><br><span class="line">            flag = <span class="keyword">true</span>;</span><br><span class="line">            exponent = - exponent;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">double</span> ans = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(exponent != <span class="number">0</span>)&#123;</span><br><span class="line">            ans *= base;</span><br><span class="line">            exponent--;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> flag? <span class="number">1</span>/ans : ans;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="调整数组顺序使奇数位于偶数前面"><a href="#调整数组顺序使奇数位于偶数前面" class="headerlink" title="调整数组顺序使奇数位于偶数前面"></a>调整数组顺序使奇数位于偶数前面</h4><p><u>题目描述</u>：</p>
<p>输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。</p>
<p><u>思路</u>：</p>
<p><a href="https://www.nowcoder.com/questionTerminal/beb5aa231adc45b2a5dcc5b62c93f593?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/beb5aa231adc45b2a5dcc5b62c93f593?answerType=1&amp;f=discussion</a></p>
<ul>
<li><code>i++</code>往前走，碰到偶数停下来，<code>j=i+1</code></li>
<li>若 <code>a[j]</code>为偶数，<code>j++</code>前进，直到碰到奇数<ul>
<li><code>a[j]</code>对应的奇数插到<code>a[i]</code>位置，<code>j</code>经过的<code>j-1</code>个偶数依次后移</li>
</ul>
</li>
</ul>
<ul>
<li>如果<code>j==len-1</code>时还没碰到奇数，证明<code>i</code>和<code>j</code>之间都为偶数了，完成整个移动</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reOrderArray</span><span class="params">(<span class="keyword">int</span> [] array)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(array.length&lt;=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> ;</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(i &lt; array.length)&#123;</span><br><span class="line">            <span class="comment">// i遇到偶数停下</span></span><br><span class="line">            <span class="keyword">if</span>(array[i]%<span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">int</span> j = i + <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">                <span class="comment">// j遇到奇数停下</span></span><br><span class="line">                <span class="keyword">while</span>(array[j]%<span class="number">2</span>==<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">if</span>(j==array.length-<span class="number">1</span>)</span><br><span class="line">                        <span class="keyword">return</span> ;</span><br><span class="line">                    j++;</span><br><span class="line">                    count++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">int</span> temp = array[i];</span><br><span class="line">                array[i] = array[j];</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k=<span class="number">0</span>; k &lt; count; k++)&#123;</span><br><span class="line">                    array[j-k] = array[j-k-<span class="number">1</span>];</span><br><span class="line">                &#125;</span><br><span class="line">                array[j-count] = temp;</span><br><span class="line">            &#125;</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="链表中第k个结点"><a href="#链表中第k个结点" class="headerlink" title="链表中第k个结点"></a>链表中第k个结点</h4><p><a href="https://www.nowcoder.com/practice/529d3ae5a407492994ad2a246518148a?tpId=13&amp;tqId=11167&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/529d3ae5a407492994ad2a246518148a?tpId=13&amp;tqId=11167&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入一个链表，输出该链表中倒数第k个结点。</p>
<p><u>方法</u>：快慢指针</p>
<p>快指针先往前走k步，注意判断边界，然后快慢一起走，当快指针为null的时候，慢指针走到了倒数第k个节点</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">public class ListNode &#123;</span></span><br><span class="line"><span class="comment">    int val;</span></span><br><span class="line"><span class="comment">    ListNode next = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">FindKthToTail</span><span class="params">(ListNode head,<span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        ListNode slow = head;</span><br><span class="line">        ListNode fast = head;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; k; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(fast==<span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            fast = fast.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(fast!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            slow = slow.next;</span><br><span class="line">            fast = fast.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> slow;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="反转链表"><a href="#反转链表" class="headerlink" title="反转链表"></a>反转链表</h4><p><a href="https://www.nowcoder.com/practice/75e878df47f24fdc9dc3e400ec6058ca?tpId=13&amp;tqId=11168&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/75e878df47f24fdc9dc3e400ec6058ca?tpId=13&amp;tqId=11168&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入一个链表，反转链表后，输出新链表的表头。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">public class ListNode &#123;</span></span><br><span class="line"><span class="comment">    int val;</span></span><br><span class="line"><span class="comment">    ListNode next = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">ReverseList</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        ListNode cur = head;</span><br><span class="line">        ListNode prev = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span>(cur!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            ListNode tmp = cur.next;</span><br><span class="line">            cur.next = prev;</span><br><span class="line">            prev = cur;</span><br><span class="line">            cur = tmp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> prev;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="合并两个排序的链表"><a href="#合并两个排序的链表" class="headerlink" title="合并两个排序的链表"></a>合并两个排序的链表</h4><p><a href="https://www.nowcoder.com/practice/d8b6b4358f774294a89de2a6ac4d9337?tpId=13&amp;tqId=11169&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/d8b6b4358f774294a89de2a6ac4d9337?tpId=13&amp;tqId=11169&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入两个单调递增的链表，输出两个链表合成后的链表，当然我们需要合成后的链表满足单调不减规则。</p>
<p><u>方法</u>：递归</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">public class ListNode &#123;</span></span><br><span class="line"><span class="comment">    int val;</span></span><br><span class="line"><span class="comment">    ListNode next = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    ListNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">Merge</span><span class="params">(ListNode list1,ListNode list2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(list1==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> list2;</span><br><span class="line">        <span class="keyword">if</span>(list2==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> list1;</span><br><span class="line">        <span class="keyword">if</span>(list1.val &lt; list2.val)&#123;</span><br><span class="line">            list1.next = Merge(list1.next,list2);</span><br><span class="line">            <span class="comment">//不要忘记这个return</span></span><br><span class="line">            <span class="keyword">return</span> list1;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            list2.next = Merge(list1, list2.next);</span><br><span class="line">            <span class="comment">//不要忘记这个return</span></span><br><span class="line">            <span class="keyword">return</span> list2;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="树的子结构"><a href="#树的子结构" class="headerlink" title="树的子结构"></a>树的子结构</h4><p><a href="https://www.nowcoder.com/practice/6e196c44c7004d15b1610b9afca8bd88?tpId=13&amp;tqId=11170&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/6e196c44c7004d15b1610b9afca8bd88?tpId=13&amp;tqId=11170&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入两棵二叉树A，B，判断B是不是A的子结构。（ps：我们约定空树不是任意一个树的子结构）</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">public class TreeNode &#123;</span></span><br><span class="line"><span class="comment">    int val = 0;</span></span><br><span class="line"><span class="comment">    TreeNode left = null;</span></span><br><span class="line"><span class="comment">    TreeNode right = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    public TreeNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">HasSubtree</span><span class="params">(TreeNode root1,TreeNode root2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root1==<span class="keyword">null</span> || root2==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> judge(root1, root2) || judge(root1.left, root2) ||judge(root2.right, root2);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">judge</span><span class="params">(TreeNode root1, TreeNode root2)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root2==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span>(root1==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span>(root1.val==root2.val)</span><br><span class="line">            <span class="keyword">return</span> judge(root1.left, root2.left) &amp;&amp; judge(root1.right, root2.right);</span><br><span class="line">        <span class="keyword">return</span> judge(root1.left, root2) || judge(root1.right, root2);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意与子树的区别：</p>
<p><a href="https://www.nowcoder.com/questionTerminal/6e196c44c7004d15b1610b9afca8bd88?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/6e196c44c7004d15b1610b9afca8bd88?answerType=1&amp;f=discussion</a></p>
<hr>
<h4 id="二叉树的镜像"><a href="#二叉树的镜像" class="headerlink" title="二叉树的镜像"></a>二叉树的镜像</h4><p><a href="https://www.nowcoder.com/practice/564f4c26aa584921bc75623e48ca3011?tpId=13&amp;tqId=11171&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/564f4c26aa584921bc75623e48ca3011?tpId=13&amp;tqId=11171&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>操作给定的二叉树，将其变换为源二叉树的镜像。</p>
<p><u>输入描述</u>:</p>
<blockquote>
<p>二叉树的镜像定义：</p>
<p>​        源二叉树<br>​            8<br>​           /  \<br>​          6   10<br>​         / \  / \<br>​        5  7 9 11<br>​        镜像二叉树<br>​            8<br>​           /  \<br>​          10   6<br>​         / \  / \<br>​        11 9 7  5</p>
</blockquote>
<p><u>思路</u>：</p>
<p>交换左右子树的节点，然后递归调用该方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">public class TreeNode &#123;</span></span><br><span class="line"><span class="comment">    int val = 0;</span></span><br><span class="line"><span class="comment">    TreeNode left = null;</span></span><br><span class="line"><span class="comment">    TreeNode right = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    public TreeNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">Mirror</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> ;</span><br><span class="line">        TreeNode tmp = root.left;</span><br><span class="line">        root.left = root.right;</span><br><span class="line">        root.right = tmp;</span><br><span class="line">        Mirror(root.left);</span><br><span class="line">        Mirror(root.right);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="顺时针打印矩阵"><a href="#顺时针打印矩阵" class="headerlink" title="顺时针打印矩阵"></a>顺时针打印矩阵</h4><p><a href="https://www.nowcoder.com/practice/9b4c81a02cd34f76be2659fa0d54342a?tpId=13&amp;tqId=11172&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/9b4c81a02cd34f76be2659fa0d54342a?tpId=13&amp;tqId=11172&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>:</p>
<p>输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字，例如，如果输入如下4 X 4矩阵： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 则依次打印出数字1,2,3,4,8,12,16,15,14,13,9,5,6,7,11,10.</p>
<p><u>思路</u>：</p>
<p><a href="https://www.nowcoder.com/questionTerminal/9b4c81a02cd34f76be2659fa0d54342a?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/9b4c81a02cd34f76be2659fa0d54342a?answerType=1&amp;f=discussion</a></p>
<ol>
<li>向右走存入整行的值，当存入后，该行再也不会被遍历，代表上边界的 up 加一，同时判断是否和代表下边界的 down 交错 </li>
<li>向下走存入整列的值，当存入后，该列再也不会被遍历，代表右边界的 right 减一，同时判断是否和代表左边界的 left 交错 </li>
<li>向左走存入整行的值，当存入后，该行再也不会被遍历，代表下边界的 down 减一，同时判断是否和代表上边界的 up 交错 </li>
<li>向上走存入整列的值，当存入后，该列再也不会被遍历，代表左边界的 left 加一，同时判断是否和代表右边界的 right 交错</li>
</ol>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayList&lt;Integer&gt; <span class="title">printMatrix</span><span class="params">(<span class="keyword">int</span> [][] matrix)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(matrix.length==<span class="number">0</span> || matrix[<span class="number">0</span>].length==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> up = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = matrix[<span class="number">0</span>].length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> down = matrix.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = left; i &lt;= right; i++)</span><br><span class="line">                res.add(matrix[up][i]);</span><br><span class="line">            up++;</span><br><span class="line">            <span class="comment">// 判断是否出界</span></span><br><span class="line">            <span class="keyword">if</span>(up&gt;down)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = up; i &lt;= down; i++)</span><br><span class="line">                res.add(matrix[i][right]);</span><br><span class="line">            right--;</span><br><span class="line">            <span class="comment">// 判断是否出界</span></span><br><span class="line">            <span class="keyword">if</span>(right&lt;left)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = right; i &gt;= left; i--)</span><br><span class="line">                res.add(matrix[down][i]);</span><br><span class="line">            down--;</span><br><span class="line">            <span class="comment">// 判断是否出界</span></span><br><span class="line">            <span class="keyword">if</span>(down&lt;up)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = down; i&gt;=up; i--)</span><br><span class="line">                res.add(matrix[i][left]);</span><br><span class="line">            left++;</span><br><span class="line">            <span class="comment">// 判断是否出界</span></span><br><span class="line">            <span class="keyword">if</span>(left&gt;right)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="包含min函数的栈"><a href="#包含min函数的栈" class="headerlink" title="包含min函数的栈"></a>包含min函数的栈</h4><p><a href="https://www.nowcoder.com/practice/4c776177d2c04c2494f2555c9fcc1e49?tpId=13&amp;tqId=11173&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/4c776177d2c04c2494f2555c9fcc1e49?tpId=13&amp;tqId=11173&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>定义栈的数据结构，请在该类型中实现一个能够得到栈中所含最小元素的min函数（时间复杂度应为O(1)）。</p>
<p>注意：保证测试中不会当栈为空的时候，对栈调用pop()或者min()或者top()方法。</p>
<p><u>思路</u>：</p>
<p>关键在于若用一个int来保存最小值，被pop出去了后怎么办：</p>
<p>使用两个栈，一个保存所有的元素，另一个用来保存历史最小值。</p>
<p>当pop()时，检查stack与minStack的栈顶元素是否相同，若相同则都pop()，否则只需pop stack.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    Stack&lt;Integer&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">    Stack&lt;Integer&gt; minStack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> node)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(stack.empty() || node &lt;= stack.peek())</span><br><span class="line">            minStack.push(node);</span><br><span class="line">        stack.push(node);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(stack.peek()==minStack.peek())</span><br><span class="line">            minStack.pop();</span><br><span class="line">        stack.pop();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> stack.peek();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">min</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> minStack.peek();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="栈的压入、弹出序列"><a href="#栈的压入、弹出序列" class="headerlink" title="栈的压入、弹出序列"></a>栈的压入、弹出序列</h4><p><a href="https://www.nowcoder.com/practice/d77d11405cc7470d82554cb392585106?tpId=13&amp;tqId=11174&amp;tPage=2&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/d77d11405cc7470d82554cb392585106?tpId=13&amp;tqId=11174&amp;tPage=2&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>输入两个整数序列，第一个序列表示栈的压入顺序，请判断第二个序列是否可能为该栈的弹出顺序。假设压入栈的所有数字均不相等。例如序列1,2,3,4,5是某栈的压入顺序，序列4,5,3,2,1是该压栈序列对应的一个弹出序列，但4,3,5,1,2就不可能是该压栈序列的弹出序列。（注意：这两个序列的长度是相等的）</p>
<p><u>思路</u>：</p>
<p>新建一个栈，将数组A压入栈中，只要栈顶元素等于数组B时，就将其出栈，当循环结束时，判断栈是否为空，若为空则返回true.</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Stack;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">IsPopOrder</span><span class="params">(<span class="keyword">int</span> [] pushA,<span class="keyword">int</span> [] popA)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(pushA.length==<span class="number">0</span> || popA.length==<span class="number">0</span> || pushA.length != popA.length)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        Stack&lt;Integer&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; pushA.length; i++)&#123;</span><br><span class="line">            stack.push(pushA[i]);</span><br><span class="line">            <span class="keyword">while</span>(!stack.empty() &amp;&amp; stack.peek()==popA[j])&#123;</span><br><span class="line">                stack.pop();</span><br><span class="line">                j++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stack.empty();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="从上往下打印二叉树"><a href="#从上往下打印二叉树" class="headerlink" title="从上往下打印二叉树"></a>从上往下打印二叉树</h4><p><a href="https://www.nowcoder.com/practice/7fe2212963db4790b57431d9ed259701?tpId=13&amp;tqId=11175&amp;tPage=2&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">https://www.nowcoder.com/practice/7fe2212963db4790b57431d9ed259701?tpId=13&amp;tqId=11175&amp;tPage=2&amp;rp=2&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking</a></p>
<p><u>题目描述</u>：</p>
<p>从上往下打印出二叉树的每个节点，同层节点从左至右打印。</p>
<p><u>思路</u>：</p>
<p><a href="https://www.nowcoder.com/questionTerminal/7fe2212963db4790b57431d9ed259701?answerType=1&amp;f=discussion" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/7fe2212963db4790b57431d9ed259701?answerType=1&amp;f=discussion</a></p>
<p>每一次打印一个节点的时候，如果该节点有子节点，则把该节点的子节点放到一个队列的尾部。接下来到对队列的头部取出最早进入队列的节点放到ArrayList 中，重复前面的操作，直至队列为空。  </p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.ArrayList;</span><br><span class="line"><span class="keyword">import</span> java.util.Queue;</span><br><span class="line"><span class="keyword">import</span> java.util.LinkedList;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">public class TreeNode &#123;</span></span><br><span class="line"><span class="comment">    int val = 0;</span></span><br><span class="line"><span class="comment">    TreeNode left = null;</span></span><br><span class="line"><span class="comment">    TreeNode right = null;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    public TreeNode(int val) &#123;</span></span><br><span class="line"><span class="comment">        this.val = val;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    &#125;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">&#125;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ArrayList&lt;Integer&gt; <span class="title">PrintFromTopToBottom</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;Integer&gt; res = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> res;</span><br><span class="line">        Queue&lt;TreeNode&gt; queue = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        queue.offer(root);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(!queue.isEmpty())&#123;</span><br><span class="line">            TreeNode cur = queue.poll();</span><br><span class="line">            res.add(cur.val);</span><br><span class="line">            <span class="keyword">if</span>(cur.left!=<span class="keyword">null</span>)</span><br><span class="line">                queue.offer(cur.left);</span><br><span class="line">            <span class="keyword">if</span>(cur.right!=<span class="keyword">null</span>)</span><br><span class="line">                queue.offer(cur.right);</span><br><span class="line">        &#125;    </span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>pip命令</title>
    <url>/2020/02/25/pip%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="安装包"><a href="#安装包" class="headerlink" title="安装包"></a>安装包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install package-name</span><br></pre></td></tr></table></figure>
<p>若安装过程中出现[WinError 5]错误，可尝试使用<code>pip install --user package-name</code></p>
<p>参考<a href="https://www.lizenghai.com/archives/585.html" target="_blank" rel="noopener">https://www.lizenghai.com/archives/585.html</a></p>
<h4 id="所有已安装的包"><a href="#所有已安装的包" class="headerlink" title="所有已安装的包"></a>所有已安装的包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure>
<h4 id="查看某个已安装包"><a href="#查看某个已安装包" class="headerlink" title="查看某个已安装包"></a>查看某个已安装包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip show package_name</span><br></pre></td></tr></table></figure>
<h4 id="检查哪些包需要更新"><a href="#检查哪些包需要更新" class="headerlink" title="检查哪些包需要更新"></a>检查哪些包需要更新</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip list --outdated</span><br></pre></td></tr></table></figure>
<h4 id="升级包"><a href="#升级包" class="headerlink" title="升级包"></a>升级包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install --upgrade package_name</span><br></pre></td></tr></table></figure>
<h4 id="安装某个版本的包"><a href="#安装某个版本的包" class="headerlink" title="安装某个版本的包"></a>安装某个版本的包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install numpy==1.18</span><br></pre></td></tr></table></figure>
<h4 id="卸载包"><a href="#卸载包" class="headerlink" title="卸载包"></a>卸载包</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip uninstall package_name</span><br></pre></td></tr></table></figure>
<p>使用pip –help命令可以查看pip帮助手册</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Computer Vision</title>
    <url>/2020/02/18/Computer-Vision/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>来源于<a href="https://www.analyticsvidhya.com/blog/2020/01/computer-vision-learning-path-2020/?utm_source=feedburner&amp;utm_medium=email&amp;utm_campaign=Feed%3A+AnalyticsVidhya+(Analytics+Vidhya" target="_blank" rel="noopener">Here’s your Learning Path to Master Computer Vision in 2020</a>)</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><h3 id="Face-Recognition"><a href="#Face-Recognition" class="headerlink" title="Face Recognition"></a>Face Recognition</h3><p><img src="/2020/02/18/Computer-Vision/1581936373011.png" alt="1581936373011"></p>
<h3 id="Types-of-computer-vision"><a href="#Types-of-computer-vision" class="headerlink" title="Types of computer vision"></a>Types of computer vision</h3><p><img src="/2020/02/18/Computer-Vision/1581936472914.png" alt="1581936472914"></p>
<h2 id="2-Image-Preprocessing"><a href="#2-Image-Preprocessing" class="headerlink" title="2. Image Preprocessing"></a>2. Image Preprocessing</h2><h3 id="2-1-Three-Beginner-Friendly-Techniques-to-Extract-Features-from-Images"><a href="#2-1-Three-Beginner-Friendly-Techniques-to-Extract-Features-from-Images" class="headerlink" title="2.1 Three Beginner-Friendly Techniques to Extract Features from Images"></a>2.1 Three Beginner-Friendly Techniques to Extract Features from Images</h3><p><a href="https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2019/08/3-techniques-extract-features-from-image-data-machine-learning-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<h4 id="2-1-1-How-do-Machines-Store-Images"><a href="#2-1-1-How-do-Machines-Store-Images" class="headerlink" title="2.1.1 How do Machines Store Images?"></a>2.1.1 How do Machines Store Images?</h4><p>Machines store images in the form of a matrix of numbers. The size of this matrix depends on the number of pixels we have in any given image.</p>
<blockquote>
<p><em>Let’s say the dimensions of an image are 180 x 200 or n x m. These dimensions are basically the number of pixels in the image (height x width).</em></p>
</blockquote>
<p><strong>These numbers, or the pixel values, denote the intensity or brightness of the pixel.</strong> <span style="color:red">Smaller numbers (closer to zero) represent black, and larger numbers (closer to 255) denote white. </span>You’ll understand whatever we have learned so far by analyzing the below image.</p>
<p>The dimensions of the below image are 22 x 16, which you can verify by counting the number of pixels:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-16.png" alt="reading image data machine learning"></p>
<blockquote>
<p><em>A colored image is typically composed of multiple colors and almost all colors can be generated from three primary colors – red, green and blue.</em></p>
</blockquote>
<p>In the case of a colored image, there are three Matrices (or channels) – Red, Green, and Blue. <strong>Each matrix has values between 0-255 representing the intensity of the color for that pixel.</strong> Consider the below image to understand this concept:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-41.png" alt="Channels in Images"></p>
<p>The three channels are superimposed (叠加) to form a colored image.</p>
<p><em>Note that these are not the original pixel values for the given image as the original matrix would be very large and difficult to visualize. Also, there are various other formats in which the images are stored. RGB is the most popular one and hence I have addressed it here. You can read more about the other popular formats <a href="https://www.w3schools.com/cssref/css_colors_legal.asp" target="_blank" rel="noopener">here</a>.</em></p>
<h4 id="2-1-2-Reading-Image-Data-in-Python"><a href="#2-1-2-Reading-Image-Data-in-Python" class="headerlink" title="2.1.2 Reading Image Data in Python"></a>2.1.2 Reading Image Data in Python</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread, imshow</span><br><span class="line"></span><br><span class="line">image = imread(<span class="string">'image_8_original.png'</span>, as_gray=<span class="literal">True</span>)</span><br><span class="line">imshow(image)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_1.png" alt="image data machine learning"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#checking image shape </span></span><br><span class="line">image.shape, image</span><br></pre></td></tr></table></figure>
<p>(28,28)</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_2-300x289.png" alt="image data machine learning"></p>
<p>Let’s now explore various methods of using pixel values as features.</p>
<h4 id="2-1-3-Method-1-Grayscale-Pixel-Values-as-Features"><a href="#2-1-3-Method-1-Grayscale-Pixel-Values-as-Features" class="headerlink" title="2.1.3 Method #1: Grayscale Pixel Values as Features"></a>2.1.3 Method #1: Grayscale Pixel Values as Features</h4><blockquote>
<p><em>The simplest way to create features from an image is to use these raw pixel values as separate features.</em></p>
</blockquote>
<p>The number of features will be the same as the number of pixels.</p>
<p>How do we arrange these pixels as features? Well, we can simply append every pixel value one after the other to generate a feature vector. This is illustrated in the image below:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-52.png" alt="pixel features machine learning"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image = imread(<span class="string">'puppy.jpeg'</span>, as_gray=<span class="literal">True</span>) </span><br><span class="line">image.shape, imshow(image)</span><br></pre></td></tr></table></figure>
<p>(660, 450)</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_3.png" alt="image data machine learning"></p>
<p>The image shape here is 660 x 450. Hence, the number of features should be 297,000. We can generate this using the <code>reshape</code> function from NumPy where we specify the dimension of the image:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#pixel features</span></span><br><span class="line">features = np.reshape(image, (<span class="number">660</span>*<span class="number">450</span>))</span><br><span class="line">features.shape, features</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(297000,)</span><br><span class="line">array([0.96470588, 0.96470588, 0.96470588, ..., 0.96862745, 0.96470588,</span><br><span class="line">       0.96470588])</span><br></pre></td></tr></table></figure>
<p>But here, we only had a single channel or a grayscale image. Can we do the same for a colored image? Let’s find out!</p>
<h4 id="2-1-4-Method-2-Mean-Pixel-Value-of-Channels-Colored-Image"><a href="#2-1-4-Method-2-Mean-Pixel-Value-of-Channels-Colored-Image" class="headerlink" title="2.1.4 Method #2: Mean Pixel Value of Channels (Colored Image)"></a>2.1.4 Method #2: Mean Pixel Value of Channels (Colored Image)</h4><p>While reading the image in the previous section, we had set the parameter <em>‘as_gray = True’</em>. So we only had one channel in the image and we could easily append the pixel values. Let us remove the parameter and load the image again:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image = imread(<span class="string">'puppy.jpeg'</span>) </span><br><span class="line">image.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(660, 450, 3)</span><br></pre></td></tr></table></figure>
<p>This time, the image has a dimension (660, 450, 3), where 3 is the number of channels. We can go ahead and create the features as we did previously. The number of features, in this case, will be 660*450*3 = 891,000.</p>
<p>Alternatively, here is another approach we can use:</p>
<blockquote>
<p><em>Instead of using the pixel values from the three channels separately, we can generate a new matrix that has the mean value of pixels from all three channels.</em></p>
</blockquote>
<p>The image below will give you even more clarity around this idea:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-6.png" alt="image pixel features"></p>
<p>By doing so, the number of features remains the same and we also take into account the pixel values from all three channels of the image. </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image = imread(<span class="string">'puppy.jpeg'</span>)</span><br><span class="line">feature_matrix = np.zeros((<span class="number">660</span>,<span class="number">450</span>)) </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,image.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,image.shape[<span class="number">1</span>]):</span><br><span class="line">        feature_matrix[i][j] = ((int(image[i,j,<span class="number">0</span>]) + int(image[i,j,<span class="number">1</span>]) + int(image[i,j,<span class="number">2</span>]))/<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>The new matrix will have the same height and width but only 1 channel. Now we can follow the same steps that we did in the previous section. We append the pixel values one after the other to get a 1D array:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = np.reshape(feature_matrix, (<span class="number">660</span>*<span class="number">450</span>)) </span><br><span class="line">features.shape</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(297000,)</span><br></pre></td></tr></table></figure>
<h4 id="2-1-5-Method-3-Extracting-Edge-Features"><a href="#2-1-5-Method-3-Extracting-Edge-Features" class="headerlink" title="2.1.5 Method #3: Extracting Edge Features"></a>2.1.5 Method #3: Extracting Edge Features</h4><p>Consider that we are given the below image and we need to identify the objects present in it:</p>
<p><img src="/2020/02/18/Computer-Vision/article-image-71.webp" alt="article-image-71"></p>
<p>You must have recognized the objects in an instant – a dog, a car and a cat. What are the features that you considered while differentiating each of these images? The shape could be one important factor, followed by color, or size. What if the machine could also identify the shape as we do?</p>
<p>A similar idea is to <strong>extract edges as features and use that as the input for the model.</strong> I want you to think about this for a moment – how can we identify edges in an image? <strong>Edge is basically where there is a sharp change in color</strong>. Look at the below image:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-81.png" alt="edge features"></p>
<p>And as we know, an image is represented in the form of numbers. So, we will look for pixels around which there is a drastic change in the pixel values.</p>
<p>Let’s say we have the following matrix for the image:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-9.png" alt="img"></p>
<p>To identify if a pixel is an edge or not, we will simply subtract the values on either side of the pixel. For this example, we have the highlighted value of 85. We will find the difference between the values 89 and 78. Since this difference is not very large, we can say that there is no edge around this pixel.</p>
<p>Now consider the pixel 125 highlighted in the below image:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-101.png" alt="img"></p>
<p>Since the difference between the values on either side of this pixel is large, we can conclude that there is a significant transition at this pixel and hence it is an edge. Now the question is, do we have to do this step manually?</p>
<p>No! <strong>There are various kernels that can be used to highlight the edges in an image.</strong> The method we just discussed can also be achieved using the Prewitt kernel (in the x-direction). Given below is the Prewitt kernel:</p>
<p><img src="/2020/02/18/Computer-Vision/article-image-132-300x159.webp" alt="article-image-132-300x159"></p>
<p>We take the values surrounding the selected pixel and multiply it with the selected kernel (Prewitt kernel). We can then add the resulting values to get a final value. Since we already have -1 in one column and 1 in the other column, adding the values is equivalent to taking the difference.</p>
<p><img src="/2020/02/18/Computer-Vision/article-image-111.webp" alt="article-image-111"></p>
<p>There are various other kernels and I have mentioned four most popularly used ones below:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-121.png" alt="kernels"></p>
<p>Let’s now go back to the notebook and generate edge features for the same image:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#importing the required libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread, imshow</span><br><span class="line"><span class="keyword">from</span> skimage.filters <span class="keyword">import</span> prewitt_h,prewitt_v</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#reading the image </span></span><br><span class="line">image = imread(<span class="string">'puppy.jpeg'</span>,as_gray=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#calculating horizontal edges using prewitt kernel</span></span><br><span class="line">edges_prewitt_horizontal = prewitt_h(image)</span><br><span class="line"><span class="comment">#calculating vertical edges using prewitt kernel</span></span><br><span class="line">edges_prewitt_vertical = prewitt_v(image)</span><br><span class="line"></span><br><span class="line">imshow(edges_prewitt_vertical, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_61.png" alt="edge features"></p>
<h3 id="2-2-HOG-Histogram-of-Oriented-Gradients-features"><a href="#2-2-HOG-Histogram-of-Oriented-Gradients-features" class="headerlink" title="2.2 HOG (Histogram of Oriented Gradients) features"></a>2.2 HOG (Histogram of Oriented Gradients) features</h3><p><a href="https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<h4 id="2-2-1-What-is-a-Feature-Descriptor"><a href="#2-2-1-What-is-a-Feature-Descriptor" class="headerlink" title="2.2.1 What is a Feature Descriptor?"></a>2.2.1 What is a Feature Descriptor?</h4><p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-1.png" alt="HOG feature"></p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/article-image-2.png" alt="HOG feature"></p>
<p>The first pair of images had a lot of information, like the shape of the object, its color, the edges, background, etc.</p>
<p>On the other hand, the second pair had much less information (only the shape and the edges) but it was still enough to differentiate the two images.</p>
<p>We were easily able to differentiate the objects in the second case because it had the necessary information we would need to identify the object. And that is exactly what a <strong>feature descriptor</strong> does:</p>
<blockquote>
<p><em>It is a simplified representation of the image that contains only the most important information about the image.</em></p>
</blockquote>
<p>There are a number of feature descriptors out there. Here are a few of the most popular ones:</p>
<ul>
<li><a href="#jumpHOG">HOG: Histogram of Oriented Gradients</a></li>
<li><a href="#jumpSIFT">SIFT: Scale Invariant Feature Transform</a></li>
<li>SURF: Speeded-Up Robust Feature</li>
</ul>
<h4 id="2-2-2-Introduction-to-the-HOG-Feature-Descriptor"><a href="#2-2-2-Introduction-to-the-HOG-Feature-Descriptor" class="headerlink" title="2.2.2 Introduction to the HOG Feature Descriptor"></a><span id="jumpHOG">2.2.2 Introduction to the HOG Feature Descriptor</span></h4><p>HOG, or Histogram of Oriented Gradients, is a feature descriptor that is often used to extract features from image data. It is widely used in <a href="https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning-version2/?utm_source=blog&amp;utm_medium=understand-math-HOG-feature-descriptor" target="_blank" rel="noopener">computer vision</a> tasks for <a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=understand-math-HOG-feature-descriptor" target="_blank" rel="noopener">object detection</a>.</p>
<p>Let’s look at some important aspects of HOG that makes it different from other feature descriptors:</p>
<ul>
<li>The HOG descriptor focuses on the <strong>structure or the shape</strong> of an object. Now you might ask, how is this different from the edge features we extract for images? In the case of edge features, we only identify if the pixel is an edge or not. HOG is able to provide the edge direction as well. This is done by extracting the <strong>gradient and orientation</strong> (or you can say magnitude and direction) of the edges</li>
<li>Additionally, these orientations are calculated in <strong>‘localized’ portions</strong>. This means that the complete image is broken down into smaller regions and for each region, the gradients and orientation are calculated. We will discuss this in much more detail in the upcoming sections</li>
<li>Finally the HOG would generate a <strong>Histogram</strong> for each of these regions separately. The histograms are created using the gradients and orientations of the pixel values, hence the name ‘Histogram of Oriented Gradients’</li>
</ul>
<p>To put a formal definition to this:</p>
<blockquote>
<p>The HOG feature descriptor counts the occurrences of gradient orientation in localized portions of an image.</p>
</blockquote>
<p>Implementing HOG using tools like OpenCV is extremely simple. It’s just a few lines of code since we have a predefined function called <strong>hog</strong> in the <strong>skimage.feature</strong> library. Our focus in this article, however, is on how these features are actually calculated.</p>
<h4 id="2-2-3-Process-of-Calculating-the-Histogram-of-Oriented-Gradients-HOG"><a href="#2-2-3-Process-of-Calculating-the-Histogram-of-Oriented-Gradients-HOG" class="headerlink" title="2.2.3 Process of Calculating the Histogram of Oriented Gradients (HOG)"></a>2.2.3 Process of Calculating the Histogram of Oriented Gradients (HOG)</h4><p>HOG具体是怎么计算的：详细内容见<a href="https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</p>
<h4 id="2-2-4-Implementing-HOG-Feature-Descriptor-in-Python"><a href="#2-2-4-Implementing-HOG-Feature-Descriptor-in-Python" class="headerlink" title="2.2.4 Implementing HOG Feature Descriptor in Python"></a>2.2.4 Implementing HOG Feature Descriptor in Python</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#importing required libraries</span></span><br><span class="line"><span class="keyword">from</span> skimage.io <span class="keyword">import</span> imread, imshow</span><br><span class="line"><span class="keyword">from</span> skimage.transform <span class="keyword">import</span> resize</span><br><span class="line"><span class="keyword">from</span> skimage.feature <span class="keyword">import</span> hog</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> exposure</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#reading the image</span></span><br><span class="line">img = imread(<span class="string">'puppy.jpeg'</span>)</span><br><span class="line">imshow(img)</span><br><span class="line">print(img.shape)</span><br></pre></td></tr></table></figure>
<p>(663, 459, 3)</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_7.png" alt="hog_feature"></p>
<p>We can see that the shape of the image is 663 x 459. We will have to resize this image into 64 x 128. Note that we are using <code>skimage</code> which takes the input as height x width.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#resizing image </span></span><br><span class="line">resized_img = resize(img, (<span class="number">128</span>,<span class="number">64</span>)) </span><br><span class="line">imshow(resized_img) </span><br><span class="line">print(resized_img.shape)</span><br></pre></td></tr></table></figure>
<p>(128, 64, 3)</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_8.png" alt="hog_feature"></p>
<p>Here, I am going to use the hog function from <code>skimage.feature</code> directly. So we don’t have to calculate the gradients, magnitude (total gradient) and orientation individually. The hog function would internally calculate it and return the feature matrix.</p>
<p>Also, if you set the parameter <code>visualize = True</code>, it will return an image of the HOG.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#creating hog features </span></span><br><span class="line">fd, hog_image = hog(resized_img, orientations=<span class="number">9</span>, pixels_per_cell=(<span class="number">8</span>, <span class="number">8</span>), </span><br><span class="line">                    cells_per_block=(<span class="number">2</span>, <span class="number">2</span>), visualize=<span class="literal">True</span>, multichannel=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>Before going ahead, let me give you a basic idea of what each of these hyperparameters represents. Alternatively, you can check the definitions from the official documentation <a href="https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog" target="_blank" rel="noopener">here</a>.</p>
<ul>
<li>The <code>orientations</code> are the number of buckets we want to create. Since I want to have a 9 x 1 matrix, I will set the orientations to 9</li>
<li><code>pixels_per_cell</code> defines the size of the cell for which we create the histograms. In the example we covered in this article, we used 8 x 8 cells and here I will set the same value. As mentioned previously, you can choose to change this value</li>
<li>We have another hyperparameter <code>cells_per_block</code> which is the size of the block over which we normalize the histogram. Here, we mention the cells per blocks and not the number of pixels. So, instead of writing 16 x 16, we will use 2 x 2 here</li>
</ul>
<p>The feature matrix from the function is stored in the variable <code>fd</code>, and the image is stored in <code>hog_image</code>. Let us check the shape of the feature matrix:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fd.shape</span><br></pre></td></tr></table></figure>
<p>(3780,)</p>
<p>As expected, we have 3,780 features for the image and this verifies the calculations we did in step 7 earlier. You can choose to change the values of the hyperparameters and that will give you a feature matrix of different sizes.</p>
<p>Let’s finally look at the HOG image:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">16</span>, <span class="number">8</span>), sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>) </span><br><span class="line"></span><br><span class="line">ax1.imshow(resized_img, cmap=plt.cm.gray) </span><br><span class="line">ax1.set_title(<span class="string">'Input image'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Rescale histogram for better display </span></span><br><span class="line">hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(<span class="number">0</span>, <span class="number">10</span>)) </span><br><span class="line"></span><br><span class="line">ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray) </span><br><span class="line">ax2.set_title(<span class="string">'Histogram of Oriented Gradients'</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/08/index_9.png" alt="hog_features"></p>
<h3 id="2-3-SIFT-Scale-Invariant-Feature-Transform-features"><a href="#2-3-SIFT-Scale-Invariant-Feature-Transform-features" class="headerlink" title="2.3 SIFT (Scale Invariant Feature Transform) features"></a><span id="jumpSIFT">2.3 SIFT (Scale Invariant Feature Transform) features</span></h3><p><a href="https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p>Take a look at the below collection of images and think of the common element between them:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/Screenshot-from-2019-09-20-17-49-55.png" alt="SIFT"></p>
<p>The resplendent Eiffel Tower, of course! We naturally understand that the scale or angle of the image may change but the object remains the same.</p>
<p>But machines have an almighty struggle with the same idea. It’s a challenge for them to identify the object in an image if we change certain things (like the angle or the scale). Here’s the good news – machines are super flexible and we can teach them to identify images at an almost human-level.</p>
<p>So, in this article, we will talk about an <span style="color:red">image matching algorithm</span> that <strong>identifies the key features from the images and is able to match these features to a new image of the same object.</strong></p>
<h4 id="2-3-1-Introduciton-to-SIFT"><a href="#2-3-1-Introduciton-to-SIFT" class="headerlink" title="2.3.1 Introduciton to SIFT"></a>2.3.1 Introduciton to SIFT</h4><blockquote>
<p><em>SIFT, or Scale Invariant Feature Transform, is a feature detection algorithm in Computer Vision.</em></p>
</blockquote>
<p>SIFT helps locate the local features in an image, commonly known as the <span style="color:red">‘<em>keypoints</em>‘ </span>of the image. These keypoints are <strong>scale &amp; rotation invariant</strong> that can be used for various computer vision applications, like image matching, object detection, scene detection, etc.</p>
<p>在模型训练过程中，我们也可以使用SIFT生成的关键点作为图像的特征。<strong>The major advantage of SIFT features, over edge features or hog features, is that they are not affected by the size or orientation of the image.</strong></p>
<p>For example, here is another image of the Eiffel Tower along with its smaller version. The keypoints of the object in the first image are matched with the keypoints found in the second image. The same goes for two images when the object in the other image is slightly rotated. Amazing, right?</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/10/Screenshot-from-2019-10-01-16-08-16-300x282.png" alt="SIFT"></p>
<p>Let’s understand how these keypoints are identified and what are the techniques used to ensure the scale and rotation invariance. Broadly speaking, the entire process can be divided into 4 parts:</p>
<ul>
<li><strong><a href="#jump2.3.2">Constructing a Scale Space:</a></strong> To make sure that features are scale-independent</li>
<li><strong><a href="#jump2.3.3">Keypoint Localisation (关键点定位):</a></strong> Identifying the suitable features or keypoints</li>
<li><strong><a href="#jump2.3.4">Orientation Assignment:</a></strong> Ensure the keypoints are rotation invariant</li>
<li><strong><a href="#jump2.3.5">Keypoint Descriptor:</a></strong> Assign a unique fingerprint to each keypoint</li>
</ul>
<p>Finally, we can use these keypoints for feature matching!</p>
<p><em>This article is based on the original paper by David G. Lowe. Here is the link: <a href="https://people.eecs.berkeley.edu/~malik/cs294/lowe-ijcv04.pdf" target="_blank" rel="noopener">Distinctive Image Features from Scale-Invariant Keypoints.</a></em></p>
<h4 id="2-3-2-Constructing-the-Scale-Space"><a href="#2-3-2-Constructing-the-Scale-Space" class="headerlink" title="2.3.2 Constructing the Scale Space"></a><span id="jump2.3.2">2.3.2 Constructing the Scale Space</span></h4><p>We need to identify the most distinct features in a given image while ignoring any noise. Additionally, we need to ensure that the features are not scale-dependent.</p>
<p>1.reduce the noise</p>
<blockquote>
<p><em>We use the</em> <strong>Gaussian Blurring technique</strong> <em>to reduce the noise in an image.</em></p>
</blockquote>
<p>So, for every pixel in an image, the Gaussian Blur calculates a value based on its neighboring pixels. Below is an example of image before and after applying the Gaussian Blur. As you can see, the texture and minor details are removed from the image and only the relevant information like the shape and edges remain:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/index_110.png" alt="gaussian blur"></p>
<p>2.ensure the features are not scale-dependent</p>
<p>Gaussian Blur successfully removed the noise from the images and we have highlighted the important features of the image. Now, <em>we need to ensure that these features must not be scale-dependent.</em> This means we will be searching for these features on multiple scales, by creating a ‘scale space’.</p>
<blockquote>
<p><em>Scale space is a collection of images having different scales, generated from a single image.</em></p>
</blockquote>
<p>To create a new set of images of different scales, we will take the original image and <strong>reduce the scale by half</strong>. For each new image, we will create blur versions as we saw above.</p>
<p>例：We have the original image of size (275, 183) and a scaled image of dimension (138, 92). For both the images, two blur images are created:</p>
<p><img src="/2020/02/18/Computer-Vision/1582017369109.png" alt="1582017369109"></p>
<p>How many times do we need to scale the image and how many subsequent blur images need to be created for each scaled image? <strong>The ideal number of octaves should be four</strong>, and for each octave, the number of blur images should be five.</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/Screenshot-from-2019-09-24-18-27-46.png" alt="sift octave"></p>
<h5 id="Difference-of-Gaussian"><a href="#Difference-of-Gaussian" class="headerlink" title="Difference of Gaussian"></a>Difference of Gaussian</h5><p>So far we have created images of multiple scales (often represented by σ) and used Gaussian blur for each of them to reduce the noise in the image. Next, we will try to enhance the features using a technique called Difference of Gaussians or DoG.</p>
<blockquote>
<p><em>Difference of Gaussian is a <span style="color:red">feature enhancement</span> algorithm that involves the subtraction of one blurred version of an original image from another, less blurred version of the original.</em></p>
</blockquote>
<p>DoG creates another set of images, for each octave, by subtracting every image from the previous image in the same scale. </p>
<p>Let us create the DoG for the images in scale space. 如下图所示，On the left, we have 5 images, all from the first octave (thus having the same scale). Each subsequent image is created by applying the Gaussian blur over the previous image. On the right, we have four images generated by subtracting the consecutive Gaussians. The results are jaw-dropping (让人吃惊)!</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/09/Screenshot-from-2019-09-25-14-18-26.png" alt="difference of gaussian"></p>
<p>Now that we have a new set of images, we are going to use this to find the important keypoints.</p>
<h4 id="2-3-3-Keypoint-Localization-关键点定位"><a href="#2-3-3-Keypoint-Localization-关键点定位" class="headerlink" title="2.3.3 Keypoint Localization (关键点定位)"></a><span id="jump2.3.3">2.3.3 Keypoint Localization (关键点定位)</span></h4><p>Once the images have been created, the next step is to find the important keypoints from the image that can be used for feature matching. <strong>The idea is to find the local maxima and minima for the images.</strong> This part is divided into two steps:</p>
<ol>
<li><a href="#jump2.3.3.1">Find the local maxima and minima</a></li>
<li><a href="#jump2.3.3.2">Remove low contrast keypoints (keypoint selection)</a></li>
</ol>
<h5 id="Local-Maxima-and-Local-Minima"><a href="#Local-Maxima-and-Local-Minima" class="headerlink" title="Local Maxima and Local Minima"></a><span id="jump2.3.3.1">Local Maxima and Local Minima</span></h5><blockquote>
<p><em>To locate the local maxima and minima, we go through every pixel in the image and compare it with its neighboring pixels.</em></p>
</blockquote>
<p>When I say ‘neighboring’, this not only includes the surrounding pixels of that image (in which the pixel lies), but also the nine pixels for the previous and next image in the octave.</p>
<p>This means that every pixel value is compared with 26 other pixel values to find whether it is the local maxima/minima. For example, in the below diagram, we have three images from the first octave. The pixel marked <em>x</em> is compared with the neighboring pixels (in green) and is selected as a keypoint if it is the highest or lowest among the neighbors:</p>
<p><img src="/2020/02/18/Computer-Vision/Screenshot-from-2019-09-25-16-50-01-300x207.webp" alt="Screenshot-from-2019-09-25-16-50-01-300x207"></p>
<p>We now have potential keypoints that represent the images and are scale-invariant. We will apply the last check over the selected keypoints to ensure that these are the most accurate keypoints to represent the image. ( 因为some of these keypoints may not be robust to noise. )</p>
<h5 id="Keypoint-Selection"><a href="#Keypoint-Selection" class="headerlink" title="Keypoint Selection"></a><span id="jump2.3.3.2">Keypoint Selection</span></h5><p><strong>we will eliminate the keypoints that have low contrast, or lie very close to the edge.</strong></p>
<p>To deal with the low contrast keypoints, <strong>a second-order Taylor expansion</strong> is computed for each keypoint. If the resulting value is less than 0.03 (in magnitude), we reject the keypoint.</p>
<p>So what do we do about the remaining keypoints? Well, we perform a check to identify the poorly located keypoints. 这些是接近边缘的关键点，具有高边缘响应，但可能对少量噪声不够稳健。<strong>A second-order Hessian matrix</strong> is used to identify such keypoints. </p>
<p>Now that we have performed both the <span style="color:red">contrast test</span> and the <span style="color:red">edge test</span> to reject the unstable keypoints, we will now assign an orientation value for each keypoint to make the rotation invariant.</p>
<h4 id="2-3-4-Orientation-Assignment"><a href="#2-3-4-Orientation-Assignment" class="headerlink" title="2.3.4 Orientation Assignment"></a><span id="jump2.3.4">2.3.4 Orientation Assignment</span></h4><p>At this stage, we have a set of stable keypoints for the images. We will now assign an orientation to each of these keypoints so that they are invariant to rotation. We can again divide this step into two smaller steps:</p>
<ol>
<li>Calculate the magnitude and orientation</li>
<li>Create a histogram for magnitude and orientation</li>
</ol>
<p>计算magnitude和orientation的方法与 HOG中的计算方法类似，具体计算过程见<a href="https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</p>
<blockquote>
<p><em>The magnitude represents the intensity of the pixel and the orientation gives the direction for the same.</em></p>
</blockquote>
<h5 id="Creating-a-Histogram-for-Magnitude-and-Orientation"><a href="#Creating-a-Histogram-for-Magnitude-and-Orientation" class="headerlink" title="Creating a Histogram for Magnitude and Orientation"></a>Creating a Histogram for Magnitude and Orientation</h5><p>On the x-axis, we will have bins for angle values, like 0-9, 10 – 19, 20-29, up to 360. Since our angle value is 57, it will fall in the 6th bin. The 6th bin value will be in proportion to the magnitude of the pixel, i.e. 16.64.  We will do this for all the pixels around the keypoint.</p>
<p>This is how we get the below histogram:</p>
<p><img src="/2020/02/18/Computer-Vision/Screenshot-from-2019-09-26-18-53-12.webp" alt="Screenshot-from-2019-09-26-18-53-12"></p>
<p><em>You can refer to this article for a much detailed explanation for calculating the gradient, magnitude, orientation and plotting histogram – <a href="https://www.analyticsvidhya.com/blog/2019/09/feature-engineering-images-introduction-hog-feature-descriptor/" target="_blank" rel="noopener">A Valuable Introduction to the Histogram of Oriented Gradients.</a></em></p>
<p>This histogram would peak at some point. <strong>The bin at which we see the peak will be the orientation for the keypoint.</strong> Additionally, if there is another significant peak (seen between 80 – 100%), then another keypoint is generated with the magnitude and scale the same as the keypoint used to generate the histogram. And the angle or orientation will be equal to the new bin that has the peak.</p>
<p>Effectively at this point, we can say that there can be a small increase in the number of keypoints.</p>
<h4 id="2-3-5-Keypoint-Descriptor"><a href="#2-3-5-Keypoint-Descriptor" class="headerlink" title="2.3.5 Keypoint Descriptor"></a><span id="jump2.3.5">2.3.5 Keypoint Descriptor</span></h4><p>This is the final step for SIFT. So far, we have stable keypoints that are scale-invariant and rotation invariant. In this section, we will use the neighboring pixels, their orientations, and magnitude, to generate a unique fingerprint for this keypoint called a ‘descriptor’.</p>
<p>Additionally, since we use the surrounding pixels, the descriptors will be partially invariant to illumination or brightness of the images.</p>
<p>We will first take a 16×16 neighborhood around the keypoint. This 16×16 block is further divided into 4×4 sub-blocks and for each of these sub-blocks, we generate the histogram using magnitude and orientation.</p>
<p><img src="/2020/02/18/Computer-Vision/Screenshot-from-2019-09-26-20-10-52.webp" alt="Screenshot-from-2019-09-26-20-10-52"></p>
<p>At this stage, the bin size is increased and we take only 8 bins (not 36). Each of these arrows represents the 8 bins and the length of the arrows define the magnitude. So, we will have a total of 128 bin values for every keypoint.</p>
<p>Here is an example:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#reading image</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'eiffel_2.jpeg'</span>)  </span><br><span class="line">gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment">#keypoints</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">img_1 = cv2.drawKeypoints(gray1,keypoints_1,img1)</span><br><span class="line">plt.imshow(img_1)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/18/Computer-Vision/index_41.webp" alt="index_41"></p>
<h4 id="2-3-6-Feature-Matching-代码"><a href="#2-3-6-Feature-Matching-代码" class="headerlink" title="2.3.6 Feature Matching (代码)"></a>2.3.6 Feature Matching (代码)</h4><p>We will now use the SIFT features for feature matching. For this purpose, I have downloaded two images of the Eiffel Tower, taken from different positions. You can try it with any two images that you want. <br>Here are the two images that I have used:</p>
<p><span style="background:yellow">reading_image_eiffel.py</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># read images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'eiffel_2.jpeg'</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">'eiffel_1.jpg'</span>) </span><br><span class="line"></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line">figure, ax = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">ax[<span class="number">0</span>].imshow(img1, cmap=<span class="string">'gray'</span>)</span><br><span class="line">ax[<span class="number">1</span>].imshow(img2, cmap=<span class="string">'gray'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/18/Computer-Vision/index_71.png" alt="index_71"></p>
<p>Now, for both these images, we are going to generate the SIFT features. First, we have to construct a SIFT object and then use the function <em>detectAndCompute</em> to get the keypoints. It will return two values – the keypoints and the descriptors.</p>
<p>Let’s determine the keypoints and print the total number of keypoints found in each image:</p>
<p><span style="background:yellow">keypoints_shape.py</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># read images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'eiffel_2.jpeg'</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">'eiffel_1.jpg'</span>) </span><br><span class="line"></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sift</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">len(keypoints_1), len(keypoints_2)</span><br></pre></td></tr></table></figure>
<p>283, 540</p>
<p>Next, let’s try and match the features from image 1 with features from image 2. We will be using the function <em>match()</em> from the <em>BFmatcher</em> (brute force match) module. Also, we will draw lines between the features that match in both the images. This can be done using the <em>drawMatches</em> function in OpenCV.</p>
<p><span style="background:yellow">feature_matching.py</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># read images</span></span><br><span class="line">img1 = cv2.imread(<span class="string">'eiffel_2.jpeg'</span>)  </span><br><span class="line">img2 = cv2.imread(<span class="string">'eiffel_1.jpg'</span>) </span><br><span class="line"></span><br><span class="line">img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)</span><br><span class="line">img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)</span><br><span class="line"></span><br><span class="line"><span class="comment">#sift</span></span><br><span class="line">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class="line"></span><br><span class="line">keypoints_1, descriptors_1 = sift.detectAndCompute(img1,<span class="literal">None</span>)</span><br><span class="line">keypoints_2, descriptors_2 = sift.detectAndCompute(img2,<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#feature matching</span></span><br><span class="line">bf = cv2.BFMatcher(cv2.NORM_L1, crossCheck=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">matches = bf.match(descriptors_1,descriptors_2)</span><br><span class="line">matches = sorted(matches, key = <span class="keyword">lambda</span> x:x.distance)</span><br><span class="line"></span><br><span class="line">img3 = cv2.drawMatches(img1, keypoints_1, img2, keypoints_2, matches[:<span class="number">50</span>], img2, flags=<span class="number">2</span>)</span><br><span class="line">plt.imshow(img3),plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/18/Computer-Vision/index_61.webp" alt="index_61"></p>
<p>I have plotted only 50 matches here for clarity’s sake. You can increase the number according to what you prefer. To find out how many keypoints are matched, we can print the length of the variable <em>matches</em>. In this case, the answer would be 190.</p>
<h4 id="2-3-7-End-Notes"><a href="#2-3-7-End-Notes" class="headerlink" title="2.3.7 End Notes"></a>2.3.7 End Notes</h4><p>In this article, we discussed the SIFT feature matching algorithm in detail. Here is a site that provides excellent visualization for each step of SIFT. You can add your own image and it will create the keypoints for that image as well. Check it out <a href="http://weitz.de/sift/" target="_blank" rel="noopener">here</a>.</p>
<p>Another popular feature matching algorithm is SURF (Speeded Up Robust Feature), which is simply a faster version of SIFT. I would encourage you to go ahead and explore it as well.</p>
<p>And if you’re new to the world of computer vision and image data, I recommend checking out the below course:</p>
<ul>
<li><a href="https://courses.analyticsvidhya.com/courses/computer-vision-using-deep-learning-version2?utm_source=blog&amp;utm_medium=detailed-guide-powerful-sift-technique-image-matching-python" target="_blank" rel="noopener">Computer Vision using Deep Learning 2.0</a></li>
</ul>
<h2 id="3-Image-Classification-using-Logistic-Regression"><a href="#3-Image-Classification-using-Logistic-Regression" class="headerlink" title="3. Image Classification using Logistic Regression"></a>3. Image Classification using Logistic Regression</h2><ul>
<li><p>Python:</p>
<p>kaggle kernel: used grid search method in logistic regression to classify rooms as messy or clean.</p>
</li>
</ul>
<p>完整代码见：<a href="https://www.kaggle.com/gulsahdemiryurek/image-classification-with-logistic-regression/notebook" target="_blank" rel="noopener">https://www.kaggle.com/gulsahdemiryurek/image-classification-with-logistic-regression/notebook</a></p>
<p>对图片的大致处理：（在这里，先不纠结train/val/test等）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"><span class="keyword">import</span> os </span><br><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> shuffle </span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm </span><br><span class="line"></span><br><span class="line">train_messy = <span class="string">"../input/images/images/train/messy"</span></span><br><span class="line">train_clean= <span class="string">"../input/images/images/train/clean"</span></span><br><span class="line">test_messy= <span class="string">"../input/images/images/val/messy"</span></span><br><span class="line">test_clean= <span class="string">"../input/images/images/val/clean"</span></span><br><span class="line">image_size = <span class="number">128</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_data</span><span class="params">()</span>:</span></span><br><span class="line">    train_data_messy = [] </span><br><span class="line">    train_data_clean=[]</span><br><span class="line">    <span class="keyword">for</span> image1 <span class="keyword">in</span> tqdm(os.listdir(train_messy)): </span><br><span class="line">        path = os.path.join(train_messy, image)</span><br><span class="line">        img1 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        img1 = cv2.resize(img1, (image_size, image_size))</span><br><span class="line">        train_data_messy.append(img1) </span><br><span class="line">    <span class="keyword">for</span> image2 <span class="keyword">in</span> tqdm(os.listdir(train_clean)): </span><br><span class="line">        path = os.path.join(train_clean, image)</span><br><span class="line">        img2 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        img2 = cv2.resize(img2, (image_size, image_size))</span><br><span class="line">        train_data_clean.append(img2) </span><br><span class="line">    </span><br><span class="line">    train_data= np.concatenate((np.asarray(train_data_messy),np.asarray(train_data_clean)),axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> train_data </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_data</span><span class="params">()</span>:</span></span><br><span class="line">    test_data_messy = [] </span><br><span class="line">    test_data_clean=[]</span><br><span class="line">    <span class="keyword">for</span> image1 <span class="keyword">in</span> tqdm(os.listdir(test_messy)): </span><br><span class="line">        path = os.path.join(test_messy, image1)</span><br><span class="line">        img1 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        img1 = cv2.resize(img1, (image_size, image_size))</span><br><span class="line">        test_data_messy.append(img1) </span><br><span class="line">    <span class="keyword">for</span> image2 <span class="keyword">in</span> tqdm(os.listdir(test_clean)): </span><br><span class="line">        path = os.path.join(test_clean, image2)</span><br><span class="line">        img2 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) </span><br><span class="line">        img2 = cv2.resize(img2, (image_size, image_size))</span><br><span class="line">        test_data_clean.append(img2) </span><br><span class="line">    </span><br><span class="line">    test_data= np.concatenate((np.asarray(test_data_messy),np.asarray(test_data_clean)),axis=<span class="number">0</span>) </span><br><span class="line">    <span class="keyword">return</span> test_data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_data = train_data() </span><br><span class="line">test_data = test_data()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">x_train_flatten = train_data.reshape(train_data.shape[<span class="number">0</span>],train_data.shape[<span class="number">1</span>]*train_data.shape[<span class="number">2</span>])</span><br></pre></td></tr></table></figure>
<p>Grid search:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">grid=&#123;<span class="string">"C"</span>:np.logspace(<span class="number">-3</span>,<span class="number">3</span>,<span class="number">7</span>),<span class="string">"penalty"</span>:[<span class="string">"l1"</span>,<span class="string">"l2"</span>]&#125;,</span><br><span class="line">logistic_regression=LogisticRegression(random_state=<span class="number">42</span>)</span><br><span class="line">log_reg_cv=GridSearchCV(logistic_regression,grid,cv=<span class="number">10</span>)</span><br><span class="line">log_reg_cv.fit(x_train_flatten, y_train)</span><br></pre></td></tr></table></figure>
<ul>
<li>C: <a href="https://mmlind.github.io/Using_Logistic_Regression_to_solve_MNIST/" target="_blank" rel="noopener">Using Logistic regression to classify images</a> (MNIST data)</li>
</ul>
<h2 id="4-Project-1-Identify-the-Apparels-服装"><a href="#4-Project-1-Identify-the-Apparels-服装" class="headerlink" title="4. Project 1- Identify the Apparels (服装)"></a>4. Project 1- Identify the Apparels (服装)</h2><p><a href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-apparels/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p><img src="/2020/02/18/Computer-Vision/1582027636102.png" alt="1582027636102"></p>
<p>More than 25% of entire revenue in E-Commerce is attributed to apparels &amp; accessories. A major problem they face is categorizing these apparels from just the images especially when the categories provided by the brands are inconsistent. This poses an interesting computer vision problem which has caught the eyes of several deep learning researchers.</p>
<p>Fashion MNIST is a drop-in replacement for the very well known, machine learning hello world - MNIST dataset which can be checked out at <a href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/" target="_blank" rel="noopener">‘Identify the digits’</a> practice problem. Instead of digits, the images show a type of apparel e.g. T-shirt, trousers, bag, etc. The dataset used in this problem was created by Zalando Research. More details can be found at this <a href="https://github.com/zalandoresearch/fashion-mnist" target="_blank" rel="noopener">link</a>.</p>
<h2 id="5-Introduction-to-Keras-amp-Neural-Networks"><a href="#5-Introduction-to-Keras-amp-Neural-Networks" class="headerlink" title="5. Introduction to Keras &amp; Neural Networks"></a>5. Introduction to Keras &amp; Neural Networks</h2><h3 id="5-1-Keras"><a href="#5-1-Keras" class="headerlink" title="5.1 Keras"></a>5.1 Keras</h3><p>Keras is one of the most commonly used deep learning tools.</p>
<ul>
<li><a href="https://keras.io/" target="_blank" rel="noopener">Keras Documentation</a> (Keras官方文档)</li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/10/tutorial-optimizing-neural-networks-using-keras-with-image-recognition-case-study/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Neural Networks using Keras</a> (MNIST)</li>
</ul>
<h3 id="5-2-Neural-Network"><a href="#5-2-Neural-Network" class="headerlink" title="5.2 Neural Network"></a>5.2 Neural Network</h3><ul>
<li><p><a href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Neural Networks from Scratch</a></p>
</li>
<li><p>Introduction to Neural Networks by Stanford:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/d14TUNcbn1k" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</li>
</ul>
<ul>
<li><p>Neural Networks by 3Blue1Brown:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aircAruvnKk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

</li>
</ul>
<h2 id="6-Project-1-Identify-the-Apparels"><a href="#6-Project-1-Identify-the-Apparels" class="headerlink" title="6. Project 1 - Identify the Apparels"></a>6. Project 1 - Identify the Apparels</h2><p>同第4部分</p>
<h2 id="7-Understanding-Convolutional-Neural-Networks-CNNs-Transfer-Learning"><a href="#7-Understanding-Convolutional-Neural-Networks-CNNs-Transfer-Learning" class="headerlink" title="7. Understanding Convolutional Neural Networks (CNNs), Transfer Learning"></a>7. Understanding Convolutional Neural Networks (CNNs), Transfer Learning</h2><h3 id="7-1-Introduction-to-Convolutional-Neural-Networks-CNNs"><a href="#7-1-Introduction-to-Convolutional-Neural-Networks-CNNs" class="headerlink" title="7.1 Introduction to Convolutional Neural Networks (CNNs):"></a>7.1 <strong>Introduction to Convolutional Neural Networks (CNNs):</strong></h3><ul>
<li><p><a href="https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Convolutional Neural Networks (CNNs) Simplified</a></p>
</li>
<li><p>Convolutional Neural Networks by Stanford:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/bNb2fEVKeEo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


</li>
</ul>
<h3 id="7-2-Introduction-to-Transfer-Learning"><a href="#7-2-Introduction-to-Transfer-Learning" class="headerlink" title="7.2 Introduction to Transfer Learning:"></a>7.2 <strong>Introduction to Transfer Learning:</strong></h3><h4 id="7-2-1-Master-Transfer-Learning"><a href="#7-2-1-Master-Transfer-Learning" class="headerlink" title="7.2.1 Master Transfer Learning"></a>7.2.1 Master Transfer Learning</h4><p><a href="https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p>训练神经网络有时需要很多的资源（RAM, GPUs）, RAM on a machine is cheap and is available in plenty, but access to GPUs is not that cheap. </p>
<p>Now, that may change in future. But for now, it means that we have to be smarter about the way we use our resources in solving Deep Learning problems. Especially so, when we try to solve complex real life problems on areas like image and voice recognition. Once you have a few hidden layers in your model, adding another layer of hidden layer would need immense resources.</p>
<p>Thankfully, there is something called “Transfer Learning” which enables us to <strong>use pre-trained models from other people by making small changes.</strong> In this article, I am going to tell how we can use pre-trained models to accelerate our solutions.</p>
<ul>
<li><strong>What is transfer learning?</strong></li>
</ul>
<p>A neural network is trained on a data. This network gains knowledge from this data, which is compiled as “weights” of the network. <span style="color:red">These weights can be extracted and then transferred to any other neural network.</span> Instead of training the other neural network from scratch, we <strong>“transfer”</strong> the learned features.</p>
<ul>
<li><strong>What is a Pre-trained Model?</strong></li>
</ul>
<p>Simply put, a pre-trained model is a model created by some one else to solve a similar problem. Instead of building a model from scratch to solve a similar problem, you use the model trained on other problem as a starting point.<br>For example, if you want to build a self learning car. You can spend years to build a decent image recognition algorithm from scratch or you can take inception model (a pre-trained model) from Google which was built on ImageNet data to identify images in those pictures.<br>A pre-trained model may not be 100% accurate in your application, but it saves huge efforts required to re-invent the wheel. </p>
<p>使用pre-trained model不仅能节约训练时间，还能得到更高的准确率</p>
<ul>
<li><strong>How can I use Pre-trained Models?</strong></li>
</ul>
<p> By using pre-trained models which have been previously trained on large datasets, we can directly use the weights and architecture obtained and apply the learning on our problem statement. This is known as transfer learning. We “transfer the learning” of the pre-trained model to our specific problem statement.</p>
<p>You should be very careful while choosing what pre-trained model you should use in your case. If the problem statement we have at hand is very different from the one on which the pre-trained model was trained – the prediction we would get would be very inaccurate. For example, a model previously trained for speech recognition would work horribly if we try to use it to identify objects using it.</p>
<p>We are lucky that many pre-trained architectures are directly available for us in the Keras library. <strong>Imagenet</strong> data set has been widely used to build various architectures since it is large enough (1.2M images) to create a generalized model. The problem statement is to train a model that can correctly classify the images into 1,000 separate object categories. These 1,000 image categories represent object classes that we come across in our day-to-day lives, such as species of dogs, cats, various household objects, vehicle types etc.</p>
<p>These pre-trained networks demonstrate a strong ability to generalize to images outside the ImageNet dataset via transfer learning. <strong>We make modifications in the pre-existing model by fine-tuning the model. </strong>Since we assume that the pre-trained network has been trained quite well, we would not want to modify the weights too soon and too much. While modifying we generally use a learning rate smaller than the one used for initially training the model.</p>
<ul>
<li><p><strong>Ways to Fine tune the model</strong></p>
<ol>
<li><strong>Feature extraction</strong> – We can use a pre-trained model as a feature extraction mechanism. What we can do is that we can remove the output layer( the one which gives the probabilities for being in each of the 1000 classes) and then use the entire network as a fixed feature extractor for the new data set.</li>
<li><strong>Use the Architecture of the pre-trained model –</strong> What we can do is that we use architecture of the model while we initialize all the weights randomly and train the model according to our dataset again.</li>
<li><strong>Train some layers while freeze others</strong> – Another way to use a pre-trained model is to train is partially. What we can do is we keep the weights of initial layers of the model frozen while we retrain only the higher layers. We can try and test as to how many layers to be frozen and how many to be trained.</li>
</ol>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2017/05/31112715/finetune1-300x270.jpg"></p>
</li>
</ul>
<p><strong>Scenario 1 – Size of the Data set is small while the Data similarity is very high –</strong> In this case, since the data similarity is very high, we do not need to retrain the model. All we need to do is to customize and modify the output layers according to our problem statement. We use the pretrained model as a feature extractor. Suppose we decide to use models trained on Imagenet to identify if the new set of images have cats or dogs. Here the images we need to identify would be similar to imagenet, however we just need two categories as my output – cats or dogs. In this case all we do is just modify the dense layers and the final softmax layer to output 2 categories instead of a 1000.</p>
<p><strong>Scenario 2 – Size of the data is small as well as data similarity is very low</strong> – In this case we can freeze the initial (let’s say k) layers of the pretrained model and train just the remaining(n-k) layers again. The top layers would then be customized to the new data set. Since the new data set has low similarity it is significant to retrain and customize the higher layers according to the new dataset.  The small size of the data set is compensated by the fact that the initial layers are kept pretrained(which have been trained on a large dataset previously) and the weights for those layers are frozen.</p>
<p><strong>Scenario 3 – Size of the data set is large however the Data similarity is very low</strong> – In this case, since we have a large dataset, our neural network training would be effective. However, since the data we have is very different as compared to the data used for training our pretrained models. The predictions made using pretrained models would not be effective. Hence, its best to train the neural network from scratch according to your data.</p>
<p><strong>Scenario 4 – Size of the data is large as well as there is high data similarity –</strong> This is the ideal situation. In this case the pretrained model should be most effective. The best way to use the model is to retain the architecture of the model and the initial weights of the model. Then we can retrain this model using the weights as initialized in the pre-trained model.</p>
<blockquote>
<p>There are various architectures that have been trained on the imageNet data set. You can go through various architectures <a href="http://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/" target="_blank" rel="noopener">here</a>.</p>
</blockquote>
<p><span style="background:yellow">代码示例</span>： se the pre-trained models to identify handwritten digits. 见<a href="https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a></p>
<h4 id="7-2-2-ConvNets-in-Practice-by-Stanford"><a href="#7-2-2-ConvNets-in-Practice-by-Stanford" class="headerlink" title="7.2.2 ConvNets in Practice by Stanford:"></a>7.2.2 ConvNets in Practice by Stanford:</h4><iframe width="560" height="315" src="https://www.youtube.com/embed/dUTzeP_HTZg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<h2 id="8-Project-2-Idendify-the-Digits"><a href="#8-Project-2-Idendify-the-Digits" class="headerlink" title="8. Project 2 - Idendify the Digits"></a>8. Project 2 - Idendify the Digits</h2><p><a href="https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://datahack.analyticsvidhya.com/contest/practice-problem-identify-the-digits/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p>Automatic digit recognition is of popular interest today. Deep Learning techniques makes it possible for object recognition in image data . This practice problem is meant to give you a kick start in deep learning. As usual, we will not only provide you with the challenge and a solution checker, but also a set of tutorials to get you off the ground!</p>
<p>The data set used for this problem is from the populat MNIST data set. Developed by Yann LeCun, Corina Cortes and Christopher Burger for evaluating machine learning model on the handwritten digit classification problem. It is a widely used data set in the machine learning community. For more details about the data set, read here <a href="http://bit.ly/1REjJgL" target="_blank" rel="noopener">http://bit.ly/1REjJgL</a></p>
<h2 id="9-Build-your-profile-Participate-in-competitions"><a href="#9-Build-your-profile-Participate-in-competitions" class="headerlink" title="9. Build your profile: Participate in competitions"></a>9. <strong>Build your profile: Participate in competitions</strong></h2><ul>
<li><a href="https://datahack.analyticsvidhya.com/contest/all/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">DataHack</a></li>
<li><a href="https://www.kaggle.com/competitions" target="_blank" rel="noopener">Kaggle</a></li>
</ul>
<h2 id="10-Solving-Object-Detection-problems"><a href="#10-Solving-Object-Detection-problems" class="headerlink" title="10. Solving Object Detection problems"></a>10. Solving Object Detection problems</h2><h3 id="10-1-Step-by-Step-Introduction-to-Object-Detection-Techniques"><a href="#10-1-Step-by-Step-Introduction-to-Object-Detection-Techniques" class="headerlink" title="10.1 Step-by-Step Introduction to Object Detection Techniques"></a>10.1 Step-by-Step Introduction to Object Detection Techniques</h3><p><a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p>The below image is a popular example of illustrating how an object detection algorithm works. Each object in the image, from a person to a kite, have been located and identified with a certain level of precision.</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/06/OD.png" alt="img"></p>
<p>Let’s look at how we can solve a general object detection problem using a CNN.</p>
<ol>
<li><p>First, we take an image as input:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/I1_2009_09_08_drive_0012_001351-768x223.png" alt="img"></p>
</li>
<li><p>Then we divide the image into various regions:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-09-14-21-14.png" alt="img"></p>
</li>
<li><p>We will then consider each region as a separate image.</p>
</li>
<li><p>Pass all these regions (images) to the CNN and classify them into various classes.</p>
</li>
<li><p>Once we have divided each region into its corresponding class, we can combine all these regions to get the original image with the detected objects:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/I1_2009_09_08_drive_0012_001351-another-copy-768x223.png" alt="img"></p>
</li>
</ol>
<p>The problem with using this approach is that the objects in the image can have different aspect ratios and spatial locations. For instance, in some cases the object might be covering most of the image, while in others the object might only be covering a small percentage of the image. The shapes of the objects might also be different (happens a lot in real-life use cases).</p>
<p>As a result of these factors, we would require a very large number of regions resulting in a huge amount of computational time. So to solve this problem and reduce the number of regions, we can use region-based CNN, which selects the regions using a proposal method. Let’s understand what this region-based CNN can do for us.</p>
<h4 id="10-1-1-Understanding-Region-Based-Convolutional-Neural-Network-RCNN"><a href="#10-1-1-Understanding-Region-Based-Convolutional-Neural-Network-RCNN" class="headerlink" title="10.1.1 Understanding Region-Based Convolutional Neural Network (RCNN)"></a>10.1.1 Understanding Region-Based Convolutional Neural Network (RCNN)</h4><h5 id="10-1-1-1-Intuition-of-RCNN"><a href="#10-1-1-1-Intuition-of-RCNN" class="headerlink" title="10.1.1.1 Intuition of RCNN"></a>10.1.1.1 Intuition of RCNN</h5><p>Instead of working on a massive number of regions, the RCNN algorithm proposes a bunch of boxes in the image and checks if any of these boxes contain any object. RCNN <strong>uses <span style="color:red">selective search</span> to extract these boxes from an image (these boxes are called regions).</strong></p>
<p>Let’s first understand what selective search is and how it identifies the different regions. There are basically four regions that form an object: varying scales, colors, textures, and enclosure. Selective search identifies these patterns in the image and based on that, proposes various regions. <a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Here is a brief overview of how selective search works.</a></p>
<p>Below is a succint summary of the steps followed in RCNN to detect objects:</p>
<ol>
<li>We first take a pre-trained convolutional neural network.</li>
<li>Then, this model is retrained. We train the last layer of the network based on the number of classes that need to be detected.</li>
<li>The third step is to get the Region of Interest for each image. We then reshape all these regions so that they can match the CNN input size.</li>
<li>After getting the regions, we train SVM to classify objects and background. For each class, we train one binary SVM.</li>
<li>Finally, we train a linear regression model to generate tighter bounding boxes for each identified object in the image.</li>
</ol>
<p>You might get a better idea of the above steps with a visual example:</p>
<ul>
<li><p>First, an image is taken as an input:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-14-59-02.png" alt="img"></p>
</li>
</ul>
<ul>
<li><p>Then, we get the Regions of Interest (ROI) using some proposal method (for example, selective search as seen above):</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-00-09.png" alt="img"></p>
</li>
<li><p>All these regions are then reshaped as per the input of the CNN, and each region is passed to the ConvNet:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-01-56.png" alt="img"></p>
</li>
<li><p>CNN then extracts features for each region and SVMs are used to divide these regions into different classes:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-03-02.png" alt="img"></p>
</li>
<li><p>Finally, a bounding box regression (<em>Bbox reg</em>) is used to predict the bounding boxes for each identified region:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-06-33.png" alt="img"></p>
</li>
</ul>
<p>And this, in a nutshell, is how an RCNN helps us to detect objects.</p>
<h5 id="10-1-1-2-Limitations-of-RCNN"><a href="#10-1-1-2-Limitations-of-RCNN" class="headerlink" title="10.1.1.2  Limitations of RCNN"></a>10.1.1.2  Limitations of RCNN</h5><p>Training an RCNN model is expensive and slow:</p>
<ul>
<li>Extracting 2,000 regions for each image based on selective search</li>
<li>Extracting features using CNN for every image region. Suppose we have N images, then the number of CNN features will be N*2,000</li>
<li>The entire process of object detection using RCNN has three models:<ol>
<li>CNN for feature extraction</li>
<li>Linear SVM classifier for identifying objects</li>
<li>Regression model for tightening the bounding boxes.</li>
</ol>
</li>
</ul>
<p>All these processes combine to make RCNN very slow. It takes around 40-50 seconds to make predictions for each new image, which essentially makes the model cumbersome and practically impossible to build when faced with a gigantic dataset.</p>
<p>Here’s the good news – we have another object detection technique which fixes most of the limitations we saw in RCNN.</p>
<h4 id="10-1-2-Understanding-Fast-RCNN"><a href="#10-1-2-Understanding-Fast-RCNN" class="headerlink" title="10.1.2 Understanding Fast RCNN"></a>10.1.2 Understanding Fast RCNN</h4><h5 id="10-1-2-1-Intuition-of-Fast-RCNN"><a href="#10-1-2-1-Intuition-of-Fast-RCNN" class="headerlink" title="10.1.2.1 Intuition of Fast RCNN"></a>10.1.2.1 Intuition of Fast RCNN</h5><p>What else can we do to reduce the computation time a RCNN algorithm typically takes? Instead of running a CNN 2,000 times per image, we can run it just once per image and get all the regions of interest (regions containing some object).</p>
<p>In Fast RCNN, we feed the input image to the CNN, which in turn generates the convolutional feature maps. Using these maps, the regions of proposals are extracted. We then use a RoI pooling layer to reshape all the proposed regions into a fixed size, so that it can be fed into a fully connected network.</p>
<p>Let’s break this down into steps to simplify the concept:</p>
<ol>
<li>As with the earlier two techniques, we take an image as an input.</li>
<li>This image is passed to a ConvNet which in turns generates the Regions of Interest.</li>
<li>A RoI pooling layer is applied on all of these regions to reshape them as per the input of the ConvNet. Then, each region is passed on to a fully connected network.</li>
<li>A softmax layer is used on top of the fully connected network to output classes. Along with the softmax layer, a linear regression layer is also used parallely to output bounding box coordinates for predicted classes.</li>
</ol>
<p>So, instead of using three different models (like in RCNN), Fast RCNN uses a single model which extracts features from the regions, divides them into different classes, and returns the boundary boxes for the identified classes simultaneously.</p>
<p>图解：</p>
<ul>
<li><p>Taking an image as input:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-14-59-021.png" alt="img"></p>
</li>
<li><p>This image is passed to a ConvNet which returns the region of interests accordingly:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-44-03.png" alt="img"></p>
</li>
<li><p>Then we apply the RoI pooling layer on the extracted regions of interest to make sure all the regions are of the same size:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-45-26.png" alt="img"></p>
</li>
<li><p>Finally, these regions are passed on to a fully connected network which classifies them, as well as returns the bounding boxes using softmax and linear regression layers simultaneously:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-08-15-47-18.png" alt="img"></p>
</li>
</ul>
<p>This is how Fast RCNN resolves two major issues of RCNN, i.e., <span style="color:red">passing one instead of 2,000 regions per image to the ConvNet, and using one instead of three different models for extracting features, classification and generating bounding boxes.</span></p>
<h5 id="10-1-2-2-Limitations-of-Fast-RCNN"><a href="#10-1-2-2-Limitations-of-Fast-RCNN" class="headerlink" title="10.1.2.2 Limitations of Fast RCNN"></a>10.1.2.2 Limitations of Fast RCNN</h5><p>It also uses <strong>selective search</strong> as a proposal method to find the Regions of Interest, which is a slow and time consuming process. It takes around 2 seconds per image to detect objects, which is much better compared to RCNN. But when we consider large real-life datasets, then even a Fast RCNN doesn’t look so fast anymore.</p>
<p>But there’s yet another object detection algorithm that trump Fast RCNN. </p>
<h4 id="10-1-3-Understanding-Faster-RCNN"><a href="#10-1-3-Understanding-Faster-RCNN" class="headerlink" title="10.1.3 Understanding Faster RCNN"></a>10.1.3 Understanding Faster RCNN</h4><h5 id="10-1-3-1-Intuition-of-Faster-RCNN"><a href="#10-1-3-1-Intuition-of-Faster-RCNN" class="headerlink" title="10.1.3.1 Intuition of Faster RCNN"></a>10.1.3.1 Intuition of Faster RCNN</h5><p>Faster RCNN is the modified version of Fast RCNN. The major difference between them is that Fast RCNN uses selective search for generating Regions of Interest, while Faster RCNN uses <strong>“Region Proposal Network”, aka RPN.</strong> RPN takes image feature maps as an input and generates a set of object proposals, each with an objectness score as output.</p>
<p>The  below steps are typically followed in a Faster RCNN approach:</p>
<ol>
<li>We take an image as input and pass it to the ConvNet which returns the feature map for that image.</li>
<li>Region proposal network is applied on these feature maps. This returns the object proposals along with their objectness score.</li>
<li>A RoI pooling layer is applied on these proposals to bring down all the proposals to the same size.</li>
<li>Finally, the proposals are passed to a fully connected layer which has a softmax layer and a linear regression layer at its top, to classify and output the bounding boxes for objects.</li>
</ol>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/10/Screenshot-from-2018-10-09-14-15-36.png" alt="img"></p>
<p><a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">A briefly explain how this Region Proposal Network (RPN) actually works.</a></p>
<h5 id="10-1-3-2-Limitations-of-Faster-RCNN"><a href="#10-1-3-2-Limitations-of-Faster-RCNN" class="headerlink" title="10.1.3.2 Limitations of Faster RCNN"></a>10.1.3.2 Limitations of Faster RCNN</h5><p>All of the object detection algorithms we have discussed so far use regions to identify the objects. The network does not look at the complete image in one go, but focuses on parts of the image sequentially. This creates two complications:</p>
<ul>
<li>The algorithm requires many passes through a single image to extract all the objects</li>
<li>As there are different systems working one after the other, the performance of the systems further ahead depends on how the previous systems performed</li>
</ul>
<h4 id="10-1-4-Summary"><a href="#10-1-4-Summary" class="headerlink" title="10.1.4 Summary"></a>10.1.4 Summary</h4><div class="table-container">
<table>
<thead>
<tr>
<th><strong>Algorithm</strong></th>
<th><strong>Features</strong></th>
<th><strong>Prediction time / image</strong></th>
<th><strong>Limitations</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>CNN</td>
<td>Divides the image into multiple regions and then classify each region into various classes.</td>
<td>–</td>
<td>Needs a lot of regions to predict accurately and hence high computation time.</td>
</tr>
<tr>
<td>RCNN</td>
<td>Uses selective search to generate regions. Extracts around 2000 regions from each image.</td>
<td>40-50 seconds</td>
<td>High computation time as each region is passed to the CNN separately also it uses three different model for making predictions.</td>
</tr>
<tr>
<td>Fast RCNN</td>
<td>Each image is passed only once to the CNN and feature maps are extracted. Selective search is used on these maps to generate predictions. Combines all the three models used in RCNN together.</td>
<td>2 seconds</td>
<td>Selective search is slow and hence computation time is still high.</td>
</tr>
<tr>
<td>Faster RCNN</td>
<td>Replaces the selective search method with region proposal network which made the algorithm much faster.</td>
<td>0.2 seconds</td>
<td>Object proposal takes time and as there are different systems working one after the other, the performance of systems depends on how the previous system has performed.</td>
</tr>
</tbody>
</table>
</div>
<h3 id="10-2-Implementing-Faster-RCNN-for-Object-Detection-代码"><a href="#10-2-Implementing-Faster-RCNN-for-Object-Detection-代码" class="headerlink" title="10.2 Implementing Faster RCNN for Object Detection (代码)"></a>10.2 Implementing Faster RCNN for Object Detection (代码)</h3><p><a href="https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2018/11/implementation-faster-r-cnn-python-object-detection/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a>)</p>
<h3 id="10-3-Object-Detection-using-YOLO-含代码"><a href="#10-3-Object-Detection-using-YOLO-含代码" class="headerlink" title="10.3 Object Detection using YOLO (含代码)"></a>10.3 Object Detection using YOLO (含代码)</h3><p>详细介绍见这里：<a href="https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2018/12/practical-guide-object-detection-yolo-framewor-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<p>The R-CNN family of techniques we saw in Part 1 primarily use regions to localize the objects within the image. The network does not look at the entire image, only at the parts of the images which have a higher chance of containing an object.</p>
<p>The YOLO framework (You Only Look Once) on the other hand, deals with object detection in a different way. It takes the entire image in a single instance and predicts the bounding box coordinates and class probabilities for these boxes. <strong>The biggest advantage of using YOLO is its superb speed</strong> – it’s incredibly fast and can process 45 frames per second. YOLO also understands generalized object representation.</p>
<blockquote>
<p>YOLO is a state-of-the-art object detection algorithm that is incredibly fast and accurate</p>
</blockquote>
<p>_<strong>Training</strong>_</p>
<p>The input for training our model will obviously be images and their corresponding y labels. Let’s see an image and make its y label:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2018/12/Screenshot-from-2018-11-17-15-02-11.png" alt="img"></p>
<p>Consider the scenario where we are using a 3 X 3 grid with two anchors per grid, and there are 3 different object classes. So the corresponding y labels will have a shape of 3 X 3 X 16. Now, suppose if we use 5 anchor boxes per grid and the number of classes has been increased to 5. So the target will be 3 X 3 X 10 X 5 = 3 X 3 X 50. This is how the training process is done – taking an image of a particular shape and mapping it with a 3 X 3 X 16 target (this may change as per the grid size, number of anchor boxes and the number of classes).</p>
<p><strong>_Testing_</strong></p>
<p>The new image will be divided into the same number of grids which we have chosen during the training period. For each grid, the model will predict an output of shape 3 X 3 X 16 (assuming this is the shape of the target during training time). The 16 values in this prediction will be in the same format as that of the training label. The first 8 values will correspond to anchor box 1, where the first value will be the probability of an object in that grid. Values 2-5 will be the bounding box coordinates for that object, and the last three values will tell us which class the object belongs to. The next 8 values will be for anchor box 2 and in the same format, i.e., first the probability, then the bounding box coordinates, and finally the classes.</p>
<p>Finally, the Non-Max Suppression technique will be applied on the predicted boxes to obtain a single prediction per object.</p>
<p>That brings us to the end of the theoretical aspect of understanding how the YOLO algorithm works, starting from training the model and then generating prediction boxes for the objects. Below are the exact dimensions and steps that the YOLO algorithm follows:</p>
<ul>
<li>Takes an input image of shape (608, 608, 3)</li>
<li>Passes this image to a convolutional neural network (CNN), which returns a (19, 19, 5, 85) dimensional output</li>
<li>The last two dimensions of the above output are flattened to get an output volume of (19, 19, 425):<ul>
<li>Here, each cell of a 19 X 19 grid returns 425 numbers</li>
<li>425 = 5 * 85, where 5 is the number of anchor boxes per grid</li>
<li>85 = 5 + 80, where 5 is (pc, bx, by, bh, bw) and 80 is the number of classes we want to detect</li>
</ul>
</li>
<li>Finally, we do the IoU and Non-Max Suppression to avoid selecting overlapping boxes</li>
</ul>
<h3 id="10-4-Object-detection-by-Stanford"><a href="#10-4-Object-detection-by-Stanford" class="headerlink" title="10.4 Object detection by Stanford:"></a>10.4 Object detection by Stanford:</h3><p><iframe width="560" height="315" src="https://www.youtube.com/embed/nDPWywWRIRo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>
<h3 id="10-5-其他Resources"><a href="#10-5-其他Resources" class="headerlink" title="10.5 其他Resources"></a>10.5 其他Resources</h3><ul>
<li><a href="https://arxiv.org/pdf/1506.02640.pdf" target="_blank" rel="noopener">YOLO Paper</a></li>
<li><a href="https://pjreddie.com/darknet/yolo/" target="_blank" rel="noopener">YOLO Pre-Trained Models</a></li>
</ul>
<h2 id="11-Project-3-Face-Counting-Challenge"><a href="#11-Project-3-Face-Counting-Challenge" class="headerlink" title="11. Project 3 - Face Counting Challenge"></a>11. Project 3 - Face Counting Challenge</h2><p><a href="https://datahack.analyticsvidhya.com/contest/vista-codefest-computer-vision-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://datahack.analyticsvidhya.com/contest/vista-codefest-computer-vision-1/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<h2 id="12-Project-4-COCO-Object-Detection-Challenge"><a href="#12-Project-4-COCO-Object-Detection-Challenge" class="headerlink" title="12. Project 4 - COCO Object Detection Challenge"></a>12. Project 4 - COCO Object Detection Challenge</h2><p><a href="http://cocodataset.org/#download" target="_blank" rel="noopener">http://cocodataset.org/#download</a></p>
<h2 id="13-Image-Segmentation"><a href="#13-Image-Segmentation" class="headerlink" title="13. Image Segmentation"></a>13. Image Segmentation</h2><h3 id="13-1-A-Step-by-Step-Introduction-to-Image-Segmentation-Techniques"><a href="#13-1-A-Step-by-Step-Introduction-to-Image-Segmentation-Techniques" class="headerlink" title="13.1 A Step-by-Step Introduction to Image Segmentation Techniques"></a>13.1 A Step-by-Step Introduction to Image Segmentation Techniques</h3><p><a href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<h4 id="13-1-1-What-is-Image-Segmentation"><a href="#13-1-1-What-is-Image-Segmentation" class="headerlink" title="13.1.1 What is Image Segmentation?"></a>13.1.1 What is Image Segmentation?</h4><p>An image is a collection or set of different pixels. We group together the pixels that have similar attributes using image segmentation. Take a moment to go through the below visual (it’ll give you a practical idea of image segmentation):</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/03/instance_segmentation_example.jpg" alt="object detection and instance segmentation"></p>
<p>Object detection builds a bounding box corresponding to each class in the image. But it tells us nothing about the shape of the object. We only get the set of bounding box coordinates. We want to get more information – this is too vague for our purposes.</p>
<p><span style="color:red">Image segmentation creates a pixel-wise mask for each object in the image.</span> This technique gives us a far more granular understanding of the object(s) in the image.</p>
<h4 id="13-1-2-Why-do-we-need-Image-Segmentation"><a href="#13-1-2-Why-do-we-need-Image-Segmentation" class="headerlink" title="13.1.2 Why do we need Image Segmentation?"></a>13.1.2 Why do we need Image Segmentation?</h4><p>Cancer has long been a deadly illness. Even in today’s age of technological advancements, cancer can be fatal if we don’t identify it at an early stage. Detecting cancerous cell(s) as quickly as possible can potentially save millions of lives.</p>
<p>The shape of the cancerous cells plays a vital role in determining the severity of the cancer. You might have put the pieces together – object detection will not be very useful here. We will only generate bounding boxes which will not help us in identifying the shape of the cells.</p>
<p>Image Segmentation techniques make a MASSIVE impact here. They help us approach this problem in a more granular manner and get more meaningful results. A win-win for everyone in the healthcare industry.</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/03/cancer-cell-segmentation.png" alt="cancer cell segmentation"></p>
<p>There are many other applications where Image segmentation is transforming industries:</p>
<ul>
<li>Traffic Control Systems</li>
<li>Self Driving Cars</li>
<li>Locating objects in satellite images</li>
</ul>
<h4 id="13-1-3-The-Different-Types-of-Image-Segmentation"><a href="#13-1-3-The-Different-Types-of-Image-Segmentation" class="headerlink" title="13.1.3 The Different Types of Image Segmentation"></a>13.1.3 The Different Types of Image Segmentation</h4><p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/03/Screenshot-from-2019-03-28-12-08-09.png" alt="semantic and instance segmentation"></p>
<p>If there are 5 people in an image, semantic segmentation will focus on classifying all the people as a single instance. Instance segmentation, on the other hand. will identify each of these people individually.</p>
<h4 id="13-1-4-Region-based-Segmentation-Threshold"><a href="#13-1-4-Region-based-Segmentation-Threshold" class="headerlink" title="13.1.4 Region-based Segmentation (Threshold)"></a>13.1.4 Region-based Segmentation (Threshold)</h4><p>One simple way to segment different objects could be to use their pixel values. An important point to note – the pixel values will be different for the objects and the image’s background if there’s a sharp contrast between them.</p>
<p>In this case, we can set a threshold value. The pixel values falling below or above that threshold can be classified accordingly (as an object or the background). This technique is known as <strong>Threshold Segmentation</strong>.</p>
<blockquote>
<p>If we want to divide the image into two regions (object and background), we define a single threshold value. This is known as the <strong>global threshold</strong>.</p>
<p>If we have multiple objects along with the background, we must define multiple thresholds. These thresholds are collectively known as the <strong>local threshold</strong>.</p>
</blockquote>
<p><span style="background:yellow">代码见<a href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</span></p>
<p>You can set different threshold values and check how the segments are made. Some of the advantages of this method are:</p>
<ul>
<li>Calculations are simpler</li>
<li>Fast operation speed</li>
<li>When the object and background have high contrast, this method performs really well</li>
</ul>
<p>But there are some limitations to this approach. When we don’t have significant grayscale difference, or there is an overlap of the grayscale pixel values, it becomes very difficult to get accurate segments.</p>
<h4 id="13-1-5-Edge-Detection-Segmentation"><a href="#13-1-5-Edge-Detection-Segmentation" class="headerlink" title="13.1.5 Edge Detection Segmentation"></a>13.1.5 Edge Detection Segmentation</h4><p>What divides two objects in an image? There is always an edge between two adjacent regions with different grayscale values (pixel values). The edges can be considered as the discontinuous local features of an image.</p>
<p>We can make use of this discontinuity to detect edges and hence define a boundary of the object. This helps us in detecting the shapes of multiple objects present in a given image. Now the question is how can we detect these edges? This is where we can make use of <span style="color:red">filters and convolutions</span>. Refer to <a href="https://www.analyticsvidhya.com/blog/2017/06/architecture-of-convolutional-neural-networks-simplified-demystified/?utm_source=blog&amp;utm_medium=image-segmentation-article" target="_blank" rel="noopener">this article</a> if you need to learn about these concepts.</p>
<p>Researchers have found that choosing some specific values for these weight matrices (filters) helps us to detect horizontal or vertical edges (or even the combination of horizontal and vertical edges).</p>
<p>One such weight matrix is the sobel operator. It is typically used to detect edges. </p>
<p><img src="/2020/02/18/Computer-Vision/1582182873707.png" alt="1582182873707"></p>
<p>There is one more type of filter that can detect both horizontal and vertical edges at the same time. This is called the laplace operator:</p>
<p><img src="/2020/02/18/Computer-Vision/1582182970901.png" alt="1582182970901"></p>
<p>例：</p>
<p><img src="/2020/02/18/Computer-Vision/1582183125398.png" alt="1582183125398"></p>
<p><span style="background:yellow">代码见<a href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</span></p>
<h4 id="13-1-6-Image-Segmentation-based-on-Clustering"><a href="#13-1-6-Image-Segmentation-based-on-Clustering" class="headerlink" title="13.1.6 Image Segmentation based on Clustering"></a>13.1.6 Image Segmentation based on Clustering</h4><p>Clustering is the task of dividing the population (data points) into a number of groups, such that data points in the same groups are more similar to other data points in that same group than those in other groups. These groups are known as clusters.</p>
<p>One of the most commonly used clustering algorithms is <a href="https://www.analyticsvidhya.com/blog/2016/11/an-introduction-to-clustering-and-different-methods-of-clustering/" target="_blank" rel="noopener">k-means</a>. Here, the k represents the number of clusters (not to be confused with k-nearest neighbor). Let’s understand how k-means works:</p>
<ol>
<li>First, randomly select k initial clusters</li>
<li>Randomly assign each data point to any one of the k clusters</li>
<li>Calculate the centers of these clusters</li>
<li>Calculate the distance of all the points from the center of each cluster</li>
<li>Depending on this distance, the points are reassigned to the nearest cluster</li>
<li>Calculate the center of the newly formed clusters</li>
<li>Finally, repeat steps (4), (5) and (6) until either the center of the clusters does not change or we reach the set number of iterations</li>
</ol>
<p><strong>The key advantage of using k-means algorithm is that it is simple and easy to understand.</strong> We are assigning the points to the clusters which are closest to them.</p>
<p><span style="background:yellow">代码见<a href="https://www.analyticsvidhya.com/blog/2019/04/introduction-image-segmentation-techniques-python/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</span></p>
<p>选择5 cluster的效果:</p>
<p><img src="/2020/02/18/Computer-Vision/1582183359913.png" alt="1582183359913"></p>
<p>k-means works really well when we have a small dataset. It can segment the objects in the image and give impressive results. But the algorithm hits a roadblock when applied on a large dataset (more number of images).</p>
<p>It looks at all the samples at every iteration, so the time taken is too high. Hence, it’s also too expensive to implement. And since k-means is a distance-based algorithm, it is only applicable to convex datasets and is not suitable for clustering <a href="https://en.wikipedia.org/wiki/Convex_set" target="_blank" rel="noopener">non-convex clusters</a>.</p>
<p>Finally, let’s look at a simple, flexible and general approach for image segmentation.</p>
<h4 id="13-1-7-Mask-R-CNN"><a href="#13-1-7-Mask-R-CNN" class="headerlink" title="13.1.7 Mask R-CNN"></a>13.1.7 Mask R-CNN</h4><p>Mask R-CNN is an extension of the popular <a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=image-segmentation-article" target="_blank" rel="noopener">Faster R-CNN</a> object detection architecture. Mask R-CNN adds a branch to the already existing Faster R-CNN outputs. The Faster R-CNN method generates two things for each object in the image:</p>
<ul>
<li>Its class</li>
<li>The bounding box coordinates</li>
</ul>
<p>Mask R-CNN adds a third branch to this which outputs the object mask as well. Take a look at the below image to get an intuition of how Mask R-CNN works on the inside:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/03/Mask-R-CNN.png" alt="Mask R-CNN"></p>
<ol>
<li>We take an image as input and pass it to the ConvNet, which returns the feature map for that image</li>
<li>Region proposal network (RPN) is applied on these feature maps. This returns the object proposals along with their objectness score</li>
<li>A RoI pooling layer is applied on these proposals to bring down all the proposals to the same size</li>
<li>Finally, the proposals are passed to a fully connected layer to classify and output the bounding boxes for objects. It also returns the mask for each proposal</li>
</ol>
<blockquote>
<p><strong>Mask R-CNN is the current state-of-the-art for image segmentation and runs at 5 fps.</strong></p>
</blockquote>
<h4 id="13-1-8-Summary"><a href="#13-1-8-Summary" class="headerlink" title="13.1.8 Summary"></a>13.1.8 Summary</h4><div class="table-container">
<table>
<thead>
<tr>
<th><strong>Algorithm</strong></th>
<th><strong>Description</strong></th>
<th><strong>Advantages</strong></th>
<th><strong>Limitations</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>Region-Based Segmentation</td>
<td>Separates the objects into different regions based on some threshold value(s).</td>
<td>a. Simple calculationsb. Fast operation speedc. When the object and background have high contrast, this method performs really well</td>
<td>When there is no significant grayscale difference or an overlap of the grayscale pixel values, it becomes very difficult to get accurate segments.</td>
</tr>
<tr>
<td>Edge Detection Segmentation</td>
<td>Makes use of discontinuous local features of an image to detect edges and hence define a boundary of the object.</td>
<td>It is good for images having better contrast between objects.</td>
<td>Not suitable when there are too many edges in the image and if there is less contrast between objects.</td>
</tr>
<tr>
<td>Segmentation based on Clustering</td>
<td>Divides the pixels of the image into homogeneous clusters.</td>
<td>Works really well on small datasets and generates excellent clusters.</td>
<td>a. Computation time is too large and expensive.b. k-means is a distance-based algorithm. It is not suitable for clustering non-convex clusters.</td>
</tr>
<tr>
<td>Mask R-CNN</td>
<td>Gives three outputs for each object in the image: its class, bounding box coordinates, and object mask</td>
<td>a. Simple, flexible and general approachb. It is also the current state-of-the-art for image segmentation</td>
<td>High training time</td>
</tr>
</tbody>
</table>
</div>
<h3 id="13-2-Implementing-Mask-R-CNN-for-Image-Segmentation"><a href="#13-2-Implementing-Mask-R-CNN-for-Image-Segmentation" class="headerlink" title="13.2 Implementing Mask R-CNN for Image Segmentation"></a>13.2 Implementing Mask R-CNN for Image Segmentation</h3><p><a href="https://www.analyticsvidhya.com/blog/2019/07/computer-vision-implementing-mask-r-cnn-image-segmentation/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2019/07/computer-vision-implementing-mask-r-cnn-image-segmentation/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020</a></p>
<h4 id="13-2-1-Understanding-Mask-R-CNN"><a href="#13-2-1-Understanding-Mask-R-CNN" class="headerlink" title="13.2.1 Understanding Mask R-CNN"></a>13.2.1 Understanding Mask R-CNN</h4><p>Mask R-CNN is basically an extension of <a href="https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/?utm_source=blog&amp;utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation" target="_blank" rel="noopener">Faster R-CNN</a>. Faster R-CNN is widely used for object detection tasks. For a given image, it returns the class label and bounding box coordinates for each object in the image. </p>
<p><strong>The Mask R-CNN framework is built on top of Faster R-CNN.</strong> So, for a given image, Mask R-CNN, in addition to the class label and bounding box coordinates for each object, will also return the object mask.</p>
<p>Let’s first quickly understand how Faster R-CNN works. This will help us grasp the intuition behind Mask R-CNN as well.</p>
<ul>
<li>Faster R-CNN first uses a ConvNet to extract feature maps from the images</li>
<li>These feature maps are then passed through a Region Proposal Network (RPN) which returns the candidate bounding boxes</li>
<li>We then apply an RoI pooling layer on these candidate bounding boxes to bring all the candidates to the same size</li>
<li>And finally, the proposals are passed to a fully connected layer to classify and output the bounding boxes for objects</li>
</ul>
<p>Once you understand how Faster R-CNN works, understanding Mask R-CNN will be very easy. So, let’s understand it step-by-step starting from the input to predicting the class label, bounding box, and object mask.</p>
<p><span style="background:yellow">第一步：<u>Backbone Model</u></span></p>
<p>Similar to the <a href="https://www.analyticsvidhya.com/blog/2018/12/guide-convolutional-neural-network-cnn/?utm_source=blog&amp;utm_medium=computer-vision-implementing-mask-r-cnn-image-segmentation" target="_blank" rel="noopener">ConvNet</a> that we use in Faster R-CNN to extract feature maps from the image, we use the ResNet 101 architecture to extract features from the images in Mask R-CNN. So, the first step is to take an image and extract features using the ResNet 101 architecture. These features act as an input for the next layer.</p>
<p><span style="background:yellow">第二步：<u>Region Proposal Network (RPN)</u></span></p>
<p>Now, we take the feature maps obtained in the previous step and apply a region proposal network (RPM). This basically predicts if an object is present in that region (or not). In this step, we get those regions or feature maps which the model predicts contain some object.</p>
<p><span style="background:yellow">第三步：<u>Region of Interest (RoI)</u></span></p>
<p>The regions obtained from the RPN might be of different shapes, hence, we apply a pooling layer and convert all the regions to the same shape. Next, these regions are passed through a fully connected network so that the class label and bounding boxes are predicted.</p>
<p>Till this point, the steps are almost similar to how Faster R-CNN works. Now comes the difference between the two frameworks. In addition to this, <strong>Mask R-CNN also generates the segmentation mask.</strong></p>
<p>For that, we first compute the region of interest so that the computation time can be reduced. For all the predicted regions, we compute the Intersection over Union (IoU) with the ground truth boxes. We can computer IoU like this:</p>
<p>IoU = Area of the intersection / Area of the union</p>
<p><strong>Now, only if the IoU is greater than or equal to 0.5, we consider that as a region of interest. Otherwise, we neglect that particular region. We do this for all the regions and then select only a set of regions for which the IoU is greater than 0.5.</strong></p>
<p>Let’s understand it using an example. Consider this image:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-19-16-37-49.png" alt="image_bounding_box">Here, the red box is the ground truth box for this image. Now, let’s say we got 4 regions from the RPN as shown below:</p>
<p><a href="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-19-16-46-07.png" target="_blank" rel="noopener"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-19-16-46-07.png" alt="rpn_predictions"></a></p>
<p>Here, the IoU of Box 1 and Box 2 is possibly less than 0.5, whereas the IoU of Box 3 and Box 4 is approximately greater than 0.5. Hence. we can say that Box 3 and Box 4 are the region of interest for this particular image whereas Box 1 and Box 2 will be neglected.</p>
<p>Next, let’s see the final step of Mask R-CNN.</p>
<p><span style="background:yellow">第四步：<u>Segmentation Mask</u></span></p>
<p>Once we have the RoIs based on the IoU values, we can add a mask branch to the existing architecture. This returns the segmentation mask for each region that contains an object. It returns a mask of size 28 X 28 for each region which is then scaled up for inference.</p>
<p>Again, let’s understand this visually. Consider the following image:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/3.jpg" alt="sample image for segmentation"></p>
<p>The segmentation mask for this image would look something like this:</p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2019/07/Screenshot-from-2019-07-19-16-59-48.png" alt="masks using Mask R-CNN"></p>
<p>Here, our model has segmented all the objects in the image. This is the final step in Mask R-CNN where we predict the masks for all the objects in the image.</p>
<p>Keep in mind that <strong>the training time for Mask R-CNN is quite high.</strong> It took me somewhere around 1 to 2 days to train the Mask R-CNN on the famous <a href="http://cocodataset.org/#home" target="_blank" rel="noopener">COCO dataset</a>. So, for the scope of this article, we will not be training our own Mask R-CNN model.</p>
<p>We will instead use the pretrained weights of the Mask R-CNN model trained on the COCO dataset. We will be using the <a href="https://github.com/matterport/Mask_RCNN" target="_blank" rel="noopener">mask rcnn framework</a> created by the Data scientists and researchers at Facebook AI Research (FAIR).</p>
<h4 id="13-2-2-Implement-Mask-R-CNN"><a href="#13-2-2-Implement-Mask-R-CNN" class="headerlink" title="13.2.2 Implement Mask R-CNN"></a>13.2.2 Implement Mask R-CNN</h4><p><span style="background:yellow">代码见<a href="https://www.analyticsvidhya.com/blog/2019/07/computer-vision-implementing-mask-r-cnn-image-segmentation/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">这里</a>.</span></p>
<h3 id="13-3-其他Resources"><a href="#13-3-其他Resources" class="headerlink" title="13.3 其他Resources"></a>13.3 其他Resources</h3><ul>
<li><a href="https://arxiv.org/pdf/1703.06870.pdf" target="_blank" rel="noopener">Mask R-CNN Paper</a></li>
<li><a href="https://github.com/matterport/Mask_RCNN" target="_blank" rel="noopener">Mask R-CNN GitHub Repository</a></li>
</ul>
<h2 id="14-Project-5-COCO-Segmentation-Challenge"><a href="#14-Project-5-COCO-Segmentation-Challenge" class="headerlink" title="14. Project 5 - COCO Segmentation Challenge"></a>14. Project 5 - COCO Segmentation Challenge</h2><p> <a href="http://cocodataset.org/#download" target="_blank" rel="noopener">COCO Segmentation Challenge</a></p>
<h2 id="15-Attention-Model"><a href="#15-Attention-Model" class="headerlink" title="15. Attention Model"></a>15. Attention Model</h2><ul>
<li><a href="https://www.analyticsvidhya.com/blog/2018/03/essentials-of-deep-learning-sequence-to-sequence-modelling-with-attention-part-i/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Sequence-to-Sequence Modeling with Attention</a></li>
<li><a href="https://nlp.stanford.edu/~johnhew/public/14-seq2seq.pdf" target="_blank" rel="noopener">Sequence-to-Sequence Models</a> by Stanford</li>
</ul>
<h2 id="16-Explore-Deep-Learning-Tools"><a href="#16-Explore-Deep-Learning-Tools" class="headerlink" title="16. Explore Deep Learning Tools"></a>16. Explore Deep Learning Tools</h2><h3 id="16-1-PyTorch"><a href="#16-1-PyTorch" class="headerlink" title="16.1 PyTorch"></a>16.1 PyTorch</h3><ul>
<li><a href="https://pytorch.org/tutorials/" target="_blank" rel="noopener">PyTorch Tutorials</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Beginner-Friendly Guide to PyTorch</a></li>
</ul>
<h3 id="16-2-TensorFlow"><a href="#16-2-TensorFlow" class="headerlink" title="16.2 TensorFlow"></a>16.2 TensorFlow</h3><ul>
<li><a href="https://www.tensorflow.org/tutorials" target="_blank" rel="noopener">TensorFlow Tutorials</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2016/10/an-introduction-to-implementing-neural-networks-using-tensorflow/?utm_source=blog&amp;utm_medium=computer-vision-learning-path-2020" target="_blank" rel="noopener">Introduction to TensorFlow</a></li>
</ul>]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>Computer Vision</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo相关问题</title>
    <url>/2020/02/17/hexo%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="hexo中无法显示数学公式："><a href="#hexo中无法显示数学公式：" class="headerlink" title="hexo中无法显示数学公式："></a>hexo中无法显示数学公式：</h4><p>参考 <a href="https://runninggump.github.io/2018/12/05/成功解决在hexo中无法显示数学公式的问题/" target="_blank" rel="noopener">成功解决在hexo中无法显示数学公式的问题</a></p>
<p><a href="https://blog.csdn.net/yexiaohhjk/article/details/82526604" target="_blank" rel="noopener">hexo next主题解决无法显示数学公式</a></p>
<h4 id="取消对”文章目录”的自动编号"><a href="#取消对”文章目录”的自动编号" class="headerlink" title="取消对”文章目录”的自动编号"></a>取消对”文章目录”的自动编号</h4><p><a href="https://segmentfault.com/q/1010000008494901" target="_blank" rel="noopener">hexo的NexT主题，怎么取消“文章目录”对标题的自动编号？</a></p>
<h4 id="Markdown页面内跳转"><a href="#Markdown页面内跳转" class="headerlink" title="Markdown页面内跳转"></a>Markdown页面内跳转</h4><p><a href="https://www.cnblogs.com/triple-y/p/10780644.html" target="_blank" rel="noopener">markdown页面内跳转</a></p>
<h4 id="设置文章封面"><a href="#设置文章封面" class="headerlink" title="设置文章封面"></a>设置文章封面</h4><p>参考 <a href="https://www.zhihu.com/tardis/sogou/art/60424755" target="_blank" rel="noopener">https://www.zhihu.com/tardis/sogou/art/60424755</a></p>
<p><code>&lt;!-- less --&gt;</code>: 点击阅读全文后不显示<code>&lt;!-- less --&gt;</code> 以上的内容</p>
<p><code>&lt;!-- more --&gt;</code>: 要显示</p>
<h4 id="设置标题样式（为浅蓝色）"><a href="#设置标题样式（为浅蓝色）" class="headerlink" title="设置标题样式（为浅蓝色）"></a>设置标题样式（为浅蓝色）</h4><p>参考<a href="https://juejin.im/post/5a71ab9f518825735300ee6c#heading-24" target="_blank" rel="noopener">篇Ⅱ：NexT主题的配置和优化指南</a></p>
<p><img src="/2020/02/17/hexo相关问题/1595819136654.png" alt="1595819136654"></p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*添加下面的CSS代码来修改博客标题样式*/</span></span><br><span class="line">.page-post-detail .post-title &#123;</span><br><span class="line">  font-size: <span class="number">26</span>px;</span><br><span class="line">  text-align: center;</span><br><span class="line">  word-<span class="keyword">break</span>: <span class="keyword">break</span>-word;</span><br><span class="line">  font-weight: $posts-expand-title-font-weight</span><br><span class="line">  background-color: #b9d3ee;</span><br><span class="line">  border-radius:<span class="number">.3</span>em;</span><br><span class="line">  line-height:<span class="number">1</span>em;</span><br><span class="line">  padding-bottom:<span class="number">.12</span>em;</span><br><span class="line">  padding-top:<span class="number">.12</span>em;</span><br><span class="line">  box-shadow:2px 2px 7px #9fb6cd;</span><br><span class="line">  +mobile() &#123;</span><br><span class="line">    font-size: <span class="number">22</span>px;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*添加上面的CSS代码来修改博客标题样式*/</span></span><br><span class="line"></span><br><span class="line">@<span class="keyword">import</span> <span class="string">"post-expand"</span>;</span><br><span class="line">@<span class="keyword">import</span> <span class="string">"post-collapse"</span>;</span><br><span class="line">@<span class="keyword">import</span> <span class="string">"post-type"</span>;</span><br><span class="line">@<span class="keyword">import</span> <span class="string">"post-title"</span>;</span><br></pre></td></tr></table></figure>
<p><em>注意：如果想把主页标题样式一同修改，可以用把</em> <code>.page-post-detail</code> 去掉。</p>
<h4 id="修改文章内链接文本样式"><a href="#修改文章内链接文本样式" class="headerlink" title="修改文章内链接文本样式"></a>修改文章内链接文本样式</h4><p> 参考<a href="https://www.cnblogs.com/brady-wang/p/8416122.html" target="_blank" rel="noopener">hexo的next主题个性化教程:打造炫酷网站</a></p>
<p>实现效果图</p>
<p><img src="https://upload-images.jianshu.io/upload_images/5308475-8cc4fc18c399af7e.gif" alt="img"></p>
<p>修改文件 <code>themes\next\source\css\_common\components\post\post.styl</code>，在末尾添加如下css样式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 文章内链接文本样式</span><br><span class="line">.post-body p a&#123;</span><br><span class="line">  color: #0593d3;</span><br><span class="line">  border-bottom: none;</span><br><span class="line">  border-bottom: 1px solid #0593d3;</span><br><span class="line">  &amp;:hover &#123;</span><br><span class="line">    color: #fc6423;</span><br><span class="line">    border-bottom: none;</span><br><span class="line">    border-bottom: 1px solid #fc6423;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中选择<code>.post-body</code> 是为了不影响标题，选择 <code>p</code> 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。</p>
<h4 id="修改主题页面布局为圆角"><a href="#修改主题页面布局为圆角" class="headerlink" title="修改主题页面布局为圆角"></a>修改主题页面布局为圆角</h4><p>参考<a href="https://wugenqiang.github.io/articles/hexo-do-optimization.html中3.12.2" target="_blank" rel="noopener">https://wugenqiang.github.io/articles/hexo-do-optimization.html中3.12.2</a></p>
<p>对scheme为Mist时无用？</p>
<h4 id="NeXT第三方服务集成"><a href="#NeXT第三方服务集成" class="headerlink" title="NeXT第三方服务集成"></a>NeXT第三方服务集成</h4><p>(评论系统，数据统计与分析，内容分享服务，搜索服务等)</p>
<p><a href="http://theme-next.iissnan.com/third-party-services.html#google-webmaster-tools" target="_blank" rel="noopener">NeXT第三方服务集成</a></p>
<p>文章及网站访问量：</p>
<p><img src="/2020/02/17/hexo相关问题/1595773900727.png" alt="1595773900727"></p>
<p>注：由于原链接已失效，还需修改</p>
<p>themes\next\layout_third_party\analytics\busuanzi-counter.swig 中</p>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">src = <span class="string">"https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"</span></span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/17/hexo相关问题/1595774099538.png" alt="1595774099538"></p>
<h4 id="给博客加上萌宠或萌妹子"><a href="#给博客加上萌宠或萌妹子" class="headerlink" title="给博客加上萌宠或萌妹子"></a>给博客加上萌宠或萌妹子</h4><p>参考 <a href="https://www.jianshu.com/p/c59a15d90759" target="_blank" rel="noopener">https://www.jianshu.com/p/c59a15d90759</a></p>
<p>不同的选择效果见 <a href="https://huaji8.top/post/live2d-plugin-2.0/" target="_blank" rel="noopener">https://huaji8.top/post/live2d-plugin-2.0/</a></p>
<h4 id="添加背景音乐"><a href="#添加背景音乐" class="headerlink" title="添加背景音乐"></a>添加背景音乐</h4><p><a href="https://www.cnblogs.com/Guhongying/p/10461970.html" target="_blank" rel="noopener">Hexo 的next主题下添加网易云音乐作BGM</a></p>
<p>网易云音乐无法生成外链：</p>
<p><a href="https://www.cnblogs.com/cstdio1/p/11617357.html" target="_blank" rel="noopener">https://www.cnblogs.com/cstdio1/p/11617357.html</a></p>
<p>（<span style="background:yellow">更新</span>：参考以上方法时，无法播放音乐？）</p>
<p>另一个方法参考：<a href="https://blog.csdn.net/qq_35859750/article/details/91452615" target="_blank" rel="noopener">hexo添加音乐</a></p>
<p>安装aplayer: <code>npm install --save hexo-tag-aplayer</code></p>
<p>粘贴以下内容到 \themes\next\layout\_macro\sidebar.swig</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 新增的内容 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- require APlayer --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">"stylesheet"</span> <span class="attr">href</span>=<span class="string">"https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- require MetingJS --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">meting-js</span></span></span><br><span class="line"><span class="tag"><span class="attr">server</span>=<span class="string">"netease"</span> </span></span><br><span class="line"><span class="tag"><span class="attr">type</span>=<span class="string">"song"</span></span></span><br><span class="line"><span class="tag"><span class="attr">id</span>=<span class="string">"188376"</span></span></span><br><span class="line"><span class="tag">&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">meting-js</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 新增的内容end --&gt;</span></span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/17/hexo相关问题/1582012566416.png" alt="1582012566416"></p>
<p>即可.</p>
<p>其中server, type, id等根据具体情况修改.</p>
<p>例：</p>
<p><img src="/2020/02/17/hexo相关问题/1582014322346.png" alt="1582014322346"></p>
<h4 id="关于目录"><a href="#关于目录" class="headerlink" title="关于目录"></a>关于目录</h4><p>在 themes\next\_config.yml 中设定，不要去安装 hexo-toc，否则会冲突</p>
<p><img src="/2020/02/17/hexo相关问题/1582014793720.png" alt="1582014793720"></p>
<h4 id="嵌入视频"><a href="#嵌入视频" class="headerlink" title="嵌入视频"></a>嵌入视频</h4><p>参考 <a href="https://www.bilibili.com/video/av23207325/" target="_blank" rel="noopener">https://www.bilibili.com/video/av23207325/</a></p>]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>B树介绍</title>
    <url>/2020/02/16/B%E6%A0%91%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><blockquote>
<p>参考：<a href="https://blog.csdn.net/A_zhangq/article/details/99662693" target="_blank" rel="noopener">https://blog.csdn.net/A_zhangq/article/details/99662693</a></p>
<p><a href="https://blog.csdn.net/qq_35571554/article/details/82759668" target="_blank" rel="noopener">漫画叙述B+树和B-树，很值得看!</a></p>
</blockquote>
<h3 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h3><p>B-树就是B树（可能有部分人会习惯上把B-树读为B减树，其实并不存在B减树，只是读法上的不同而已），B就是balanced，平衡的意思。<strong>B-树就是指的B树</strong>。</p>
<p>B-树是一种多路搜索树（并不是二叉的）：    </p>
<ol>
<li><p>定义任意非叶子结点最多只有M个儿子，且M&gt;2；    </p>
</li>
<li><p>根结点的儿子数为 [2, M]；    </p>
</li>
<li><p>除根结点以外的非叶子结点的儿子数为 [M/2, M]；    </p>
</li>
<li><p>每个结点存放至少 M/2-1（取上整）和至多  M-1 个关键字；（至少 2个关键字）    </p>
</li>
<li><p>非叶子结点的关键字个数 = 指向儿子的指针个数 - 1；    </p>
</li>
<li><p>非叶子结点的关键字：K[1], K[2], …, K[M-1]；且 K[i] &lt; K[i+1] ；    </p>
</li>
<li><p>非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1] 指向关键字小于 K[1] 的子树，P[M] 指向关键字大于            K[M-1] 的子树，其它 P[i] 指向关键字属于(K[i-1], K[i]) 的子树；    </p>
</li>
<li><p>所有叶子结点位于同一层；    </p>
</li>
</ol>
<p>如 (M = 3)：</p>
<p><img src="https://img-blog.csdnimg.cn/20190815211241789.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Ffemhhbmdx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><strong>B-树的搜索：</strong></p>
<p>从根结点开始，对结点内的关键字（有序）序列进行二分查找，如果命中则结束，否则进入查询关键字所属范围的儿子结点；重复，直到所对应的儿子指针为空，或已经是叶子结点.</p>
<p><strong>B-树的特性：</strong></p>
<ul>
<li>关键字集合分布在整颗树中；</li>
<li>任何一个关键字出现且只出现在一个结点中；</li>
<li>搜索有可能在非叶子结点结束；</li>
<li>其搜索性能等价于在关键字全集内做一次二分查找；</li>
<li>自动层次控制；</li>
</ul>
<hr>
<a id="more"></a>
<h3 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h3><p>B+树是B-树的变体，也是一种多路搜索树：</p>
<p>其定义基本与B-树同，除了：</p>
<ol>
<li>非叶子结点的子树指针与关键字个数相同；</li>
<li>非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1]]的子树（B-树是开区间）；</li>
<li>为所有叶子结点增加一个链指针；</li>
<li>所有关键字都在叶子结点出现；</li>
</ol>
<p>如（M=3）:</p>
<p><img src="https://img-blog.csdnimg.cn/20190817142029576.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Ffemhhbmdx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p><strong>B+树的搜索</strong>：</p>
<p>与B-树基本相同，区别是B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），其性能也等价于在关键字全集做一次二分查找；</p>
<p><strong>B+树的特性：</strong></p>
<ul>
<li>所有关键字都出现在叶子结点的链表中（稠密索引），且链表中的关键字恰好是<strong>有序</strong>的；</li>
<li>不可能在非叶子结点命中；</li>
<li>非叶子结点相当于是叶子结点的索引（稀疏索引），叶子结点相当于是存储（关键字）数据的数据层；</li>
<li>更适合文件索引系统；</li>
</ul>
<blockquote>
<p>关于稠密索引与稀疏索引：<a href="https://blog.csdn.net/Qmen_Crow/article/details/51052160" target="_blank" rel="noopener">https://blog.csdn.net/Qmen_Crow/article/details/51052160</a></p>
</blockquote>
<p><strong>B+树的分裂：</strong></p>
<p>当一个结点满时，分配一个新的结点，并将原结点中1/2的数据复制到新结点，最后在父结点中增加新结点的指针；B+树的分裂只影响原结点和父结点，而不会影响兄弟结点，所以它不需要指向兄弟的指针。</p>
<hr>
<h3 id="B-树-1"><a href="#B-树-1" class="headerlink" title="B*树"></a>B*树</h3><p>B*树是B+树的一种变形，它是在B+树的基础上，将索引层以指针连接起来（在B+树的非根和非叶子结点再增加指向兄弟的指针），使搜索取值更加快捷。 </p>
<p>如下图（M = 3）：</p>
<p><img src="https://img-blog.csdnimg.cn/20190817142644325.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0Ffemhhbmdx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>B*树在B+树的基础上产生了一系列的变化，如下：</p>
<ol>
<li>B*树定义了非叶子结点关键字个数至少为(2/3)M，即块的最低使用率为2/3（代替B+树的1/2）；</li>
<li><strong>B *树的分裂：</strong>当一个结点满时，如果它的下一个兄弟结点未满，那么将一部分数据移到兄弟结点中，再在原结点插入关键字，最后修改父结点中兄弟结点的关键字（因为兄弟结点的关键字范围改变了）；如果兄弟也满了，则在原结点与兄弟结点之间增加新结点，并各复制1/3的数据到新结点，最后在父结点增加新结点的指针。</li>
</ol>
<p>B*树相对于B+树，空间利用率上有所提高，查询速率也有所提高。</p>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><p>二叉搜索树：二叉树，每个结点只存储一个关键字且值大于左子树，小于右子树。</p>
</li>
<li><p>B（B-）树：多路搜索树，每个结点存储 M/2-1 到 M - 1 个关键字，非叶子结点存储指向关键字范围的子结点； 所有关键字在整颗树中出现，且只出现一次，非叶子结点可以命中；</p>
</li>
<li>B+树：在B-树基础上，为叶子结点增加链表指针，所有关键字都在叶子结点中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中；</li>
<li>B*树：在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1/2提高到2/3；</li>
</ul>
<p><img src="/2020/02/16/B树介绍/1581863461822.png" alt="1581863461822"></p>
<p>这两种树都是平衡的多分树，它们都可以用于文件的索引结构，但B树只能支持随机检索，而B+树是有序的树，既能支持随机检索，又能支持顺序检索。</p>]]></content>
      <tags>
        <tag>B树</tag>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN相关资料（LSTM, GRU）</title>
    <url>/2020/02/15/RNN%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="pdf："><a href="#pdf：" class="headerlink" title="pdf："></a>pdf：</h4><p><a href="https://www.aclweb.org/anthology/C16-1311.pdf" target="_blank" rel="noopener">Effective LSTMs for Target-Dependent Sentiment Classification</a></p>
<h4 id="网页："><a href="#网页：" class="headerlink" title="网页："></a>网页：</h4><p><a href="https://www.jianshu.com/p/95d5c461924c" target="_blank" rel="noopener">【译】理解LSTM（通俗易懂版）</a></p>
<p><a href="https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be" target="_blank" rel="noopener">Understanding GRU Networks</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/32481747" target="_blank" rel="noopener">人人都能看懂的GRU</a></p>
<p><a href="https://www.cnblogs.com/jiangxinyang/p/9376021.html" target="_blank" rel="noopener">深度学习之GRU网络</a></p>
<p><a href="https://www.jianshu.com/p/3774d46b665e" target="_blank" rel="noopener">lstm和gru结构的再理解</a></p>
<p><a href="http://www.sohu.com/a/336551522_99979179" target="_blank" rel="noopener">图解LSTM与GRU单元的各个公式和区别 </a></p>
<p><a href="https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/" target="_blank" rel="noopener">Fundamentals of Deep Learning – Introduction to Recurrent Neural Networks</a></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN相关资料</title>
    <url>/2020/02/15/CNN%E7%9B%B8%E5%85%B3%E8%B5%84%E6%96%99/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="pdf："><a href="#pdf：" class="headerlink" title="pdf："></a>pdf：</h4><p><a href="https://www.aclweb.org/anthology/D14-1181.pdf" target="_blank" rel="noopener">Convolutional Neural Networks for Sentence Classification</a></p>
<h4 id="网页："><a href="#网页：" class="headerlink" title="网页："></a>网页：</h4><p><a href="https://www.cnblogs.com/yelbosh/p/5808706.html" target="_blank" rel="noopener">卷积神经网络CNN在自然语言处理中的应用</a></p>
<h4 id="卷积与矩阵乘法："><a href="#卷积与矩阵乘法：" class="headerlink" title="卷积与矩阵乘法："></a>卷积与矩阵乘法：</h4><p><img src="/2020/02/15/CNN相关资料/卷积与矩阵乘法.jpg" alt="卷积与矩阵乘法"></p>
<p><img src="/2020/02/15/CNN相关资料/example.jpg" alt="example"></p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>CNN</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>移动零</title>
    <url>/2020/02/05/%E7%A7%BB%E5%8A%A8%E9%9B%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/move-zeroes/" target="_blank" rel="noopener">移动零（难度：简答）</a></p>
<p><img src="/2020/02/05/移动零/1580888243775.png" alt="1580888243775"></p>
<p>问题的两个要求是：</p>
<ul>
<li>将所有 0 移动到数组末尾。</li>
<li>所有非零元素必须保持其原始顺序。</li>
</ul>
<p>这里很好地认识到这两个需求是相互排斥的，也就是说，你可以解决单独的子问题，然后将它们组合在一起以得到最终的解决方案。</p>
<h4 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h4><ul>
<li>一个指针<code>i</code>从前到后遍历数组，每当遇到非0数时，令 <code>nums[cur] = nums[i]; cur++;</code>，<code>cur</code>是另一个指针（从0开始），记录当前位置。</li>
<li>当<code>i</code>遍历完后，此时<code>cur</code>指向的位置到数组的末尾全赋为0即可。</li>
</ul>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">moveZeroes</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> cur = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]!=<span class="number">0</span>)&#123;</span><br><span class="line">                nums[cur] = nums[i];</span><br><span class="line">                cur++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(cur &lt; nums.length)&#123;</span><br><span class="line">            nums[cur] = <span class="number">0</span>;</span><br><span class="line">            cur++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/02/05/移动零/1580890229187.png" alt="1580890229187"></p>
<p><strong>复杂度</strong></p>
<ul>
<li>时间复杂度：O(n)。</li>
<li>空间复杂度：O(1)。</li>
</ul>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>最小覆盖子串</title>
    <url>/2020/01/28/%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/minimum-window-substring/" target="_blank" rel="noopener">最小覆盖子串（难度：困难）</a></p>
<p><img src="/2020/01/28/最小覆盖子串/1580195563488.png" alt="1580195563488"></p>
<h4 id="方法：滑动窗口"><a href="#方法：滑动窗口" class="headerlink" title="方法：滑动窗口"></a>方法：滑动窗口</h4><h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><ol>
<li><p>初始，<code>left</code>指针和<code>right</code>指针都指向<code>s</code>的第一个元素.</p>
</li>
<li><p>将 <code>right</code>指针右移，扩张窗口，直到得到一个可行窗口，亦即包含<code>t</code>的全部字母的窗口。</p>
</li>
<li><p>得到可行的窗口后，将<code>left</code>指针逐个右移，若得到的窗口依然可行，则更新最小窗口大小。</p>
</li>
<li><p>若窗口不再可行，则跳转至 2。</p>
</li>
</ol>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minWindow</span><span class="params">(self, s: str, t: str)</span> -&gt; str:</span></span><br><span class="line">        left = <span class="number">0</span></span><br><span class="line">        right = <span class="number">0</span></span><br><span class="line">        res = <span class="string">""</span></span><br><span class="line">        need = defaultdict(int)</span><br><span class="line">        window = defaultdict(int)</span><br><span class="line">        minLen = len(s)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> t:</span><br><span class="line">            need[i] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> right &lt; len(s):</span><br><span class="line">            window[s[right]] += <span class="number">1</span></span><br><span class="line">            <span class="keyword">while</span> self.con(need,window):</span><br><span class="line">                <span class="keyword">if</span> len(s[left:right+<span class="number">1</span>]) &lt; minLen:</span><br><span class="line">                    minLen = len(s[left:right+<span class="number">1</span>])</span><br><span class="line">                    res = s[left:right+<span class="number">1</span>]</span><br><span class="line">                window[s[left]] -= <span class="number">1</span></span><br><span class="line">                left += <span class="number">1</span></span><br><span class="line">            right += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">con</span><span class="params">(self, need, window)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> key <span class="keyword">in</span> need.keys():</span><br><span class="line">            <span class="keyword">if</span> need[key] &gt; window[key]:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p><img src="/2020/01/28/最小覆盖子串/1580201292271.png" alt="1580201292271"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>滑动窗口最大值</title>
    <url>/2020/01/22/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E6%9C%80%E5%A4%A7%E5%80%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/sliding-window-maximum/" target="_blank" rel="noopener">滑动窗口最大值（难度：困难）</a></p>
<p><img src="/2020/01/22/滑动窗口最大值/1579702056767.png" alt="1579702056767"></p>
<p><img src="/2020/01/22/滑动窗口最大值/1579702078067.png" alt="1579702078067"></p>
<h4 id="方法一：暴力法"><a href="#方法一：暴力法" class="headerlink" title="方法一：暴力法"></a>方法一：暴力法</h4><p>遍历每个滑动窗口，找到每个窗口的最大值。一共有 N - k + 1 个滑动窗口，每个有 k 个元素，于是算法的时间复杂度为 O(Nk)，表现较差。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span><span class="params">(self, nums: List[int], k: int)</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> nums</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(nums)-(k<span class="number">-1</span>)):</span><br><span class="line">            j = i + k<span class="number">-1</span></span><br><span class="line">            res.append(max(nums[i:j+<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/22/滑动窗口最大值/1579666044377.png" alt="1579666044377"></p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><ul>
<li>时间复杂度：O(Nk)。其中 <code>N</code> 为数组中元素个数。</li>
<li>空间复杂度：O<em>(</em>N<em>−</em>k+1)，用于输出数组。</li>
</ul>
<h4 id="方法二：递归"><a href="#方法二：递归" class="headerlink" title="方法二：递归"></a>方法二：递归</h4><p>详细讲解见<a href="https://leetcode-cn.com/problems/sliding-window-maximum/solution/hua-dong-chuang-kou-zui-da-zhi-by-leetcode-3/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/sliding-window-maximum/solution/hua-dong-chuang-kou-zui-da-zhi-by-leetcode-3/</a></p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span><span class="params">(self, nums: List[int], k: int)</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) &lt;= <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">return</span> nums</span><br><span class="line">        </span><br><span class="line">        n = len(nums)</span><br><span class="line">        left = [<span class="number">0</span>]*n</span><br><span class="line">        right = [<span class="number">0</span>]*n</span><br><span class="line">        left[<span class="number">0</span>] = nums[<span class="number">0</span>]</span><br><span class="line">        right[n<span class="number">-1</span>] = nums[n<span class="number">-1</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">            <span class="comment"># 从左到右</span></span><br><span class="line">            <span class="keyword">if</span> i % k == <span class="number">0</span>: </span><br><span class="line">                <span class="comment"># block start</span></span><br><span class="line">                left[i] = nums[i]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                left[i] = max(left[i<span class="number">-1</span>], nums[i])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 从右到左</span></span><br><span class="line">            j = n - i - <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> (j+<span class="number">1</span>) % k == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># block end</span></span><br><span class="line">                right[j] = nums[j]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                right[j] = max(right[j+<span class="number">1</span>], nums[j])</span><br><span class="line">        </span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n-k+<span class="number">1</span>):</span><br><span class="line">            j = i+k<span class="number">-1</span></span><br><span class="line">            res.append(max(right[i], left[j]))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/22/滑动窗口最大值/1579669254322.png" alt="1579669254322"></p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(N)，我们对长度为 N 的数组处理了 3次。</p>
<p>空间复杂度：O(N)，用于存储长度为 N 的 left 和 right 数组，以及长度为 N - k + 1的输出数组。</p>
<h4 id="方法三：双端队列"><a href="#方法三：双端队列" class="headerlink" title="方法三：双端队列"></a>方法三：双端队列</h4><p><img src="/2020/01/22/滑动窗口最大值/1579703855488.png" alt="1579703855488"></p>
<p><img src="/2020/01/22/滑动窗口最大值/1579703901936.png" alt="1579703901936"></p>
<p>思路：维护窗口，向右移动时左侧超出窗口的值弹出，因为需要的是窗口内的最大值，所以只要保证窗口内的值是递减的即可，小于新加入的值全部弹出。最左端即为窗口最大值 </p>
<h5 id="代码-2"><a href="#代码-2" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">maxSlidingWindow</span><span class="params">(self, nums: List[int], k: int)</span> -&gt; List[int]:</span></span><br><span class="line">        temp = []</span><br><span class="line">        res = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i,v <span class="keyword">in</span> enumerate(nums): <span class="comment"># i是索引，v是值</span></span><br><span class="line">            <span class="comment"># 左侧超出窗口的值弹出</span></span><br><span class="line">            <span class="keyword">if</span> i&gt;=k <span class="keyword">and</span> temp[<span class="number">0</span>]&lt;=i-k:</span><br><span class="line">                temp.pop(<span class="number">0</span>) <span class="comment"># pop索引为0的数</span></span><br><span class="line">            <span class="keyword">while</span> temp <span class="keyword">and</span> nums[temp[<span class="number">-1</span>]] &lt;= v:</span><br><span class="line">                temp.pop() <span class="comment"># pop最后一个数</span></span><br><span class="line">            temp.append(i)</span><br><span class="line">            <span class="keyword">if</span> i&gt;=k<span class="number">-1</span>:</span><br><span class="line">                res.append(nums[temp[<span class="number">0</span>]])</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/22/滑动窗口最大值/1579704974700.png" alt="1579704974700"></p>
<h5 id="复杂度-2"><a href="#复杂度-2" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(N)，每个元素被处理两次- 其索引被添加到双向队列中和被双向队列删除。</p>
<p>空间复杂度：O(N)，输出数组使用了O(N−k+1) 空间，双向队列使用了 O(k)。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>递归</tag>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树的中序遍历</title>
    <url>/2020/01/21/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/" target="_blank" rel="noopener">二叉树的中序遍历（难度：中等）</a></p>
<p><img src="/2020/01/21/二叉树的中序遍历/1579622453083.png" alt="1579622453083"></p>
<p><strong>中序遍历：左-中-右</strong></p>
<h4 id="方法一：递归"><a href="#方法一：递归" class="headerlink" title="方法一：递归"></a>方法一：递归</h4><p>定义一个辅助函数来实现递归。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> List &lt; Integer &gt; inorderTraversal(TreeNode root) &#123;</span><br><span class="line">        List &lt; Integer &gt; res = <span class="keyword">new</span> ArrayList &lt; &gt; ();</span><br><span class="line">        helper(root, res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">helper</span><span class="params">(TreeNode root, List &lt; Integer &gt; res)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (root != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (root.left != <span class="keyword">null</span>) &#123;</span><br><span class="line">                helper(root.left, res);</span><br><span class="line">            &#125;</span><br><span class="line">            res.add(root.val);</span><br><span class="line">            <span class="keyword">if</span> (root.right != <span class="keyword">null</span>) &#123;</span><br><span class="line">                helper(root.right, res);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。递归函数 T(n) = 2 T(n/2)+1。<br>空间复杂度：最坏情况下需要空间O(n)，平均情况为O(logn)。</p>
<h4 id="方法二：迭代"><a href="#方法二：迭代" class="headerlink" title="方法二：迭代"></a>方法二：迭代</h4><p>颜色标记法：</p>
<blockquote>
<p>作者：hzhu212<br>链接：<a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/solution/yan-se-biao-ji-fa-yi-chong-tong-yong-qie-jian-ming/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/binary-tree-inorder-traversal/solution/yan-se-biao-ji-fa-yi-chong-tong-yong-qie-jian-ming/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>其核心思想如下：</p>
<ul>
<li>使用颜色标记节点的状态，新节点为白色，已访问的节点为灰色。</li>
<li>如果遇到的节点为白色，则将其标记为灰色，然后将其右子节点、自身、左子节点依次入栈。</li>
<li>如果遇到的节点为灰色，则将节点的值输出。</li>
</ul>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span><span class="params">(self, root: TreeNode)</span> -&gt; List[int]:</span></span><br><span class="line">        WHITE, GRAY = <span class="number">0</span>, <span class="number">1</span></span><br><span class="line">        res = []</span><br><span class="line">        stack = [(WHITE, root)]</span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            color, node = stack.pop()</span><br><span class="line">            <span class="keyword">if</span> node == <span class="literal">None</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> color == WHITE:</span><br><span class="line">                stack.append((WHITE, node.right))</span><br><span class="line">                stack.append((GRAY, node))</span><br><span class="line">                stack.append((WHITE, node.left))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                res.append(node.val)</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p>如要实现前序、后序遍历，只需要调整左右子节点的入栈顺序即可。</p>
<h5 id="另一种写法："><a href="#另一种写法：" class="headerlink" title="另一种写法："></a>另一种写法：</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span><span class="params">(self, root: TreeNode)</span> -&gt; List[int]:</span></span><br><span class="line">        stack = []</span><br><span class="line">        res = []</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">while</span> root:</span><br><span class="line">                stack.append(root)</span><br><span class="line">                root = root.left</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> stack:</span><br><span class="line">                <span class="keyword">return</span> res</span><br><span class="line">            root = stack.pop()</span><br><span class="line">            res.append(root.val)</span><br><span class="line">            root = root.right</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/21/二叉树的中序遍历/1579622422214.png" alt="1579622422214"></p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。</p>
<p>空间复杂度：O(n)。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">算法</th>
<th style="text-align:left">执行用时</th>
<th style="text-align:left">内存消耗</th>
<th style="text-align:left">语言</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">方法二：迭代（另一种写法）</td>
<td style="text-align:left">28 ms</td>
<td style="text-align:left">13 MB</td>
<td style="text-align:left">Python3</td>
</tr>
<tr>
<td style="text-align:left">方法二：迭代（颜色标价法）</td>
<td style="text-align:left">36 ms</td>
<td style="text-align:left">12.7 MB</td>
<td style="text-align:left">Python3</td>
</tr>
<tr>
<td style="text-align:left">方法一：递归</td>
<td style="text-align:left">0 ms</td>
<td style="text-align:left">34.6 MB</td>
<td style="text-align:left">Java</td>
</tr>
</tbody>
</table>
</div>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>二叉树</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉搜索树中第k小的元素</title>
    <url>/2020/01/21/%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%E4%B8%AD%E7%AC%ACk%E5%B0%8F%E7%9A%84%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/" target="_blank" rel="noopener">二叉搜索树中第K小的元素（难度：中等）</a></p>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/1579620616705.png" alt="1579620616705"></p>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/1579620662544.png" alt="1579620662544"></p>
<p>此题与<a href="https://qypx.github.io/2020/01/21/二叉树的中序遍历/">二叉树的中序遍历（难度：中等）</a>类似，只需稍加变化。</p>
<h4 id="方法一：递归"><a href="#方法一：递归" class="headerlink" title="方法一：递归"></a>方法一：递归</h4><p>通过构造 BST 的中序遍历序列，则第 <code>k-1</code> 个元素就是第 <code>k</code> 小的元素。</p>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/7dc3fe454519e27105c5aaf57d20b26137bd77c56bb0289830bf18116627de12-file_1579413216156.jpg" alt="7dc3fe454519e27105c5aaf57d20b26137bd77c56bb0289830bf18116627de12-file_1579413216156"></p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">kthSmallest</span><span class="params">(TreeNode root, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        List&lt;Integer&gt; arr = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        inorder(root,arr);</span><br><span class="line">        <span class="keyword">return</span> arr.get(k-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">inorder</span><span class="params">(TreeNode root, List arr)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(root.left!=<span class="keyword">null</span>)</span><br><span class="line">                inorder(root.left, arr);</span><br><span class="line">            arr.add(root.val);</span><br><span class="line">            <span class="keyword">if</span>(root.right!=<span class="keyword">null</span>)</span><br><span class="line">                inorder(root.right, arr);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/1579620513520.png" alt="1579620513520"></p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(N)，遍历了整个树。</p>
<p>空间复杂度：O(N)，用了一个数组存储中序序列。</p>
<h4 id="方法二：迭代"><a href="#方法二：迭代" class="headerlink" title="方法二：迭代"></a>方法二：迭代</h4><p>在栈的帮助下，可以将方法一的递归转换为迭代，这样可以加快速度，因为这样可以不用遍历整个树，可以在找到答案后停止。</p>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/25159a5137867644b75f203ee1917645d2cd454d8f4871e371d7edfa67bef083-file_1579413216176.jpg" alt="25159a5137867644b75f203ee1917645d2cd454d8f4871e371d7edfa67bef083-file_1579413216176"></p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"># class TreeNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, x):</span></span><br><span class="line"><span class="comment">#         self.val = x</span></span><br><span class="line"><span class="comment">#         self.left = None</span></span><br><span class="line"><span class="comment">#         self.right = None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kthSmallest</span><span class="params">(self, root: TreeNode, k: int)</span> -&gt; int:</span></span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">while</span> root:</span><br><span class="line">                stack.append(root)</span><br><span class="line">                root = root.left</span><br><span class="line">            root = stack.pop()</span><br><span class="line">            k -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">return</span> root.val</span><br><span class="line">            root = root.right</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/21/二叉搜索树中第k小的元素/1579621550313.png" alt="1579621550313"></p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(H+k)，其中 H指的是树的高度，由于我们开始遍历之前，要先向下达到叶，当树是一个平衡树时：复杂度为O(logN+k)。当树是一个不平衡树时：复杂度为 O(N+k)，此时所有的节点都在左子树。</p>
<p>空间复杂度：O(H+k)。当树是一个平衡树时：O(logN+k)。当树是一个非平衡树时：O(N+k)。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>二叉树</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title>最长连续序列</title>
    <url>/2020/01/20/%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-consecutive-sequence/" target="_blank" rel="noopener">最长连续序列（难度：困难）</a></p>
<p><img src="/2020/01/20/最长连续序列/1579513410172.png" alt="1579513410172"></p>
<h4 id="方法：哈希表（HashSet）"><a href="#方法：哈希表（HashSet）" class="headerlink" title="方法：哈希表（HashSet）"></a>方法：哈希表（HashSet）</h4><p>因为一个序列可能在 <code>nums</code> 数组的任意一个数字开始，我们可以枚举每个数字作为序列的第一个数字，搜索所有的可能性 （暴力法）。优化：将数组中的数字用HashSet保存，实现O(1)的时间查询，同时，我们只对 <code>当前数字 - 1</code> 不在哈希表里的数字，作为连续序列的第一个数字去找对应的最长序列，这是因为其他数字一定已经出现在了某个序列里。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">longestConsecutive</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (nums.length &lt;= <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> nums.length;</span><br><span class="line">            </span><br><span class="line">        HashSet&lt;Integer&gt; hashSet = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num:nums)</span><br><span class="line">            hashSet.add(num);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> maxLen = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> curLen = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span>(!hashSet.contains(nums[i]-<span class="number">1</span>))&#123;</span><br><span class="line">                <span class="keyword">int</span> curNum = nums[i];</span><br><span class="line">                <span class="keyword">while</span>(hashSet.contains(curNum+<span class="number">1</span>))&#123;</span><br><span class="line">                    curLen++;</span><br><span class="line">                    curNum++;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            maxLen = Math.max(maxLen,curLen);</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> maxLen;        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。尽管在 for 循环中嵌套了一个 while 循环，时间复杂度看起来像是二次方级别的。但其实它是线性的算法。因为只有当 curNum 遇到了一个序列的开始， while 循环才会被执行（也就是 curNum-1 不在数组 nums 里）， while 循环在整个运行过程中只会被迭代 n 次。这意味着尽管看起来时间复杂度为 O(n⋅n) ，实际这个嵌套循环只会运行O(n+n)=O(n) 次。所有的计算都是线性时间的，所以总的时间复杂度是 O(n)的。</p>
<p>空间复杂度：O(n)。为了实现 O(1)的查询，我们对哈希表分配线性空间，以保存 nums 数组中的 O(n)个数字。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title>HashSet</title>
    <url>/2020/01/20/HashSet/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul>
<li>无序列表HashSet是采用hash表来实现的。其中的元素没有按顺序排列，add()、remove()以及contains()等方法都是复杂度为O(1)的方法。 </li>
<li>无序列表列表TreeSet是采用树结构实现(红黑树算法)。元素是按顺序进行排列，但是add()、remove()以及contains()等方法都是复杂度为O(log (n))的方法。它还提供了一些方法来处理排序的set，如first(), last(), headSet(), tailSet()等等</li>
</ul>
<p><a href="https://leetcode-cn.com/problems/longest-consecutive-sequence/solution/zui-chang-lian-xu-xu-lie-by-leetcode/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/longest-consecutive-sequence/solution/zui-chang-lian-xu-xu-lie-by-leetcode/</a></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title>Feeding Data to your Cluster - Kafka &amp; Flume</title>
    <url>/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- toc -->
<h3 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h3><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579416693703.png" alt="1579416693703"></p>
<h4 id="What-is-streaming"><a href="#What-is-streaming" class="headerlink" title="What is streaming?"></a>What is streaming?</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579417084705.png" alt="1579417084705"></p>
<p>With streaming technologies such as Kafka, you can actually process new data as it’s generated into your cluster, maybe you’re gonna save it into HDFS, maybe you’ll save it into HBase or some other database or maybe you’ll actually process it in real time as it comes in.</p>
<p>Usually when we’re talking about Big Data, there’s a big flow of it coming in all the time and you want to be dealing with it as it comes instead of storing it up and dealing with it in batches. </p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579417930302.png" alt="1579417930302"></p>
<h4 id="Enter-Kafka"><a href="#Enter-Kafka" class="headerlink" title="Enter Kafka"></a>Enter Kafka</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579418299281.png" alt="1579418299281"></p>
<p>The good thing is that Kafka because it stores it, consumers can catch up from where they last left off, so it will maintain the point where each consumer left off and allow them to just pick up whenever they want to. So it can publish data in real time to your consumers, but if your consumer goes off line or just wants to catch up from some point in the past, it can do that too.</p>
<a id="more"></a>
<h4 id="Kafka-architecture"><a href="#Kafka-architecture" class="headerlink" title="Kafka architecture"></a>Kafka architecture</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579419075767.png" alt="1579419075767"></p>
<p>Even though it says app, that doesn’t necessarily mean you’re going to be developing an app in order to use Kafka, often there are ones you can just use off the shelf and Kafka even comes with some built-in that might serve your purposes.</p>
<p>You can make these pretty fancy systems that are very scalable, very fast, that can transform data and store it, and do whatever you want with it really, as it comes in.</p>
<h4 id="How-Kafka-scales"><a href="#How-Kafka-scales" class="headerlink" title="How Kafka scales"></a>How Kafka scales</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579419261062.png" alt="1579419261062"></p>
<h3 id="Let’s-play"><a href="#Let’s-play" class="headerlink" title="Let’s play"></a>Let’s play</h3><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579419425921.png" alt="1579419425921"></p>
<h4 id="Activity-Setting-up-Kafka-and-publishing-some-data"><a href="#Activity-Setting-up-Kafka-and-publishing-some-data" class="headerlink" title="[Activity] Setting up Kafka, and publishing some data"></a>[Activity] Setting up Kafka, and publishing some data</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963832#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963832#overview</a></p>
<p>Kafka depends on ZooKeeper to keep track of what topics exists.</p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579420886266.png" alt="1579420886266"></p>
<p>in the real world, this would be massive floods of data coming in from massive web server fleets and things. It can handle that and publish it scalably and reliably to wherever it needs to go. So that’s really what it’s all about, it’s a scalable and reliable mechanism for publishing and subscribing to massive data streams.</p>
<h4 id="Activity-Publishing-web-logs-with-Kafka"><a href="#Activity-Publishing-web-logs-with-Kafka" class="headerlink" title="[Activity] Publishing web logs with Kafka"></a>[Activity] Publishing web logs with Kafka</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963846#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963846#overview</a></p>
<p>So let’s do something a little bit closer to what you might do in reality. Let’s use a built-in Kafka connector to actually monitor a file and publish new lines on that file to a given Kafka topic that then get written out to some other file somewhere else.</p>
<p>使用的一些Linux语句：</p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579422270057.png" alt="1579422270057"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579422355086.png" alt="1579422355086"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579422381621.png" alt="1579422381621"></p>
<h3 id="Flume"><a href="#Flume" class="headerlink" title="Flume"></a>Flume</h3><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579422490612.png" alt="1579422490612"></p>
<h4 id="What-is-Flume"><a href="#What-is-Flume" class="headerlink" title="What is Flume?"></a>What is Flume?</h4><p>You can really think of Flume as a bonafide part of the Hadoop ecosystem, as opposed to Kafka which is much more general purpose in its design.</p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579423582139.png" alt="1579423582139"></p>
<p>Now you might think to yourself “Why can’t I just directly transfer data across to my HDFS cluster?” Well, you need some sort of a buffer in between these two things.</p>
<h4 id="Flume-Agent"><a href="#Flume-Agent" class="headerlink" title="Flume Agent"></a>Flume Agent</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579423781528.png" alt="1579423781528"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425760102.png" alt="1579425760102"></p>
<p>Flume与Kafka的一个区别：It’s not really like Kafka where Kafka just stores up data indefinitely and people can pull that data in whenever they want to. Kafka does expire data after some amount of time, but with Flume, basically your sink grabs data from Flume and once it’s been grabbed from the channel it gets deleted, so flume does not hang onto your messages or your events any longer than it needs to, as soon as your sync processes it, it throws it away. Kafka is a little bit more easier to set up if you have data going to multiple different places that might be pulling at different rates.</p>
<h4 id="Built-in-Source-Types"><a href="#Built-in-Source-Types" class="headerlink" title="Built-in Source Types"></a>Built-in Source Types</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425301835.png" alt="1579425301835"></p>
<h4 id="Built-in-Sink-Types"><a href="#Built-in-Sink-Types" class="headerlink" title="Built-in Sink Types"></a>Built-in Sink Types</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579424846813.png" alt="1579424846813"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579424947616.png" alt="1579424947616"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425396680.png" alt="1579425396680"></p>
<p>It’s basically a way of smoothing out the traffic between the data coming in from your logs or whatever your source might be and where you’re writing it to.</p>
<h3 id="Let’s-play-1"><a href="#Let’s-play-1" class="headerlink" title="Let’s play"></a>Let’s play</h3><h4 id="Activity-Set-up-Flume-and-publish-logs-with-it"><a href="#Activity-Set-up-Flume-and-publish-logs-with-it" class="headerlink" title="[Activity] Set up Flume and publish logs with it"></a>[Activity] Set up Flume and publish logs with it</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963868#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963868#overview</a></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425190618.png" alt="1579425190618"></p>
<p>All you really need to do to get Flume running is write a configuration file that defines what sources channels and sinks are associated with each agent that you want in your Flume setup.</p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425924768.png" alt="1579425924768"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579427003629.png" alt="1579427003629"></p>
<h4 id="Activity-Set-up-Flume-to-monitor-a-directory-and-store-its-data-in-HDFS"><a href="#Activity-Set-up-Flume-to-monitor-a-directory-and-store-its-data-in-HDFS" class="headerlink" title="[Activity] Set up Flume to monitor a directory and store its data in HDFS"></a>[Activity] Set up Flume to monitor a directory and store its data in HDFS</h4><p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579425361515.png" alt="1579425361515"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579426725240.png" alt="1579426725240"></p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579426873190.png" alt="1579426873190"></p>
<p>What ends up happening is that we get new subdirectories being generated for each 10 minute interval that goes by.</p>
<p><img src="/2020/01/19/Feeding-Data-to-your-Cluster-Kafka/1579427060001.png" alt="1579427060001"></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Kafka</tag>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title>Using non-relational data stores with Hadoop - NoSQL &amp; HBase &amp; MongoDB</title>
    <url>/2020/01/16/Using-non-relational-data-stores-with-Hadoop/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- toc -->
<h3 id="Why-NoSQL"><a href="#Why-NoSQL" class="headerlink" title="Why NoSQL?"></a>Why NoSQL?</h3><p>We’ve talked about integrating Hadoop with SQL solutions - MySQL - RDBMSs, if you will - relational database management systems - and those are very handy for giving you the power of a rich analytical query language like SQL to answer your business questions. But, you know, they do take a little bit of time to execute. So <strong>if you’re doing analytic work, relational databases are awesome. </strong>Even if you’re running a small, like, say, an internal web site or a very small-scale web site, something like MySQL can even vend that data to the outside world pretty well.</p>
<p>BUT let’s imagine you need to take things up to the next level. You’re going to start to run into some limitations with SQL and relational database systems.</p>
<p>Maybe you don’t really need the ability to issue arbitrary queries across your entire dataset. Maybe all you need is just the ability to <strong>very quickly answer a specific question </strong>like “What movie should I recommend for this customer?” or “What web pages has this customer looked at in the past?” </p>
<p>And if you need to do that <strong>at a very large scale very quickly across a massive dataset</strong>, something like MySQL might not cut it. You know, if you’re an Amazon or a Google, you might need something that can even <strong>handle tens of thousands of transactions per second without breaking a sweat. And that’s where NoSQL comes in.</strong></p>
<p>These are alternative database systems that <em>give up</em> a rich query language like SQL <em>for</em> the ability to very quickly and at great scale answer very simple questions. So for systems like that you want something called NoSQL, also known as non-relational databases, or not only SQL - that’s a term that comes up sometimes, too. And <strong>these systems are built to scale horizontally forever, and also built to be very fast and very resilient.</strong></p>
<p>Up first, let’s talk about HBase. HBase is actually built on top of HDFS, so it allows you to have a very fast, very scalable transactional system to query your data that’s stored on a horizontally partitioned HDFS file system. So if you need to expose your massive data that’s sitting on your Hadoop cluster, Hbase can be a great way to expose that data to a web service, to web applications, anything that needs to operate very quickly and at a very high scale.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579161940219.png" alt="1579161940219"></p>
<a id="more"></a>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579162098786.png" alt="1579162098786"></p>
<p>if you think about things like Amazon or Google, people are always buying new things or always searching for new things, new web sites are always coming out, so this data is always just getting bigger and bigger and bigger over time. So that has to live on some sort of a distributed cluster, like a Hadoop cluster. You’re just not going to fit that into a single hard drive on a single database. You need something that’s more horizontally scalable, where you can keep on adding capacity as your data continues to grow over time.</p>
<p>It’s not just about random access to planet-size data - it’s also planet-size access to that data. Imagine you’re running a web site like Amazon, where you need to very quickly retrieve the list of things people ordered, or the things they looked at, or what movies they should be recommended, or on Google - what they searched for in the past. That all has to happen at extremely large scale. Tens of thousands of people per second might be hitting your service to actually retrieve this information in real time.</p>
<p>Again, a single Oracle database or MySQL database is not gonna cut it, when you’re talking about that kind of transaction rates on that large of a data set.</p>
<p>过去没有NoSQL, Hadoop时，采用的方法：</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579162897675.png" alt="1579162897675"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579163190865.png" alt="1579163190865"></p>
<p>All you need is an API that says, “given this customer ID, give me back this list of information”, or “given</p>
<p>this item identifier, give me back this information about this item”. So, more often than not, all you really need at runtime is a simple API that allows you to get information for a given key or put information into a given key.</p>
<p>These are basically, key-value data stores at a high level. And if that’s all you need, then you don’t need a big fancy relational database. All you need is a more scalable system that can be very easily horizontally partitioned for given key ranges, that just answers the question: “Give me this stuff for this key”.</p>
<p>And you can always do both, too. For example, you can have a Hadoop cluster that you’re running Hive on, or Pig, or Spark, to actually answer the more complex questions that you have, but for the things you are doing at a very high scale, at very high transaction rates, you can bolt on a NoSQL database to actually handle that part of the problem. It’s not a question of one or the other - it’s about having the right tools in place for the right jobs.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579163943922.png" alt="1579163943922"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579165798303.png" alt="1579165798303"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579165874566.png" alt="1579165874566"></p>
<h3 id="What-is-HBase"><a href="#What-is-HBase" class="headerlink" title="What is HBase"></a>What is HBase</h3><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579166108894.png" alt="1579166108894"></p>
<p>HBase is built on top of HDFS. So if you’re storing massive datasets on an HDFS file system, HBase can be used to actually vend that to the outside world at a very large scale.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579170600274.png" alt="1579170600274"></p>
<p>Just like every other NoSQL solution, it <strong>does not have a query language, but it does have an API</strong> that can very quickly answer the question “what are the values for this key?” or “store this value for this key”.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579170812851.png" alt="1579170812851"></p>
<h4 id="CRUD"><a href="#CRUD" class="headerlink" title="CRUD"></a>CRUD</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579171017155.png" alt="1579171017155"></p>
<h4 id="HBase-architecture"><a href="#HBase-architecture" class="headerlink" title="HBase architecture"></a>HBase architecture</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579172096734.png" alt="1579172096734"></p>
<p>Basically, it’s split up into different region servers. This is the core of HBase itself. When we talk about regions, we’re talking about ranges of keys, so it’s just like sharding or range partitioning in more traditional database systems. But the magic of it all is that it can automatically adapt, so, as your data grows, it can automatically repartition things, and if you add more servers to the mix, it can automatically deal with that at runtime.</p>
<p>So there’s a very complex mechanism that involves write-ahead commit logs and, merging things together over time asynchronously. But you don’t have to worry about those details - HBase does it for you. All you need to know is that it can automatically distribute your data amongst a fleet of region servers, so an entire cluster, if you will.</p>
<p>Now, when you have an application that’s actually talking to HBase - a web application or a web server - it’s not actually going to talk to these master nodes directly, it’s going to be talking to region servers directly.</p>
<h4 id="HBase-data-model"><a href="#HBase-data-model" class="headerlink" title="HBase data model"></a>HBase data model</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579172733321.png" alt="1579172733321"></p>
<p>What’s different about HBase is that it has the concept of column families. So you don’t define a fixed set of columns for each row in your database. Instead you define column families, and each column family can contain a very large number of individual columns.</p>
<p>This comes in handy where you have cases of sparse data.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579174693898.png" alt="1579174693898"></p>
<h4 id="Ways-to-access-HBase"><a href="#Ways-to-access-HBase" class="headerlink" title="Ways to access HBase"></a>Ways to access HBase</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579175017006.png" alt="1579175017006"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579174915921.png" alt="1579174915921"></p>
<h3 id="Activity-Import-movie-ratings-into-HBase"><a href="#Activity-Import-movie-ratings-into-HBase" class="headerlink" title="[Activity] Import movie ratings into HBase"></a>[Activity] Import movie ratings into HBase</h3><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579178657253.png" alt="1579178657253"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579179141807.png" alt="1579179141807"></p>
<p>Now we’re going to run a REST service on top of HBase. It’s just a service that you can query through</p>
<p>HTTP requests, and we’re going to write a client that actually queries that service to store and retrieve</p>
<p>data through the REST service.</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963426#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963426#overview</a></p>
<p>返回结果：</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579179897880.png" alt="1579179897880"></p>
<h3 id="MongoDB-Overview"><a href="#MongoDB-Overview" class="headerlink" title="MongoDB Overview"></a>MongoDB Overview</h3><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579180346655.png" alt="1579180346655"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579180457304.png" alt="1579180457304"></p>
<p>CAP theorem: <strong>MongoDB chooses consistency and partition-tolerance.</strong></p>
<p>Since it dose have to deal with big data, partition-tolerance is something is has to do, and MongoDB chooses consistency over availability.</p>
<p>So MongoDB has a single master, a single primary database that you have to talk to all the time to ensure consistency. But if that master goes down, it will result in a period of unavailability, while a new primary database is put into place.</p>
<h4 id="Document-based-data-model"><a href="#Document-based-data-model" class="headerlink" title="Document-based data model"></a>Document-based data model</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579235814767.png" alt="1579235814767"></p>
<p>The big thing that’s different about MongoDB is that you can stick pretty much anything you want into MongoDB - basically, any JSON blob of data you can shove into a document in MongoDB. It doesn’t have to be structured, you don’t have to have the same schema across each document. You can put whatever you want in there.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579236174990.png" alt="1579236174990"></p>
<p>You still need to think about what the queries are you going to be performing on this database and design your database schema accordingly. Think about what indices you might need for fast lookups for the queries you’re going to do. At the end of the day, it’s still a NoSQL database, so you cannot do joins efficiently, so you want to make sure your schema is denormalized as much as you can. </p>
<h4 id="MongoDB-terminology"><a href="#MongoDB-terminology" class="headerlink" title="MongoDB terminology"></a>MongoDB terminology</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579238197250.png" alt="1579238197250"></p>
<p>在MongoDB中我们讨论 Databse, Collection, 和 Document, 而不是 Database, Table, 和 Row.</p>
<p>A MongoDB database contains collections, and a collection contains a collection of documents.</p>
<p>And the main restriction here is simply that you cannot move data between collections across different databases, so if you do need to reference data between different collections, they do need to be within the same database.</p>
<h4 id="Replication-Sets"><a href="#Replication-Sets" class="headerlink" title="Replication Sets"></a>Replication Sets</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579250924977.png" alt="1579250924977"></p>
<p>MongoDB has a single-master architecture, the idea being that we want to have consistency over availability, but you can have these secondary databases that maintain copies over time from your primary database, so, as writes happen to your primary database, those writes get replicated through an operation log to any secondary nodes that you might have attached to it.</p>
<p>The way that replication chain works is kind of arbitrary. It actually just tries to figure out which server can it talk to most quickly.</p>
<p>And I want to stress again that we haven’t even talked about big data yet. What we’re talking about here in replica sets is just having a single monolithic MongoDB server, where all of the data sits on that single server, and we’re replicating that data to backup servers.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579254081608.png" alt="1579254081608"></p>
<h4 id="Sharding-How-MongoDB-handles-big-data"><a href="#Sharding-How-MongoDB-handles-big-data" class="headerlink" title="Sharding (How MongoDB handles big data)"></a>Sharding (How MongoDB handles big data)</h4><p>For actually scaling out data across more than one server with MongoDB, we need to set up something called sharding.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579254450944.png" alt="1579254450944"></p>
<p>The way sharding works is that we actually have multiple replica sets, where each replica set is responsible for some range of values on some indexed value in my database. So in order to get sharding to work, it requires that you set up an index on some unique value on your collection, and that index is used to actually balance the load of information among multiple replica sets, and then on each application server, whatever you’re using to talk to MongoDB, you’ll run a process called “mongos”, and “mongos” talks to exactly three configuration servers that you have running somewhere that knows about how things are partitioned and then uses that to figure out which replica set do I talk to to get the information that I want.</p>
<p>“mongos” is running something called a balancer in the background. So, over time, if it finds that it actually doesn’t have an even distribution of values in whatever field you’re partitioning on, it can rebalance things across your replica sets in real time over time.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579254879640.png" alt="1579254879640"></p>
<h4 id="Neat-Things-about-MongoDB"><a href="#Neat-Things-about-MongoDB" class="headerlink" title="Neat Things about MongoDB"></a>Neat Things about MongoDB</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579255204023.png" alt="1579255204023"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579255278039.png" alt="1579255278039"></p>
<h3 id="Activity-Install-MongoDB-and-integrate-Spark-with-MongoDB"><a href="#Activity-Install-MongoDB-and-integrate-Spark-with-MongoDB" class="headerlink" title="[Activity] Install MongoDB and integrate Spark with MongoDB"></a>[Activity] Install MongoDB and integrate Spark with MongoDB</h3><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963458#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963458#overview</a></p>
<p>We’re going to read in the “u.user” data file from the MovieLens dataset, convert that into a dataframe in Spark and then write that dataframe out to MongoDB, and then we’re going to read it back and do a little query on it.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579328591006.png" alt="1579328591006"></p>
<p>What we’re not doing is loading this data into Spark locally and then running a query on it - what it’s</p>
<p>actually doing is figuring out how do I translate this SQL query into a MongoDB query and actually</p>
<p>execute that on MongoDB and return the results back from MongoDB.</p>
<h3 id="Activity-Using-the-MongoDB-Shell"><a href="#Activity-Using-the-MongoDB-Shell" class="headerlink" title="[Activity] Using the MongoDB Shell"></a>[Activity] Using the MongoDB Shell</h3><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963462#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963462#overview</a></p>
<p>启动MongoDB Shell:</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579406411404.png" alt="1579406411404"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579331041897.png" alt="1579331041897"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579331085161.png" alt="1579331085161"></p>
<p>注意一点：we never set up an index. So when I said, “go find user ID 100”, it couldn’t do that very efficiently, and I actually had to do a full table scan, because MongoDB doesn’t automatically index things for you.</p>
<p>I can do <code>db.users.explain().find( {user_id: 100} )</code> , and that will do an explain on the query, telling you what it will do under the hood to actually execute the command “find” on the expression “{user_id: 100}”. And you can see here all it’s doing is a scan on the “winningPlan”, looking for user ID 100 going forward. So it’s kind of just starts at the beginning of the entire database and chugs through it forward one record, one document at a time, until it stumbles across user ID 100, so, obviously, not the most efficient way of doing a lookup.</p>
<p>So to fix that, let’s make an index. To do that, I can say, <code>db.users.createIndex( {user_id: 1} )</code> -and what this means is I want to create an index on the “user_id” field and the “1” just means it’s ascending. So that’s going to give you back a sort order that’s in ascending order, if you want to optimize sorts as well.</p>
<p>Once it has its index on the “user_id” field, it can much more quickly look up where to find a given document for that user ID.</p>
<p><strong>MongoDB does not set up an index for you on your primary key. You have to do it by hand, and if you forget to do it, your database is going to be horribly inefficient when you do lookups.</strong></p>
<p>Let’s aggregate all of the users by occupation and figure out the average age for each occupation.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579405319292.png" alt="1579405319292"></p>
<p>In MongoDB things that start with a dollar sign mean that this has some sort of a special meaning to MongoDB, so “$group” is a command that MongoDB recognizes.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579405698972.png" alt="1579405698972"></p>
<p>How many users are in our database?</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579405757587.png" alt="1579405757587"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579406239652.png" alt="1579406239652"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579406303820.png" alt="1579406303820"></p>
<h3 id="Choosing-a-database-technology"><a href="#Choosing-a-database-technology" class="headerlink" title="Choosing a database technology"></a>Choosing a database technology</h3><h4 id="Integration-considerations"><a href="#Integration-considerations" class="headerlink" title="Integration considerations"></a>Integration considerations</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579406708880.png" alt="1579406708880"></p>
<p>Different technologies have different connectors for different other technologies. </p>
<p>例如, if you have a big analytics job that’s currently running in Apache Spark, then you probably want to limit yourself to external databases that can connect easily to Apache Spark.</p>
<p>又例如, Maybe you have some front-end system that actually depends on having a SQL interface to a back-end database, and you’re thinking about moving from a monolithic relational database to a distributed non-relational database. In that case, it might make life a lot easier if the non-relational database you’re moving to offers some sort of SQL-like interface that can be easily migrated to from your front-end application.</p>
<h4 id="Scaling-requirements"><a href="#Scaling-requirements" class="headerlink" title="Scaling requirements"></a>Scaling requirements</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579406971416.png" alt="1579406971416"></p>
<p>How much data are you really talking about? Is it going to grow unbounded over time?</p>
<p>If so, then you need some sort of a database technology that is not limited to the data that you can store on one PC, right? You’re going to have to look at something like Cassandra or MongoDB or HBase, where you can actually distribute the storage of your data across an entire cluster and scale horizontally instead of vertically.</p>
<p>Think, too, about your transaction rates: how many requests do you intend to get per second? You know, if we’re talking about thousands, then, again, a single database server is not going to cut it. You need something that’s distributed, where you can spread out the load of those transactions more evenly.</p>
<h4 id="Support-considerations"><a href="#Support-considerations" class="headerlink" title="Support considerations"></a>Support considerations</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579407277634.png" alt="1579407277634"></p>
<p>So do you actually have the in-house expertise to spin up this new technology and actually configure it properly? It’s going to be harder than you think, especially if you’re using this in the real world or in any sort of situation, where you have personally identifiable information in the mix from your end users. In that case, you need to make sure you’re thinking very deeply about the <strong>security</strong> of your system, and the truth is most of the NoSQL databases we talked about, if you just configure them with their default settings, there’ll be no security at all. Anybody at all can connect to these things and retrieve data or write data into them, so you need to make sure you have someone available who knows what they’re doing for setting this up in a secure manner.</p>
<p>That might mean if you are in a big organization that has these experts in house, that’s great, don’t even think about it - but if you’re in a smaller organization, you might want to consider: does this technology I’m choosing actually offer professional paid support that will help guide me through these setup decisions and the initial administration of my server over time? Or are there administrators that I can outsource the ongoing administration to over time? So in this case, you know, a more corporate solution like MongoDB might actually be a good choice, because, you know, they have paid support, and even for the more open-source Apache projects, there are companies out there that do offer paid professional support for them as well, so do your homework and try to figure out: can I really do this on my own, and if not, what resources are out there in the marketplace to help me? </p>
<h4 id="CAP-considerations"><a href="#CAP-considerations" class="headerlink" title="CAP considerations"></a>CAP considerations</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579407517312.png" alt="1579407517312"></p>
<p>So again, the way to think about this is when you’re thinking about the scale of your requirements, do you need to have partition tolerance? Do you have sufficient scale, where you know you’re going to eventually need more than one server serving up the data just for handling the transactions you’re talking about, and also for the scale of the data that you’re talking about? If so, partition tolerance is non-negotiable, you need that one, and your only real choice in that case is consistency or availability.</p>
<p>And that will determine which one of these sides of the triangle you might want to lean toward. So the type of application will determine what you want there. Is it actually OK if your system goes down for a few seconds or a few minutes? If not, then availability’s going to be your prime concern. Is it OK if you have eventual consistency, where, if you write something, people might get the old value back on subsequent reads for a few seconds? If so, who cares about consistency, right? Again, I would take availability instead. But if you’re dealing with something that’s dealing with real transactional information like, you know, stock transactions or some sort of financial transactions, you might value consistency above all else, and in that case, you want to really focus on that corner of the triangle.</p>
<blockquote>
<p>注：Now, I should point out that the CAP theorem isn’t really a hard-and-fast rule. The reality is these tradeoffs have become a little bit more loose in recent years. For example, consider Cassandra: is it really trading off consistency for availability and partition tolerance? Well, you can actually configure the amount of consistency that you want from Cassandra - you can tell it, “I want to make sure I get back the same result from every replica of this data before I actually consider that transaction to be final”, and if you’re running it in that mode, you’re kind of getting all three.</p>
<p>The lines are getting blurred between these different tradeoffs over time. So the honest truth is any of these technologies can be made to work in pretty much any situation, if you try hard enough. It’s really a question of choosing the technology that’s best suited to the tradeoffs that you want to make.</p>
</blockquote>
<h4 id="Simplicity"><a href="#Simplicity" class="headerlink" title="Simplicity"></a>Simplicity</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579408720595.png" alt="1579408720595"></p>
<p>If you don’t need to set up a highly complex NoSQL cluster and something that needs a lot of maintenance, like, you know, MongoDB or HBase, where you have all these external servers that maintain its configuration, don’t do it, if you don’t need to. </p>
<p><strong>Think about the minimum requirements that you need for your system and keep it as simple as possible.</strong></p>
<p>If you don’t need to deal with massive scale, don’t deploy a NoSQL database, if you don’t already have one, right? Just use a MySQL instance somewhere, it will be fine.</p>
<p>So keep it simple, do not deploy a whole new system that does not have good expertise within your organization, unless you really need to. Simple technologies and simple architectures are going to be a lot easier to maintain.</p>
<h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579408982980.png" alt="1579408982980"></p>
<p>Go with MySQL.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579409021695.png" alt="1579409021695"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579409163590.png" alt="1579409163590"></p>
<p>Well, first of all, step back and ask yourself, “do I even have enough scale here to warrant a non-relational database at all? Why am I even thinking about this question - right? - if all I’m doing is analytics, that’s what Hadoop is for, that’s what Spark is for.”</p>
<p>如果只是需要分析：You can import this data into HDFS on your cluster and analyze it offline. </p>
<p>如果是想要很快的得到结果：If we’re not talking about high transaction rates here, where we care about very quickly getting the answer to a specific query over and over and over again, thousands of times per second, - that’s the sort of a problem that NoSQL databases are meant for.</p>
<p>You could solve this problem just by importing your log data into HDFS, but it doesn’t involve external databases at all. Once that data is residing on my HDFS cluster, I can write a Spark job that mines that data, assigns the appropriate structure to it, and it can actually run machine learning algorithms on it even using Spark’s MLlib.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579409497341.png" alt="1579409497341"></p>
<p>Just use your Hadoop cluster and the capabilities that the Hadoop ecosystem gives you, without resorting to outside database technologies.</p>
<p>There’s no need here to set up an external database at all necessarily, unless you need to vend this data to a very large audience externally. So if you were actually building Google Analytics for real, where you had, you know, millions of people that wanted to hit it and get answers from it at once, then, sure, you’d want to expose that through some sort of an external database system that’s integrated with your cluster.</p>
<p>But if you’re just using this internally for analytic use, there’s no need to even talk about things like NoSQL or Mongo or Cassandra or something like that.</p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579409662825.png" alt="1579409662825"></p>
<p>Consistency:  it’s OK if, for a few seconds after new recommendations have been computed for a user, that you’re still getting the old recommendations.</p>
<p>So, thinking back to the CAP theorem, we care about availability, we care about partition tolerance very much, the thing that we’re willing to give up, maybe, is consistency.</p>
<p>In that case, Cassandra might be a good choice. </p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579409873125.png" alt="1579409873125"></p>
<p><img src="/2020/01/16/Using-non-relational-data-stores-with-Hadoop/1579410043297.png" alt="1579410043297"></p>
<p>We posed this scenario, where you’re building a massive stock trading system, where maybe you want to run a big analytics job on Hadoop or Spark in the background, but you still need to have some sort of a front-end interface to the actual stock trades themselves, so what would be a good choice of a database in this situation?</p>
<p>选择 MongoDB 或者 HBase 都可以。对于 MongoDB, there is a big company behind it that makes its living selling support for it. 另一方面，Now, there are other companies out there that do specialize in offering support for things like HBase or other Apache projects, so don’t make that a hard decision there.</p>
]]></content>
      <tags>
        <tag>Hadoop</tag>
        <tag>HBase</tag>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Using relational data stores with Hadoop —— Hive &amp; Sqoop</title>
    <url>/2020/01/15/Using-relational-data-stores-with-Hadoop-%E2%80%94%E2%80%94-Hive/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- toc -->
<h2 id="HIVE"><a href="#HIVE" class="headerlink" title="HIVE"></a>HIVE</h2><p>We can actually make your Hadoop cluster look like a relational database through a technology called <strong>Hive</strong>. And there’s also ways of integrating a new Hadoop cluster with a MySQL database.</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579064046135.png" alt="1579064046135"></p>
<h3 id="What-is-Hive"><a href="#What-is-Hive" class="headerlink" title="What is Hive?"></a>What is Hive?</h3><p>It lets you write standard SQL queries that look just like you’d be using them on MySQL, but actually execute them on data that’s stored across your entire cluster, maybe on an HDFS cluster as well.</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579064255091.png" alt="1579064255091"></p>
<h4 id="Why-Hive"><a href="#Why-Hive" class="headerlink" title="Why Hive"></a>Why Hive</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579082214734.png" alt="1579082214734"></p>
<h4 id="Why-not-Hive"><a href="#Why-not-Hive" class="headerlink" title="Why not Hive"></a>Why not Hive</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579083363568.png" alt="1579083363568"></p>
<p>It’s not really meant for being hit with tons of queries all at once, from a website or something like that. That’s where you use something like HBase instead.</p>
<p>Hive is a bunch of smoke and mirrors to make it look like a database, so you can issue SQL queries on it, but it isn’t really.</p>
<a id="more"></a>
<h4 id="HiveQL"><a href="#HiveQL" class="headerlink" title="HiveQL"></a>HiveQL</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579084456353.png" alt="1579084456353"></p>
<h3 id="Activity-Use-Hive-to-find-the-most-popular-movie"><a href="#Activity-Use-Hive-to-find-the-most-popular-movie" class="headerlink" title="[Activity] Use Hive to find the most popular movie"></a>[Activity] Use Hive to find the most popular movie</h3><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963170#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963170#overview</a></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579085359675.png" alt="1579085359675"></p>
<p>或写成：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT title, COUNT(movieID) AS ratingCount</span><br><span class="line">FROM ratings JOIN names ON ratings.movieID = names.movieID</span><br><span class="line">GROUP BY ratings.movieID</span><br><span class="line">ORDER BY ratingCount DESC;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579085980578.png" alt="1579085980578"></p>
<p>We used views in Hive to split up a more complicated query into something more readable and more manageable.</p>
<p>执行时会花一点时间，remember this isn’t really a relational database, so things like joins are kind of painful when you’re not dealing with normalized data.</p>
<p>执行后会发现新创建的view出现在了Database里：</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579085692727.png" alt="1579085692727"></p>
<p>Your views are persistent, they’re stored to disk.</p>
<p>若此时再执行会出错，可写成： <code>CREATE VIEW IF NOT EXISTS topMovieIDs ...</code></p>
<p>Just to clean up our mess and not leave that around: <code>DROP VIEW topMovieIDs;</code></p>
<h3 id="How-Hive-works"><a href="#How-Hive-works" class="headerlink" title="How Hive works?"></a>How Hive works?</h3><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579086892876.png" alt="1579086892876"></p>
<h4 id="Schema-on-read"><a href="#Schema-on-read" class="headerlink" title="Schema on read"></a>Schema on read</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579087836551.png" alt="1579087836551"></p>
<p>One of the basic concepts pf Hive is something called <em>schema on read</em>, and this is what separates it from a more traditional database. With a real relational database, it uses something called <em>schema on write</em> where you define the schema of your database before you load the data into it, and it’s actually enforced at the time that you write the data to disk. </p>
<p>Hive flips that on its head. It takes unstructured data and just sort of applies a schema to it as it’s being read instead.</p>
<p>So, Hive isn’t creating some structured relational database under the hood, that would be very inefficient, it’s just taking the existing data that you have on your cluster and imparting a schema to it when it’s read in.</p>
<h4 id="Where-is-the-data-内部表与外部表"><a href="#Where-is-the-data-内部表与外部表" class="headerlink" title="Where is the data? (内部表与外部表)"></a>Where is the data? (内部表与外部表)</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579089471741.png" alt="1579089471741"></p>
<p>对于 managed table, if you do a “DROP TABLE” command from Hive, then that data is gone.</p>
<p>But sometimes you want to share that data with other systems that are outside of Hive. So that’s where external tables come in. “CREATE EXTERNAL TABLE” with “Location” says, “I’m going to use Hive on this data here, but I’m not going to own it anymore”. So I drop this table, it’s going to drop the metadata, 但是原数据不会被删除。</p>
<h4 id="Partitioning-分区"><a href="#Partitioning-分区" class="headerlink" title="Partitioning 分区"></a>Partitioning 分区</h4><p>If you do have a massive dataset and your queries tend to be on a specific partition of that data, partitioning in Hive can be a very important optimization. </p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579096514448.png" alt="1579096514448"></p>
<p>We wouldn’t have to scan over the entire customer database, we could just scan over the actual files that are specific to the country that I’m interested in.</p>
<h4 id="Ways-to-use-Hive"><a href="#Ways-to-use-Hive" class="headerlink" title="Ways to use Hive"></a>Ways to use Hive</h4><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579096909189.png" alt="1579096909189"></p>
<h3 id="Activity-Use-Hive-to-find-the-movie-with-the-highest-average-rating"><a href="#Activity-Use-Hive-to-find-the-movie-with-the-highest-average-rating" class="headerlink" title="[Activity] Use Hive to find the movie with the highest average rating"></a>[Activity] Use Hive to find the movie with the highest average rating</h3><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579149719149.png" alt="1579149719149"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579097528758.png" alt="1579097528758"></p>
<p>或写成：？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT title, AVG(rating) as avgRating</span><br><span class="line">FROM ratings JOIN names on ratings.movieID = names.movieID</span><br><span class="line">GROUP BY ratings.movieID</span><br><span class="line">HAVING COUNT(ratings.movieID)  &gt; 10</span><br><span class="line">ORDER BY avgRating DESC;</span><br></pre></td></tr></table></figure>
<h2 id="Sqoop"><a href="#Sqoop" class="headerlink" title="Sqoop"></a>Sqoop</h2><h3 id="Integrating-MySQL-with-Hadoop"><a href="#Integrating-MySQL-with-Hadoop" class="headerlink" title="Integrating MySQL with Hadoop"></a>Integrating MySQL with Hadoop</h3><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579149997458.png" alt="1579149997458"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579150738331.png" alt="1579150738331"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579150774304.png" alt="1579150774304"></p>
<h3 id="Import-Export-data-MySQL-lt-gt-HDFS-Hadoop"><a href="#Import-Export-data-MySQL-lt-gt-HDFS-Hadoop" class="headerlink" title="Import/Export data (MySQL &lt;-&gt; HDFS/Hadoop)"></a>Import/Export data (MySQL &lt;-&gt; HDFS/Hadoop)</h3><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579151204058.png" alt="1579151204058"></p>
<p>Export data from your database into Hadoop:</p>
<ol>
<li>kick off a bunch of mappers (只有mappers, all we’re doing is moving data and transforming it from one place to another, there’s no real reduce going on here.)</li>
<li>all these mappers are going to talk to your HDFS cluster on your Hadoop cluster and populate a big old table on HDFS, which is a giant text file (例如逗号分隔的数据), and from there, you can use tools like Hive or Pig on it.</li>
</ol>
<p>REMEMBER, the power of HDFS is that file might be distributed across many different hosts, blocks, and also stored redundantly. We’ve done more than just dump our database to a file here - we’ve dumped it into HDFS, which opens up a whole world of possibilities for analyzing it in a robust, scalable and a manner that can be resilient to failure.</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579156422401.png" alt="1579156422401"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579157592193.png" alt="1579157592193"></p>
<p>与导入HDFS一样，导入Hive同样会kick off a MapReduce job.</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579154105803.png" alt="1579154105803"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579159508995.png" alt="1579159508995"></p>
<h3 id="Play-with-MySQL-and-Sqoop"><a href="#Play-with-MySQL-and-Sqoop" class="headerlink" title="Play with MySQL and Sqoop"></a>Play with MySQL and Sqoop</h3><p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579154231118.png" alt="1579154231118"></p>
<h4 id="Activity-Install-MySQL-and-import-our-movie-data"><a href="#Activity-Install-MySQL-and-import-our-movie-data" class="headerlink" title="[Activity] Install MySQL and import our movie data"></a>[Activity] Install MySQL and import our movie data</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963236#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963236#overview</a></p>
<h4 id="Activity-Use-Sqoop-to-import-data-from-MySQL-to-HDFS-Hive"><a href="#Activity-Use-Sqoop-to-import-data-from-MySQL-to-HDFS-Hive" class="headerlink" title="[Activity] Use Sqoop to import data from MySQL to HDFS/Hive"></a>[Activity] Use Sqoop to import data from MySQL to HDFS/Hive</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963266#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963266#overview</a></p>
<p>由 MySQL 导入 HDFS 后：</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579156905400.png" alt="1579156905400"></p>
<p>由 MySQL 导入Hive后：</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579157822360.png" alt="1579157822360"></p>
<blockquote>
<p>注：These sorts of tools that we’re using with Hadoop are really intended for big datasets, so there’s a lot of overhead for doing what’s actually a pretty simple operation. It doesn’t make sense if you’re using small datasets. 如果数据集很小，在一个host就能装下，没必要用这些工具，用MySQL就足够了。</p>
</blockquote>
<h4 id="Activity-Use-Sqoop-tp-export-data-from-Hadoop-to-MySQL"><a href="#Activity-Use-Sqoop-tp-export-data-from-Hadoop-to-MySQL" class="headerlink" title="[Activity] Use Sqoop tp export data from Hadoop to MySQL"></a>[Activity] Use Sqoop tp export data from Hadoop to MySQL</h4><p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963272#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963272#overview</a></p>
<ol>
<li>首先需要知道 where the data in Hive actually resides. REMEMBER, Hive is just a schema-on-read sort of deal. The actual data itself if just stored as a plain old text somewhere, and all Hive is doing is imparting structure to it when it’s being read. </li>
</ol>
<p>On Hortonworks:</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579158771230.png" alt="1579158771230"></p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579158823550.png" alt="1579158823550"></p>
<p>不是靠逗号分隔的，Hive actually uses low ASCII values, like 1 and 2 and 3, to delimit its data. </p>
<ol>
<li>在导入前，MySQL中要先有 target table</li>
</ol>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579159104056.png" alt="1579159104056"></p>
<p>3.</p>
<p><img src="/2020/01/15/Using-relational-data-stores-with-Hadoop-——-Hive/1579159601163.png" alt="1579159601163"></p>
<p>和import一样，export也会kick off a bunch of mappers using MapReduce.</p>
<blockquote>
<p>什么时候需要从Hive导入MySQL: From a practical standpoint, if you need to expose your data to a database that’s more well-suited for OLTP. Sometimes you’ll be doing some huge operation using Hive or some other tool on your cluster, but the output of that operation might be small enough to fit on a single database.</p>
</blockquote>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>We talked about making your Hadoop cluster look like a MySQL database or a SQL database, using Hive.</p>
<p>And we also talked about using your Hadoop cluster with a real MySQL database as well. Kind of two different directions there.</p>
<p>Next, let’s talk about <strong>NoSQL</strong>. Sometimes you actually want to expose your data in a way that’s more amenable to <strong>real-time queries</strong>, and there’s a bunch of ways to do that and also ways of integrating Hadoop with systems that are more real-time in nature.</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
        <tag>Sqoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop Course Overview</title>
    <url>/2020/01/14/Hadoop-Course-Overview/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>课程：</p>
<p><a href="https://www.udemy.com/course-dashboard-redirect/?course_id=996228" target="_blank" rel="noopener"><img src="https://i.udemycdn.com/course/240x135/996228_af5f_3.jpg" alt="The Ultimate Hands-On Hadoop - Tame your Big Data!"></a><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/" target="_blank" rel="noopener"><strong>The Ultimate Hands-On Hadoop - Tame your Big Data!</strong></a></p>
<p><a href="https://sundog-education.com/hadoop-materials/" target="_blank" rel="noopener">Course Materials</a></p>
<h4 id="What-you’ll-learn"><a href="#What-you’ll-learn" class="headerlink" title="What you’ll learn"></a>What you’ll learn</h4><ul>
<li>Design distributed systems that manage “big data” using Hadoop and related technologies.</li>
<li>Use HDFS and MapReduce for storing and analyzing data at scale.</li>
<li>Use Pig and Spark to create scripts to process data on a Hadoop cluster in more complex ways.</li>
<li>Analyze relational data using Hive and MySQL</li>
<li>Analyze non-relational data using HBase, Cassandra, and MongoDB</li>
<li>Query data interactively with Drill, Phoenix, and Presto</li>
<li>Choose an appropriate data storage technology for your application</li>
<li>Understand how Hadoop clusters are managed by YARN, Tez, Mesos, Zookeeper, Zeppelin, Hue, and Oozie.</li>
<li>Publish data to your Hadoop cluster using Kafka, Sqoop, and Flume</li>
<li>Consume streaming data using Spark Streaming, Flink, and Storm</li>
</ul>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark</title>
    <url>/2020/01/14/Spark/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- toc -->
<h3 id="Introduction-to-Spark"><a href="#Introduction-to-Spark" class="headerlink" title="Introduction to Spark"></a>Introduction to Spark</h3><p><img src="/2020/01/14/Spark/1578976053911.png" alt="1578976053911"></p>
<p><img src="/2020/01/14/Spark/1578976261212.png" alt="1578976261212"></p>
<p>There’s a lot of cool features built on top of Spark, like things for machine learning and graph analysis and streaming data.</p>
<h4 id="Scalable"><a href="#Scalable" class="headerlink" title="Scalable"></a>Scalable</h4><p><img src="/2020/01/14/Spark/捕获.JPG" alt="捕获"></p>
<h4 id="Fast"><a href="#Fast" class="headerlink" title="Fast"></a>Fast</h4><p><img src="/2020/01/14/Spark/1578977218206.png" alt="1578977218206"></p>
<p>Spark除了比MapReduce更快以外，还有一个优势：MapReduce is very limited in what it can do. You have to think about things in terms of mappers and reducers, whereas Spark provides a framework for removing that level of though from you, you can just think more about your end results and program toward that and think less about how to actual distribute it across the cluster.</p>
<a id="more"></a>
<h4 id="Hot"><a href="#Hot" class="headerlink" title="Hot"></a>Hot</h4><p><img src="/2020/01/14/Spark/1578977501017.png" alt="1578977501017"></p>
<h4 id="Not-that-hard-可使用的语言，RDD"><a href="#Not-that-hard-可使用的语言，RDD" class="headerlink" title="Not that hard (可使用的语言，RDD)"></a>Not that hard (可使用的语言，RDD)</h4><p><img src="/2020/01/14/Spark/1578977890605.png" alt="1578977890605"></p>
<p>A few lines of code can actually kick off some very complex analysis on a cluster.</p>
<p>Spark 2.0 which came out in 2006, they’ve built on top of RDDs to produce something called a data set. That’s a little bit more of a SQL focused take on an RDD, but at the end of the day, it’s still built around the RDD.</p>
<h4 id="Components-of-Spark"><a href="#Components-of-Spark" class="headerlink" title="Components of Spark"></a>Components of Spark</h4><p><img src="/2020/01/14/Spark/1578978133377.png" alt="1578978133377"></p>
<p>Spark has a lot of depth to it, so while you could just program at the RDD level within <strong>Spark Core</strong>, there are also libraries built on top of Spark that are part of Spark itself.</p>
<p><strong>Spark Streaming</strong>: Instead of doing batch processing of data, you can actually input data in real time. Data can be ingested as it’s being produced, and then Spark can analyze it across some window of time, and you can output the results of that analysis to a database or some NoSQL data store, all within a few lines of code.</p>
<p><strong>Spark SQL</strong>: Very hot area right now. It’s basically a SQL interface to Spark. You can write SQL queries against your data using Spark SQL. It allows us to do more optimizations beyond the directed acyclic graph, because it can do SQL optimizations on the queries that you’re actually running.</p>
<p><strong>MLLib</strong>: An entire library of machine learning and data mining tools that you can run on a data set that’s in Spark.</p>
<p><strong>GraphX</strong>: That’s the graph in terms of graph theory. Imagine for example, you have a social network graph, and you want to analyze the properties of that graph, and see who’s connected to who and what way, and what are the shortest path and things like that, GraphX provides a very extensible way of doing that.</p>
<p>SO, very rich ecosystem surrounding Spark that lets you do a wide variety of tasks on big data across the cluster.</p>
<h4 id="这门课将使用的语言及Scala"><a href="#这门课将使用的语言及Scala" class="headerlink" title="这门课将使用的语言及Scala"></a>这门课将使用的语言及Scala</h4><p><img src="/2020/01/14/Spark/1578979417251.png" alt="1578979417251"></p>
<p>If you do want to end up using Spark in production in the real world, Python is OK to start with, but you probably want to move to Scala. </p>
<p><img src="/2020/01/14/Spark/1578979634184.png" alt="1578979634184"></p>
<p>It’s not very hard to move from Python to Scala. </p>
<h3 id="RDD-The-Resilient-Distributed-Dataset"><a href="#RDD-The-Resilient-Distributed-Dataset" class="headerlink" title="RDD (The Resilient Distributed Dataset)"></a>RDD (The Resilient Distributed Dataset)</h3><p><img src="/2020/01/14/Spark/1578989468387.png" alt="1578989468387"></p>
<h4 id="What-is-RDD"><a href="#What-is-RDD" class="headerlink" title="What is RDD?"></a>What is RDD?</h4><p><img src="/2020/01/14/Spark/1578989673088.png" alt="1578989673088"></p>
<p>It’s an abstraction across all the nastiness that happens under the hood to actually make sure your job is evenly distributed across your cluster that it can handle failures in a resilient manner, and at the end of the day, it just looks like a dataset to you.</p>
<p>From a programming standpoint, an RDD is just a dataset to you. But under the hood, it’s resilient and distributed and you don’t have to think about that very much.</p>
<h4 id="How-do-you-make-RDD"><a href="#How-do-you-make-RDD" class="headerlink" title="How do you make RDD"></a>How do you make RDD</h4><p><img src="/2020/01/14/Spark/1578989938843.png" alt="1578989938843"></p>
<p>The SparkContext is sort of the environment that your driver program runs within Spark, and it is what creates RDDs.</p>
<h4 id="Create-RDD"><a href="#Create-RDD" class="headerlink" title="Create RDD"></a>Create RDD</h4><p><img src="/2020/01/14/Spark/1578990141827.png" alt="1578990141827"></p>
<p><img src="/2020/01/14/Spark/1579012530332.png" alt="1579012530332"></p>
<p><img src="/2020/01/14/Spark/1578990969096.png" alt="1578990969096"></p>
<p>Once you have an RDD, what do you do with it?</p>
<h4 id="Transform-RDD"><a href="#Transform-RDD" class="headerlink" title="Transform RDD"></a>Transform RDD</h4><p><img src="/2020/01/14/Spark/1579008653516.png" alt="1579008653516"></p>
<p><em>map</em>: apply some function to every input row of your RDD and create a new RDD that is transformed in some way. Map is used when you have a one to one relationship </p>
<p><em>flatmap</em>: 与map的区别在于，使用map, input于output是一对一的关系，使用flatmap, can have any relationship, where your input lines may or may not result in one or more output lines. 例如，maybe you want to split out each input line into multiple rows, or maybe you want to discard some of the input lines if they’re invalid.</p>
<p><em>filter</em>: can be used to take stuff out of an RDD so you can provide that with some function that determines whether or not a row survives.</p>
<p><em>distinct</em>: gives you back the distinct unique values in an RDD. </p>
<p><em>sample</em>: sample them randomly.</p>
<p><img src="/2020/01/14/Spark/1579008991727.png" alt="1579008991727"></p>
<p><img src="/2020/01/14/Spark/1579009321705.png" alt="1579009321705"></p>
<h4 id="RDD-actions"><a href="#RDD-actions" class="headerlink" title="RDD actions"></a>RDD actions</h4><p><img src="/2020/01/14/Spark/1579009474269.png" alt="1579009474269"></p>
<h4 id="Lazy-evaluation"><a href="#Lazy-evaluation" class="headerlink" title="Lazy evaluation"></a>Lazy evaluation</h4><p><img src="/2020/01/14/Spark/1579009528882.png" alt="1579009528882"></p>
<p>So basically, as you go through this script and transform your RDD’s, until you hit an action, all that’s doing is building up this graph, this chain of dependencies within your driver script, and only when that action is called does it actually figure out the quickest path through those dependencies. And it’s at that point that it actually kicks off the job on your cluster.</p>
<h4 id="Using-RDD’s-in-Spark"><a href="#Using-RDD’s-in-Spark" class="headerlink" title="Using RDD’s in Spark"></a>Using RDD’s in Spark</h4><p>Find the movie with the lowest average rating - with RDD’s.</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/6082670#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/6082670#overview</a></p>
<p><img src="/2020/01/14/Spark/1579014872589.png" alt="1579014872589"></p>
<h3 id="Spark-SQL-DataFrames-and-DataSets"><a href="#Spark-SQL-DataFrames-and-DataSets" class="headerlink" title="Spark SQL (DataFrames and DataSets)"></a>Spark SQL (DataFrames and DataSets)</h3><p><img src="/2020/01/14/Spark/1579012722667.png" alt="1579012722667"></p>
<p>Now, let’s talk about Spark SQL and the Spark 2.0 way of doing things using dataframes and datasets.</p>
<p><img src="/2020/01/14/Spark/1579012953410.png" alt="1579012953410"></p>
<p><img src="/2020/01/14/Spark/1579013215223.png" alt="1579013215223"></p>
<p><img src="/2020/01/14/Spark/1579013233354.png" alt="1579013233354"></p>
<p><img src="/2020/01/14/Spark/1579013961536.png" alt="1579013961536"></p>
<p>DataFrame is really a dataset of row objects, and DataSet is a more general term that can contain any sort of typed information, not necessarily a row like you have in a DataFrame.</p>
<p><img src="/2020/01/14/Spark/1579014168231.png" alt="1579014168231"></p>
<p><img src="/2020/01/14/Spark/1579014221441.png" alt="1579014221441"></p>
<p>Spark SQL is very extensible, you can create user defined functions that plug into a SQL and create your own functions you can use within your SQL queries.</p>
<p>SO, this is the power of DataFrames and DataSets in Spark 2.0 and Spark SQL. The other thing that’s worth noting is that this is sort of the unified API between different subsystems of Spark going forward. You’ll see that in Spark 2 the MLLib machine learning library of the Spark streaming library, all now have DataSet based APIs that you can use, so DataSets are kind of the common denominator between these different systems that allow you to pass data between them. </p>
<p>So, not only do you get performance benefits by using DataSets in Spark 2, you also get easier ways of actually using all these capabilities built on top of Spark we can mix and match them in interesting ways.</p>
<h4 id="Using-DataSets-in-Spark-2"><a href="#Using-DataSets-in-Spark-2" class="headerlink" title="Using DataSets in Spark 2"></a>Using DataSets in Spark 2</h4><p>Find the movie with lowest average rating - with DataFrames.</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963108#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963108#overview</a></p>
<p><img src="/2020/01/14/Spark/1579014920753.png" alt="1579014920753"></p>
<h3 id="Using-MLLib-in-Spark"><a href="#Using-MLLib-in-Spark" class="headerlink" title="Using MLLib in Spark"></a>Using MLLib in Spark</h3><p>movie recommendations (通过predict rating)</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963112#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963112#overview</a></p>
<p><img src="/2020/01/14/Spark/1579059887637.png" alt="1579059887637"></p>
<h3 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h3><p><img src="/2020/01/14/Spark/1579060756315.png" alt="1579060756315"></p>
<p><img src="/2020/01/14/Spark/1579062594969.png" alt="1579062594969"></p>
<p><img src="/2020/01/14/Spark/1579062687242.png" alt="1579062687242"></p>
<p>check your result</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/6115596#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/6115596#overview</a></p>
<p>The DataFrame approach is a lot easier to use, and when you’re running it at a large scale it’s going to be faster as well.</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>存储过程</title>
    <url>/2020/01/13/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>存储过程（Stored Procedure）是一种在数据库中存储复杂程序，以便外部程序调用的一种数据库对象。</p>
<p>存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行。</p>
<p>存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用。</p>
<h4 id="什么是存储过程？"><a href="#什么是存储过程？" class="headerlink" title="什么是存储过程？"></a>什么是存储过程？</h4><p>存储过程就是作为可执行对象存放在数据库中的一个或多个SQL命令。<br>通俗来讲：存储过程其实就是能完成一定操作的一组SQL语句。</p>
<h4 id="为什么要使用存储过程？"><a href="#为什么要使用存储过程？" class="headerlink" title="为什么要使用存储过程？"></a>为什么要使用存储过程？</h4><p>1.存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般SQL语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度。<br>2.当对数据库进行复杂操作时，可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。<br>3.存储过程可以重复使用，可减少数据库开发人员的工作量。<br>4.安全性高，可设定只有某些用户才具有对指定存储过程的使用权</p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul>
<li>存储过程可封装，并隐藏复杂的商业逻辑。</li>
<li>存储过程可以回传值，并可以接受参数。</li>
<li>存储过程无法使用 SELECT 指令来运行，因为它是子程序，与查看表，数据表或用户定义函数不同。</li>
<li>存储过程可以用在数据检验，强制实行商业逻辑等。</li>
</ul>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul>
<li>存储过程，往往定制化于特定的数据库上，因为支持的编程语言不同，当切换到其他厂商的数据库系统时，需要重写原有的存储过程。</li>
<li>存储过程的性能调校与撰写，受限于各种数据库系统。</li>
</ul>
<p>存储过程：存储过程就是编译好了的一些sql语句。</p>
<ol>
<li><p>存储过程因为SQL语句已经预编绎过了，因此运行的速度比较快。</p>
</li>
<li><p>可保证数据的安全性和完整性。通过存储过程可以使没有权限的用户在控制之下间接地存取数据库，从而保证数据的安全。通过存储过程可以使相关的动作在一起发生，从而可以维护数据库的完整性。</p>
</li>
<li>可以降低网络的通信量。存储过程主要是在服务器上运行，减少对客户机的压力。</li>
<li>存储过程可以接受参数、输出参数、返回单个或多个结果集以及返回值。可以向程序返回错误原因</li>
<li>存储过程可以包含程序流、逻辑以及对数据库的查询。同时可以实体封装和隐藏数据逻辑。</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>事务与锁</title>
    <url>/2020/01/13/%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><!-- toc -->
<h4 id="事务-Transaction"><a href="#事务-Transaction" class="headerlink" title="事务 Transaction"></a>事务 Transaction</h4><p>事务：是一系列的数据库操作 (a group of SQL statement)，是数据库应用的基本逻辑单位。</p>
<p>事务性质：(<span style="color:red">ACID</span>)</p>
<ul>
<li>原子性（atomicity）。即不可分割性，事务要么全部被执行，要么就全部不被执行。</li>
<li>一致性或可串性（consistency）。事务的执行使得数据库从一种正确状态转换成另一种正确状态。</li>
<li>隔离性（isolation）。在事务正确提交之前，不允许把该事务对数据的任何改变提供给任何其他事务。</li>
<li>持久性（durability）。事务正确提交后，其结果将永久保存在数据库中，即使在事务提交后有了其他故障，事务的处理结果也会得到保存。</li>
</ul>
<p><img src="/2020/01/13/事务与锁/1578903852566.png" alt="1578903852566"></p>
<p><img src="/2020/01/13/事务与锁/1578903920125.png" alt="1578903920125"></p>
<p><img src="/2020/01/13/事务与锁/1578904033183.png" alt="1578904033183"></p>
<p><img src="/2020/01/13/事务与锁/1578904133622.png" alt="1578904133622"></p>
<p><img src="/2020/01/13/事务与锁/1578904156358.png" alt="1578904156358"></p>
<a id="more"></a>
<p><img src="/2020/01/13/事务与锁/1578904553025.png" alt="1578904553025"></p>
<p><img src="/2020/01/13/事务与锁/1578904582538.png" alt="1578904582538"></p>
<p><img src="/2020/01/13/事务与锁/1578904641058.png" alt="1578904641058"></p>
<p><img src="/2020/01/13/事务与锁/1578904660894.png" alt="1578904660894"></p>
<p><img src="/2020/01/13/事务与锁/1578904679577.png" alt="1578904679577"></p>
<p><code>可串行化</code>：多个事务的并发执行是正确的，当且仅当其结果与某一次序串行地执行它们时的结果相同，称这种调度策略是可串行化调度。</p>
<p><img src="/2020/01/13/事务与锁/1578904744883.png" alt="1578904744883"></p>
<h4 id="并发控制-Concurrency-Control"><a href="#并发控制-Concurrency-Control" class="headerlink" title="并发控制 Concurrency Control"></a>并发控制 Concurrency Control</h4><p><strong>并发控制：</strong> 所谓并发控制，是指多用户共享的系统中，许多用户可能同时对同一数据进行操作。</p>
<p><img src="/2020/01/13/事务与锁/1578904973251.png" alt="1578904973251"></p>
<p><img src="/2020/01/13/事务与锁/1578905068177.png" alt="1578905068177"></p>
<p><img src="/2020/01/13/事务与锁/1578905172492.png" alt="1578905172492"></p>
<p><img src="/2020/01/13/事务与锁/1578905192362.png" alt="1578905192362"></p>
<h5 id="共享锁与排他锁（或叫互斥锁）"><a href="#共享锁与排他锁（或叫互斥锁）" class="headerlink" title="共享锁与排他锁（或叫互斥锁）"></a>共享锁与排他锁（或叫互斥锁）</h5><p><img src="/2020/01/13/事务与锁/1578905290193.png" alt="1578905290193"></p>
<p><img src="/2020/01/13/事务与锁/1578905458095.png" alt="1578905458095"></p>
<h5 id="两段锁协议（Two-Phase-Locking-——-2PL）"><a href="#两段锁协议（Two-Phase-Locking-——-2PL）" class="headerlink" title="两段锁协议（Two-Phase Locking —— 2PL）"></a>两段锁协议（Two-Phase Locking —— 2PL）</h5><p><a href="https://www.jianshu.com/p/5c78f5c4d57b" target="_blank" rel="noopener">https://www.jianshu.com/p/5c78f5c4d57b</a></p>
<p>两段锁协议规定所有的事务应遵守的规则：</p>
<p>① 在对任何数据进行读、写操作之前，首先要申请并获得对该数据的封锁。</p>
<p>② 在释放一个封锁之后，事务不再申请和获得其它任何封锁。</p>
<p>即事务的执行分为两个阶段：</p>
<p>第一阶段是获得封锁的阶段，称为扩展阶段。</p>
<p>第二阶段是释放封锁的阶段，称为收缩阶段。</p>
<p><em>若所有事务均遵守两段锁协议，则这些事务的所有交叉调度都是可串行化的。</em></p>
<p><img src="/2020/01/13/事务与锁/1578923170158.png" alt="1578923170158"></p>
<blockquote>
<p>简单的理解两段锁，就是分为两个阶段：<br>第一阶段 只能去申请锁<br>第二阶段 只能去释放锁</p>
</blockquote>
<p><a href="https://blog.csdn.net/weixin_38118016/article/details/90271468" target="_blank" rel="noopener">https://blog.csdn.net/weixin_38118016/article/details/90271468</a></p>
<p>举个例子，假设有一个表 t，主键是 id，其中一个字段是 k，在下面的操作中，事务 B 的 update 语句执行时，会是什么现象呢 ？</p>
<p><img src="https://img-blog.csdnimg.cn/20190516203512941.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODExODAxNg==,size_16,color_FFFFFF,t_70" alt="img"></p>
<p>这个问题的结论取决于事务 A 执行完前两条语句后，持有哪些锁，以及在什么时候释放。</p>
<p>实际上，事务 A 持有两个记录的行锁，都是在 commit 的时候才释放的，所以事务 B 的 update 就会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能被继续执行。也就是说，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，需要等事务结束时才释放，这就是两阶段锁协议，分为加锁阶段和解锁阶段，所有的 lock 操作都在 unlock 操作之后。</p>
<p>假设你负责实现一个电影票在线交易业务，顾客 userA 要在影院 cinema 购买电影票，需要涉及以下操作：</p>
<ol>
<li><p>扣除顾客 userA 账户余额</p>
</li>
<li><p>增加影院 cinema 账户余额</p>
</li>
<li><p>记录一条交易日志</p>
</li>
</ol>
<p>也就是说，完成这次交易，需要 update 两条记录， insert 一条记录。当然为了保证交易的原子性，我们需要这三个操作放在一个事务中。与此同时，还有顾客 userB 也在影院购买电影票，那么你会怎样安排这三个语句在事务中的顺序呢？</p>
<p>首先发现冲突的部分是语句 2，就是两个事务都要给 cinema 的账户余额增加电影票价。根据两阶段协议，不论怎么安排语句，所有的操作需要的行锁都是在事务提交的时候才释放的，要想使行锁在事务中不会停留太长时间，最大程度的减少事务之间的锁等待，应该把语句 2 放在最后面。如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20190516203204823.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODExODAxNg==,size_16,color_FFFFFF,t_70" alt="img"></p>
<h5 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h5><p>死锁：事务循环等待数据锁，则会死锁。<br>死锁处理：预防死锁协议，死锁恢复机制。</p>
<p><img src="/2020/01/13/事务与锁/1578905609640.png" alt="1578905609640"></p>
<p><a href="https://blog.csdn.net/weixin_38118016/article/details/90271468" target="_blank" rel="noopener">https://blog.csdn.net/weixin_38118016/article/details/90271468</a></p>
<p>如下图所示，事务 A 在等待事务 B 释放 id = 2 的行锁，而事务 B 在等待 事务 A 释放 id = 1 的行锁，事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。</p>
<p><img src="https://img-blog.csdnimg.cn/20190516203204496.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODExODAxNg==,size_16,color_FFFFFF,t_70" alt="img"></p>
<p>在并发系统中，<strong>不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程进入无限等待的状态</strong>，成为死锁。</p>
<p>当进入死锁状态时，有下列 2 种策略：</p>
<ol>
<li><p>设置超时时间，第一个被锁住的事务 A 等待超过多少秒会超时退出（例如50s），其他事务得以执行。然而对于在线服务来说，这个等待时间往往是无法接受的。如果设置太短 (如1s)，可能有的事务只是简单的锁等待，就被退出了，会出现很多误伤。</p>
</li>
<li><p>发起死锁检测，发现死锁之后主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。比如回滚事务 A，让事务 B 继续执行。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>索引Index</title>
    <url>/2020/01/13/%E7%B4%A2%E5%BC%95Index/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/2020/01/13/索引Index/1578902807233.png" alt="1578902807233"></p>
<p><img src="/2020/01/13/索引Index/1578902869016.png" alt="1578902869016"></p>
<p><code>Create UNIQUE INDEX index_name ON TableName(col_name);</code> //建索引</p>
<p><img src="/2020/01/13/索引Index/1578902891139.png" alt="1578902891139"></p>
<p><img src="/2020/01/13/索引Index/1578902910331.png" alt="1578902910331"></p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>视图View</title>
    <url>/2020/01/13/%E8%A7%86%E5%9B%BEView/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/2020/01/13/视图View/1578902313361.png" alt="1578902313361"></p>
<p><img src="/2020/01/13/视图View/1578902382330.png" alt="1578902382330"></p>
<p><img src="/2020/01/13/视图View/1578902994931.png" alt="1578902994931"></p>
<p><img src="/2020/01/13/视图View/1578903023109.png" alt="1578903023109"></p>
<p><code>INSERT INTO Viewname {column1,column2,…} values(exp1,exp2,…);</code>//插入视图实际影响表</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title>Hive介绍</title>
    <url>/2020/01/12/Hive%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>参考：</p>
<p><a href="https://blog.csdn.net/PowerBlogger/article/details/83626449" target="_blank" rel="noopener">https://blog.csdn.net/PowerBlogger/article/details/83626449</a></p>
<p><a href="https://blog.csdn.net/u010886217/article/details/83796151" target="_blank" rel="noopener">https://blog.csdn.net/u010886217/article/details/83796151</a></p>
<!-- toc -->
<h3 id="什么是Hive？"><a href="#什么是Hive？" class="headerlink" title="什么是Hive？"></a>什么是Hive？</h3><p>Hive是建立在Hadoop上的，用来构建数据仓库的工具，里面有表的概念，可以使用SQL语句实现存储、查询和分析存储在 HDFS上的数据，这些SQL语句在Hive中称为HQL，语法和SQL语句基本一样。<br>由于数据是杂乱无章的，所以Hive需要一份关于这些数据的元数据来管理和操作这些数据。这份元数据包括：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">元数据（</span><br><span class="line">行的分隔符（在映射成表的时候知道在哪里分行显示）</span><br><span class="line">字段分隔符（在映射成表的时候知道在哪里分列显示）</span><br><span class="line">字段的类型</span><br><span class="line">字段的名称</span><br><span class="line">）</span><br></pre></td></tr></table></figure>
<p>在Hive中，我们把数据存储在HDFS中，元数据默认存储在Hive自带的Derby数据库中，由于Derby不能实现并发访问，所以我们一般使用mysql进行替换。</p>
<h3 id="Hive的原理"><a href="#Hive的原理" class="headerlink" title="Hive的原理"></a>Hive的原理</h3><p><strong>Hive 将用户的 HQL 语句进行解析，优化，最终把一个个的HQL语句转换为 MapReduce 作业提交到 Hadoop 集群上，Hadoop进行作业的调度及监控，作业完成后将执行结果返回给用户。</strong>所以，<strong>Hive并不进行计算，只是把HQL解析为MapperReduce在HDFS集群中运行而已</strong>，所以Hive的效率并不高。</p>
<h3 id="Hive中表的类型"><a href="#Hive中表的类型" class="headerlink" title="Hive中表的类型"></a>Hive中表的类型</h3><p>Hive中有5种表：内部表，外部表，临时表，分区表，桶表（分桶表）</p>
<h4 id="1-内部表"><a href="#1-内部表" class="headerlink" title="1. 内部表"></a>1. 内部表</h4><p>数据默认存储在/user/hive/warehouse，由Hive自身管理，删除内部表会同时删除存储数据和元数据。</p>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">// 建表方式一</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1(</span><br><span class="line">	    <span class="keyword">id</span>	<span class="built_in">INT</span>，</span><br><span class="line">	    <span class="keyword">name</span> <span class="keyword">STRING</span>，</span><br><span class="line">	    age <span class="built_in">INT</span>,</span><br><span class="line">		gfs <span class="built_in">ARRAY</span>&lt;<span class="keyword">STRING</span>&gt;,</span><br><span class="line">		address <span class="keyword">MAP</span>&lt;<span class="keyword">STRING</span>,<span class="keyword">STRING</span>&gt;,</span><br><span class="line">		info <span class="keyword">STRUCT</span>&lt;country:<span class="keyword">String</span>,province:<span class="keyword">String</span>,shi:<span class="keyword">String</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">' '</span> </span><br><span class="line">COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span></span><br><span class="line"><span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">':'</span> </span><br><span class="line"><span class="keyword">LINES</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\n'</span></span><br><span class="line">LOCATION <span class="string">"/test"</span>;//可以设置源数据的位置，若不设置默认就在Hive的工作目录区</span><br><span class="line"></span><br><span class="line">// 建表方式二</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gfstbl1 <span class="keyword">like</span> gfstbl;只是创建表结构</span><br><span class="line"></span><br><span class="line">// 建表方式三</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> gfstbl2 <span class="keyword">AS</span> <span class="keyword">SELECT</span> <span class="keyword">id</span>,<span class="keyword">name</span>,gfs,address <span class="keyword">from</span> gfstbl; </span><br><span class="line">  会创建相应的表结构，并且插入数据，相当于完整的赋值</span><br></pre></td></tr></table></figure>
<p><strong>加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/gfs.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> gfstbl;</span><br></pre></td></tr></table></figure>
<p><strong>查看表描述信息：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> [<span class="keyword">EXTENDED</span>|FORMATTED] table_name</span><br><span class="line"><span class="keyword">EXTENDED</span> 极简的方式显示</span><br><span class="line">FORMATTED 格式化方式来显示</span><br><span class="line"><span class="keyword">DESCRIBE</span> <span class="keyword">EXTENDED</span> gfstbl;默认就是EXTENDED</span><br><span class="line"><span class="keyword">DESCRIBE</span> FORMATTED gfstbl;</span><br></pre></td></tr></table></figure>
<p><strong>插入数据的其他方式：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">插入数据的方式：</span><br><span class="line">	1、<span class="keyword">insert</span> 新数据</span><br><span class="line">	<span class="number">2</span>、<span class="keyword">load</span></span><br><span class="line">	<span class="number">3</span>、查询其他表数据 <span class="keyword">insert</span> 到新表中</span><br><span class="line">	模板：</span><br><span class="line">		<span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...)] </span><br><span class="line">		select_statement1 <span class="keyword">FROM</span> from_statement;</span><br><span class="line">		</span><br><span class="line">		FROM from_statement</span><br><span class="line">		<span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> tablename1 [<span class="keyword">PARTITION</span> (partcol1=val1, partcol2=val2 ...) </span><br><span class="line">		[<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>]] select_statement1</span><br><span class="line"></span><br><span class="line">		<span class="keyword">insert</span> <span class="keyword">into</span> rest <span class="keyword">select</span> <span class="keyword">count</span>(*) <span class="keyword">from</span> <span class="keyword">table</span>;</span><br><span class="line">		</span><br><span class="line">		习惯写法 from提前  减少SQL代码的冗余</span><br><span class="line">		from day_hour_table</span><br><span class="line">		<span class="keyword">insert</span> <span class="keyword">into</span> rest </span><br><span class="line">			<span class="keyword">select</span> <span class="keyword">count</span>(*) ;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="2-外部表"><a href="#2-外部表" class="headerlink" title="2. 外部表"></a>2. 外部表</h4><p>数据存储位置由用户自己指定，由HDFS管理，<strong>删除外部表时仅仅会删除元数据，存储数据不会受到影响。</strong></p>
<ul>
<li><p>适用情形：</p>
<p>当一份日志需要多个小组一起分析，分析完了之后创建的表就可以删除了。但是普通的表删除的同时也会把数据删除，这样就会影响到其他小组的分析，而且日志数据也不能随便删除。所以，需要外部表，删除外部表，不会删除对应的HDFS上的数据。</p>
</li>
<li><p>对比外部表和内部表区别<br>删除外部表，数据不会有任何改变，只是mysql中的元数据被修改，但是删除内部表（管理表），数据就会被删除。</p>
</li>
</ul>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> wc_external </span><br><span class="line">   (word1 <span class="keyword">STRING</span>, </span><br><span class="line">   word2 <span class="keyword">STRING</span>) </span><br><span class="line">   <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line">   <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">' '</span> </span><br><span class="line">   location <span class="string">'/test/external'</span>; location可加可不加，不加location默认是在hive的工作目录区</span><br></pre></td></tr></table></figure>
<blockquote>
<p>总结：hive内部表和外部表的区别<br>    1）创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径， 不对数据的位置做任何改变。<br>    2）删除表时：在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据</p>
</blockquote>
<h4 id="3-临时表"><a href="#3-临时表" class="headerlink" title="3. 临时表"></a>3. 临时表</h4><p>在当前会话期间存在，会话结束后自动销毁。</p>
<ul>
<li><p>适用情形</p>
<p>临时分析，在关闭hive客户端后，临时表就会消失。主要用于存储不重要中间结果集，不重要的表。</p>
</li>
</ul>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">TEMPORARY</span> <span class="keyword">table</span> ttabc(<span class="keyword">id</span> <span class="built_in">Int</span>,<span class="keyword">name</span> <span class="keyword">String</span>) 临时表的声明周期是一次会话</span><br><span class="line">进入hive shell 创建一张表，关闭shell后，表丢失，临时表不支持分区</span><br></pre></td></tr></table></figure>
<p><strong>建表并加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">TEMPORARY</span> <span class="keyword">table</span> dept_tmp(  </span><br><span class="line">deptno <span class="built_in">int</span>,  </span><br><span class="line">dname <span class="keyword">string</span>,</span><br><span class="line">loc <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/datas/dept.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_tmp;</span><br></pre></td></tr></table></figure>
<p><strong>查看location信息：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">desc formatted dept_tmp;</span><br><span class="line">Location:               hdfs://172.19.199.187:8020/tmp/hive/hadoop/68174383-f427-4629-9707-0ab1c9b07726/_tmp_space.db/d872efec-1294-48b0-9071-31cf98d46400    </span><br><span class="line">Table Type:             MANAGED_TABLE</span><br></pre></td></tr></table></figure>
<h4 id="4-分区表"><a href="#4-分区表" class="headerlink" title="4. 分区表"></a>4. 分区表</h4><p>将数据按照某个字段或者关键字分成多个子目录来存储，防止暴力扫描全表。</p>
<ul>
<li><p>适用情形</p>
<p>普通的表：select * from logs where date = ‘20171209’，执行流程：对全表的数据进行查询，然后才过滤操作。</p>
<p>分区表：select * from logs where date = ‘20171209’，执行流程：直接加载对应文件路径下的数据。</p>
<p>适用于大数据量，可以通过分区快速定位需要查询的数据，<strong>分区表的作用主要是提高查询检索的效率 。</strong></p>
</li>
</ul>
<p><strong>静态分区表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_hour_table (<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">content</span> <span class="keyword">string</span>) partitioned <span class="keyword">by</span> (dt <span class="built_in">int</span>,<span class="keyword">hour</span> <span class="built_in">int</span>) </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span> ;</span><br></pre></td></tr></table></figure>
<p><strong>加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- insert单条插入的方式往分区表中插入数据：</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">9</span>,<span class="keyword">hour</span>=<span class="number">1</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">9</span>,<span class="keyword">hour</span>=<span class="number">2</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">8</span>,<span class="keyword">hour</span>=<span class="number">1</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">8</span>,<span class="keyword">hour</span>=<span class="number">2</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="comment">-- load批量插入的方式往分区表中插入数据：</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">"/root/ceshi"</span> <span class="keyword">into</span> <span class="keyword">table</span> day_table <span class="keyword">partition</span> (dt=<span class="number">10</span>,<span class="keyword">hour</span>=<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p><strong>删除Hive分区表中的分区：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_table <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10</span>,<span class="keyword">hour</span>=<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p><strong>创建\添加分区：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] <span class="keyword">PARTITION</span> partition_spec [LOCATION <span class="string">'location'</span>]</span><br><span class="line">[, <span class="keyword">PARTITION</span> partition_spec [LOCATION <span class="string">'location'</span>], ...];</span><br><span class="line"></span><br><span class="line">partition_spec:</span><br><span class="line">	  : (partition_column = partition_col_value, partition_column = partition_col_value, ...) </span><br><span class="line"></span><br><span class="line"><span class="comment">-- 创建一个空分区：</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10000</span>, <span class="keyword">hour</span>=<span class="number">2000</span>);</span><br><span class="line"><span class="comment">-- 然后将数据上传到空分区对应的目录下，分区表中就会显示数据</span></span><br><span class="line">	HDFS dfs -put ........</span><br><span class="line"><span class="comment">-- 创建一个空分区并且将空分区指向数据位置：</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10000</span>, <span class="keyword">hour</span>=<span class="number">2000</span>) location <span class="string">"/test"</span></span><br></pre></td></tr></table></figure>
<p><strong>动态分区表：</strong></p>
<p>动态分区表和静态分区表建表语句相同，插入数据的方式不同</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure>
<p>动态分区可以根据数据本身的特征自动来划分分区，load data …只是将数据上传到HDFS指定目录，所以我们需要使用from insert的方式插入数据，hive才会根据分区设置自动将数据进行分区。</p>
<h4 id="5-分桶表"><a href="#5-分桶表" class="headerlink" title="5. 分桶表"></a>5. 分桶表</h4><p>将数据按照某个字段和桶的数量，对指定字段进行取模运算，拆分成多个小文件来存储，模相同的存储在同一个小文件中，提高join以及抽样的效率。</p>
<ul>
<li><p>适用情形</p>
<p>数据有严重的数据倾斜，分布不均匀，但是相对来说每个桶中的数据量会比较平均。桶与桶之间做join等查询的时候，会有优化。</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp_bu(  </span><br><span class="line">empno <span class="built_in">int</span>,  </span><br><span class="line">ename <span class="keyword">string</span>,</span><br><span class="line">job <span class="keyword">string</span>,  </span><br><span class="line">mgr <span class="built_in">int</span>,</span><br><span class="line">hiredate <span class="keyword">string</span>,  </span><br><span class="line">sal <span class="keyword">double</span>,  </span><br><span class="line">comm <span class="keyword">double</span>,  </span><br><span class="line">deptno <span class="built_in">int</span></span><br><span class="line">)CLUSTERED <span class="keyword">BY</span>(deptno) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  <span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> emp_bu_2 <span class="keyword">select</span> * <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>
<p>分桶表是对列值取哈希值的方式，将不同数据放到不同文件中存储<br>由列的哈希值除以桶的个数来决定每条数据划分在哪个桶中<br>对于hive中每一个表、分区都可以进一步进行分桶</p>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> psnbucket( <span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>, age <span class="built_in">INT</span>) </span><br><span class="line">CLUSTERED <span class="keyword">BY</span> (age) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<p><strong>插入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> psnbucket <span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span>, age <span class="keyword">from</span> original;</span><br></pre></td></tr></table></figure>
<p><strong>分桶表+分区表：</strong></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> psnbucket_partition( <span class="keyword">id</span> <span class="built_in">INT</span>, <span class="keyword">name</span> <span class="keyword">STRING</span>, age <span class="built_in">INT</span>) </span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(height <span class="keyword">DOUBLE</span>) </span><br><span class="line">CLUSTERED <span class="keyword">BY</span> (age) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title>笔试知识点</title>
    <url>/2020/01/12/%E7%AC%94%E8%AF%95%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="Hbase"><a href="#Hbase" class="headerlink" title="Hbase"></a>Hbase</h4><p>HBase是一个分布式的、面向列的开源数据库。</p>
<p>题目来源于：<a href="https://www.cnblogs.com/cxchanpin/p/7381890.html" target="_blank" rel="noopener">https://www.cnblogs.com/cxchanpin/p/7381890.html</a></p>
<ul>
<li><p>HBase来源于哪篇博文？ C</p>
<p>A. The Google File System</p>
<p>B. MapReduce</p>
<p>C. BigTable</p>
<p>D. Chubby</p>
</li>
</ul>
<hr>
<ul>
<li><p>下对HBase的描写叙述哪些是正确的？ B、C、D</p>
<p>A. 不是开源的</p>
<p>B. 是面向列的</p>
<p>C. 是分布式的</p>
<p>D. 是一种NoSQL数据库</p>
</li>
</ul>
<a id="more"></a>
<hr>
<ul>
<li><p>HBase依靠（）存储底层数据 A</p>
<p>A. HDFS</p>
<p>B. Hadoop</p>
<p>C. Memory</p>
<p>D. MapReduce</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase依赖（）提供消息通信机制 A</p>
<p>A. Zookeeper</p>
<p>B. Chubby</p>
<p>C. RPC</p>
<p>D. Socket</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase依赖（）提供强大的计算能力 D</p>
<p>A. Zookeeper</p>
<p>B. Chubby</p>
<p>C. RPC</p>
<p>D. MapReduce</p>
</li>
</ul>
<hr>
<ul>
<li><p>MapReduce与HBase的关系，哪些描写叙述是正确的？ B、C</p>
<p>A. 两者不可或缺。MapReduce是HBase能够正常执行的保证</p>
<p>B. 两者不是强关联关系，没有MapReduce，HBase能够正常执行</p>
<p>C. MapReduce能够直接訪问HBase</p>
<p>D. 它们之间没有不论什么关系</p>
</li>
</ul>
<hr>
<ul>
<li><p>以下哪些选项正确描写叙述了HBase的特性？ A、B、C、D</p>
<p>A. 高可靠性</p>
<p>B. 高性能</p>
<p>C. 面向列</p>
<p>D. 可伸缩</p>
</li>
</ul>
<hr>
<ul>
<li><p>以下与Zookeeper类似的框架是？D</p>
<p>A. Protobuf</p>
<p>B. Java</p>
<p>C. Kafka </p>
<p>D. Chubby</p>
</li>
</ul>
<p>Kafka是一个高吞吐量分布式消息系统。kafka的数据仅仅会顺序append。数据的删除策略是累积到一定程度或者超过一定时间再删除。Kafka还有一个独特的地方是将消费者信息保存在client而不是MQserver。这样server就不用记录消息的投递过程，每一个client都自己知道自己下一次应该从什么地方什么位置读取消息。消息的投递过程也是采用client主动pull的模型，这样大大减轻了server的负担。Kafka还强调降低数据的序列化和拷贝开销，它会将一些消息组织成Message Set做批量存储和发送，而且client在pull数据的时候，尽量以zero-copy的方式传输。利用sendfile（相应java里的 FileChannel.transferTo/transferFrom）这种高级IO函数来降低拷贝开销。可见，kafka是一个精心设计，特定于某些应用的MQ系统，这种偏向特定领域的MQ系统我预计会越来越多，垂直化的产品策略值的考虑。</p>
<p>Chubby首先是一个分布式的文件系统。Chubby可以提供机制使得client可以在Chubby service上创建文件和运行一些文件的基本操作。说它是分布式的文件系统，是由于一个Chubby cell是一个分布式的系统。一般包括了5台机器，整个文件系统是部署在这5台机器上的。</p>
<p>从更高一点的语义层面上，Chubby是一个 lock service。一个针对松耦合的分布式系统的lock service。所谓lock service，就是这个service可以提供开发者经经常使用的“锁”，“解锁”功能。通过Chubby，一个分布式系统中的上千个client都可以 对于某项资源进行“加锁”，“解锁”。</p>
<p>那么，Chubby是如何实现这种“锁”功能的？就是通过文件。Chubby中的“锁”就是文件。在上例中，创建文件事实上就是进行“加锁”操作，创建文件成功的那个server事实上就是抢占到了“锁”。用户通过打开、关闭和读取文件。获取共享锁或者独占锁； 而且通过通信机制，向用户发送更新信息。</p>
<p>综上所述。Chubby是一个lock service。通过这个lock service能够解决分布式中的一致性问题。而这个lock service的实现是一个分布式的文件系统。</p>
<hr>
<ul>
<li><p>以下与HDFS类似的框架是？C</p>
<p>A. NTFS</p>
<p>B. FAT32</p>
<p>C. GFS (也是分布式文件系统，谷歌自己的分布式文件系统)</p>
<p>D. EXT3</p>
</li>
</ul>
<hr>
<ul>
<li><p>以下哪些概念是HBase框架中使用的？A、C</p>
<p>A. HDFS</p>
<p>B. GridFS</p>
<p>C. Zookeeper</p>
<p>D. EXT3</p>
</li>
</ul>
<hr>
<h5 id="HFile"><a href="#HFile" class="headerlink" title="HFile"></a>HFile</h5><p><span style="color:red">HFile是HBase存储数据的文件组织形式</span></p>
<ul>
<li><p>HFile数据格式中的Data字段用于（）。A</p>
<p>A. 存储实际的KeyValue数据</p>
<p>B. 存储数据的起点</p>
<p>C. 指定字段的长度</p>
<p>D. 存储数据块的起点</p>
</li>
</ul>
<hr>
<ul>
<li><p>HFile数据格式中的MetaIndex字段用于（）。D</p>
<p>A. Meta块的长度</p>
<p>B. Meta块的结束点</p>
<p>C. Meta块数据内容</p>
<p>D. Meta块的起始点</p>
</li>
</ul>
<hr>
<ul>
<li><p>HFile数据格式中的Magic字段用于（）。A</p>
<p>A. 存储随机数，防止数据损坏</p>
<p>B. 存储数据的起点</p>
<p>C. 存储数据块的起点</p>
<p>D. 指定字段的长度</p>
</li>
</ul>
<hr>
<ul>
<li><p>HFile数据格式中的KeyValue数据格式，下列选项描写叙述正确的是（）。A、D</p>
<p>A. 是byte[]数组</p>
<p>B. 没有固定的结构</p>
<p>C. 数据的大小是定长的</p>
<p>D. 有固定的结构</p>
</li>
</ul>
<hr>
<ul>
<li><p>HFile数据格式中的KeyValue数据格式中Value部分是（）。C</p>
<p>A. 拥有复杂结构的字符串</p>
<p>B. 字符串</p>
<p>C. 二进制数据</p>
<p>D. 压缩数据</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase中的批量载入底层使用（）实现。A</p>
<p>A. MapReduce</p>
<p>B. Hive</p>
<p>C. Coprocessor</p>
<p>D. Bloom Filter</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase性能优化包括以下的哪些选项？A、B、C、D</p>
<p>A. 读优化</p>
<p>B. 写优化</p>
<p>C. 配置优化</p>
<p>D. JVM优化</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase构建二级索引的实现方式有哪些？ A、B</p>
<p>A. MapReduce</p>
<p>B. Coprocessor</p>
<p>(HBase在0.92之后引入了协处理器(coprocessors)，实现一些激动人心的新特性：可以轻易建立二次索引、复杂过滤器(谓词下推)以及訪问控制等)</p>
<p>C. Bloom Filter</p>
<p>D. Filter</p>
</li>
</ul>
<hr>
<ul>
<li><p>关于HBase二级索引的描写叙述。哪些是正确的？A、B</p>
<p>A. 核心是倒排表</p>
<p>B. 二级索引概念是相应Rowkey这个“一级”索引</p>
<p>C. 二级索引使用平衡二叉树</p>
<p>D. 二级索引使用LSM结构</p>
</li>
</ul>
<hr>
<ul>
<li><p>下列关于Bloom Filter的描写叙述正确的是？A、C</p>
<p>A. 是一个非常长的二进制向量和一系列随机映射函数</p>
<p>B. 没有误算率</p>
<p>C. 有一定的误算率</p>
<p>D. 能够在Bloom Filter中删除元素</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase官方版本号能够安装在什么操作系统上？A、B、C</p>
<p>A. CentOS</p>
<p>B. Ubuntu</p>
<p>C. RedHat</p>
<p>D. Windows</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase虚拟分布式模式须要（）个节点？A</p>
<p>A. 1</p>
<p>B. 2</p>
<p>C. 3</p>
<p>D. 最少3个</p>
</li>
</ul>
<hr>
<ul>
<li><p>HBase分布式模式最好须要（）个节点？C</p>
<p>A. 1</p>
<p>B. 2</p>
<p>C. 3</p>
</li>
</ul>
<hr>
<ul>
<li><p>下列哪些选项是安装HBase前所必须安装的？A、B</p>
<p>A. 操作系统</p>
<p>B. JDK</p>
<p>C. Shell Script</p>
<p>D. Java Code</p>
</li>
</ul>
<hr>
<ul>
<li><p>解压.tar.gz结尾的HBase压缩包使用的Linux命令是？A</p>
<p>A. tar -zxvf</p>
<p>B. tar -zx</p>
<p>C. tar -s</p>
<p>D. tar -nf</p>
</li>
</ul>
<hr>
<ul>
<li>从Hadoop 2.7.3 版本开始，HDFS中Block size 的默认大小为128MB.</li>
</ul>
<hr>
<h4 id="SQL面试题"><a href="#SQL面试题" class="headerlink" title="SQL面试题"></a>SQL面试题</h4><p><a href="https://www.cnblogs.com/huolong-blog/p/7603454.html" target="_blank" rel="noopener">https://www.cnblogs.com/huolong-blog/p/7603454.html</a></p>
<ul>
<li><p>触发器的作用？</p>
<p>触发器是一种特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。</p>
</li>
</ul>
<hr>
<ul>
<li><p>什么是存储过程？用什么来调用？</p>
<p>存储过程是一个预编译的SQL语句，优点是允许模块化的设计，就是说只需创建一次，以后在该程序中就可以调用多次。如果某次操作需要执行多次SQL，使用存储过程比单纯SQL语句执行要快。可以用一个命令对象来调用存储过程。</p>
</li>
</ul>
<hr>
<ul>
<li><p>索引的作用？和它的优点缺点是什么？</p>
<p>索引就一种特殊的查询表，数据库的搜索引擎可以利用它加速对数据的检索。简单地说，索引是一个数据结构，用来快速访问数据库表格或者视图里的数据。它很类似与现实生活中书的目录，不需要查询整本书内容就可以找到想要的数据。索引可以是唯一的，创建索引允许指定单个列或者是多个列。缺点是它减慢了数据录入的速度，同时也增加了数据库的尺寸大小。</p>
</li>
</ul>
<hr>
<ul>
<li><p>什么是事务？什么是锁？</p>
<p>事务就是被绑定在一起作为一个逻辑工作单元的SQL语句分组，如果任何一个语句操作失败那么整个操作就失败，以后操作就会回滚到操作前状态，或者是上个节点。为了确保要么执行，要么不执行，就可以使用事务。要将有组语句作为事务考虑，就需要通过ACID测试，即原子性，一致性，隔离性和持久性。</p>
<p>锁：在所有的DBMS中，锁是实现事务的关键，锁可以保证事务的完整性和并发性。与现实生活中锁一样，它可以使某些数据的拥有者，在某段时间内不能使用某些数据或数据结构。</p>
</li>
</ul>
<hr>
<ul>
<li><p>什么叫视图？游标是什么？</p>
<p>视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，视图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。</p>
<p>游标：是对查询出来的结果集作为一个单元来有效的处理。游标可以定在该单元中的特定行，从结果集的当前行检索一行或多行。可以对结果集当前行做修改。一般不使用游标，但是需要逐条处理数据的时候，游标显得十分重要。游标用于定位结果集的行。</p>
</li>
</ul>
<h4 id="算法工程师能力评估（牛客）"><a href="#算法工程师能力评估（牛客）" class="headerlink" title="算法工程师能力评估（牛客）"></a>算法工程师能力评估（牛客）</h4><p><img src="/2020/01/12/笔试知识点/1581870524984.png" alt="1581870524984"></p>
<p><img src="/2020/01/12/笔试知识点/1581864564384.png" alt="1581864564384"></p>
<p><img src="/2020/01/12/笔试知识点/1581864653934.png" alt="1581864653934"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581864678069.png" alt="1581864678069"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581864809633.png" alt="1581864809633"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581864854892.png" alt="1581864854892"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581864889064.png" alt="1581864889064"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581864916612.png" alt="1581864916612"></p>
<p>B树相关知识见<a href="https://qypx.github.io/2020/02/16/B树介绍/">这里</a></p>
<hr>
<ul>
<li>具有3个结点的二叉树有几种形态？</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581865489812.png" alt="1581865489812"></p>
<p>解析：</p>
<pre><code> 这是组合计数问题，最常见的catalan数，C(n)=(1/(n+1))*((2*n)!/(n!*n!)) 

 3个节点详细如图： 
</code></pre><p><img src="/2020/01/12/笔试知识点/1581865572237.png" alt="1581865572237"></p>
<hr>
<ul>
<li>已知一棵二叉树前序遍历和中序遍历分别为 <code>ABDEGCFH</code> 和 <code>DBGEACHF</code>，则该二叉树的后序遍历为多少？</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581865717797.png" alt="1581865717797"></p>
<p>解析：</p>
<p><strong>前序遍历确定根节点，中序遍历确定左右子树</strong>。</p>
<p><img src="/2020/01/12/笔试知识点/1581866226956.png" alt="1581866226956"></p>
<hr>
<ul>
<li>已知数据表A中每个元素距其最终位置不远，为节省时间排序，应采用什么方法排序？</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581866323542.png" alt="1581866323542"></p>
<p>解析：</p>
<ul>
<li><p>插入排序：如果平均每个元素离最终位置相距c个元素，则其复杂度为O(cn)，一共n趟，每次比较c次； </p>
</li>
<li><p>快速排序：最好的、平均的复杂度都是O(nlog(n))，如果每次选择的中间数都最小或最大，那就是最坏的情况，复杂度是O(n*n)；所以快速排序和元素的位置没有关系，跟选择的中间数有关。 </p>
</li>
<li><p>堆排序：复杂度一直是O(nlog(n)); </p>
</li>
<li><p>直接选择排序：跟元素位置没有关系，都要遍历n遍，每遍找出最小或最大数来，复杂度是O(n*n)； </p>
<p>答案是插入排序。 </p>
</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581866854874.png" alt="1581866854874"></p>
<hr>
<ul>
<li>将N条长度均为M的有序链表进行合并，合并以后的链表也保持有序，时间复杂度为()?</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581867137493.png" alt="1581867137493"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581867157973.png" alt="1581867157973"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581867257640.png" alt="1581867257640"></p>
<p>解析：这个是卡特兰数的经典应用，但是这个问题不是一两句话能说得清的。</p>
<p>可采取代入法，n=1或n=2代入，均可得到正确答案。</p>
<hr>
<ul>
<li>T(n) = 25T(n/5)+n^2的时间复杂度？</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581867385697.png" alt="1581867385697"></p>
<p>解析：Master Theorem</p>
<p><img src="/2020/01/12/笔试知识点/1581867450572.png" alt="1581867450572"></p>
<hr>
<ul>
<li>连续自然数之和为1000的共有几组？（m，n都为自然数，单独1个数也算作“连续自然数”）</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581868980583.png" alt="1581868980583"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581869129932.png" alt="1581869129932"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581869211656.png" alt="1581869211656"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581869344795.png" alt="1581869344795"></p>
<p><img src="/2020/01/12/笔试知识点/1581869369324.png" alt="1581869369324"></p>
<hr>
<ul>
<li>写出a*(b-c*d)+e-f/g*(h+i*j-k)的逆波兰表达式。</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581869439352.png" alt="1581869439352"></p>
<p><a href="https://zh.wikipedia.org/wiki/%E9%80%86%E6%B3%A2%E5%85%B0%E8%A1%A8%E7%A4%BA%E6%B3%95" target="_blank" rel="noopener">逆波兰表达式</a></p>
<hr>
<ul>
<li>下列关于线性表，二叉平衡树，哈希表存储数据的优劣描述错误的是？</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581869526156.png" alt="1581869526156"></p>
<p>解析：<strong>在平衡二叉树中插入结点要随时保证插入后整棵二叉树是平衡的，所以可能需要通过一次或多次树旋转来重新平衡这个树</strong>。</p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581869693305.png" alt="1581869693305"></p>
<p><img src="/2020/01/12/笔试知识点/1581869715738.png" alt="1581869715738"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581869761466.png" alt="1581869761466"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581869840257.png" alt="1581869840257"></p>
<hr>
<ul>
<li>如果一个堆栈的入栈序列是A,B,C,D,E,则堆栈的不可能输出顺序是（）。</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581869901758.png" alt="1581869901758"></p>
<hr>
<ul>
<li>若以{4,5,6,7,8}作为叶子结点的权值构造哈夫曼树，则其带权路径长度是（）。</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581870076226.png" alt="1581870076226"></p>
<p>解析：</p>
<p><img src="https://uploadfiles.nowcoder.com/images/20161031/6306378_1477892872536_FB5C81ED3A220004B71069645F112867" alt="img"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1581870138420.png" alt="1581870138420"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581870210402.png" alt="1581870210402"></p>
<hr>
<ul>
<li>设某颗二叉树中有360个结点，则该二叉树的最小高度是？(包括根节点)</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1581870300117.png" alt="1581870300117"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1581870472998.png" alt="1581870472998"></p>
<hr>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><hr>
<ul>
<li><p>时间序列模型中，哪一个模型可以较好的拟合波动性的分析和预测 (D)</p>
<p>A. AR模型</p>
<p>B. MA模型</p>
<p>C. ARMA模型</p>
<p>D. GARCH模型</p>
</li>
</ul>
<p>解析：</p>
<p>参考 <a href="https://blog.csdn.net/s1491695565/article/details/52093003" target="_blank" rel="noopener">https://blog.csdn.net/s1491695565/article/details/52093003</a></p>
<p>时间序列中常用预测技术  一个时间序列是一组对于某一变量连续时间点或连续时段上的观测值。</p>
<p><strong>1.  移动平均法 (MA)</strong></p>
<p>1.1. 简单移动平均法</p>
<p>设有一时间序列y1,y2,…, 则按数据点的顺序逐点推移求出N个数的平均数，即可得到一次移动平均数.</p>
<p> 1.2 趋势移动平均法  </p>
<p>当时间序列没有明显的趋势变动时，使用一次移动平均就能够准确地反映实际情况，直接用第t周期的一次移动平均数就可预测第t+1周期之值。</p>
<p>时间序列出现线性变动趋势时，用一次移动平均数来预测就会出现滞后偏差。修正的方法是在一次移动平均的基础上再做二次移动平均，利用移动平均滞后偏差的规律找出曲线的发展方向和发展趋势，然后才建立直线趋势的预测模型。故称为趋势移动平均法。</p>
<p><strong>2.  自回归模型(AR)</strong></p>
<p>AR模型是一种线性预测，即已知N个数据，可由模型推出第N点前面或后面的数据（设推出P点）.</p>
<p>本质类似于插值，其目的都是为了增加有效数据，只是AR模型是由N点递推，而插值是由两点（或少数几点）去推导多点，所以AR模型要比插值方法效果更好。</p>
<p><strong>3. 自回归滑动平均模型(ARMA)</strong></p>
<p>其建模思想可概括为：逐渐增加模型的阶数，拟合较高阶模型，直到再增加模型的阶数而剩余残差方差不再显著减小为止。</p>
<p><strong>4. GARCH模型</strong></p>
<p>回归模型。除去和普通回归模型相同的之处，GARCH对误差的方差进行了进一步的建模。特别适用于波动性的分析和预测。</p>
<p><strong>4. 指数平滑法</strong></p>
<p>移动平均法的预测值实质上是以前观测值的加权和，且对不同时期的数据给予相同的加权。这往往不符合实际情况。</p>
<p>指数平滑法则对移动平均法进行了改进和发展，其应用较为广泛。</p>
<p>基本思想都是：预测值是以前观测值的加权和，且对不同的数据给予不同的权，新数据给较大的权，旧数据给较小的权。</p>
<p>根据平滑次数不同，指数平滑法分为：一次指数平滑法、二次指数平滑法和三次指数平滑法等。</p>
<hr>
<ul>
<li><p>下面对集成学习模型中的弱学习者描述错误的是 (C)</p>
<p>A. 他们经常不会过拟合</p>
<p>B. 他们通常带有高偏差，所以其并不能解决复杂学习问题</p>
<p>C. 他们通常会过拟合</p>
</li>
</ul>
<p>弱学习器：略优于随机猜测的学习器。（西瓜书）</p>
<hr>
<ul>
<li><p>xgboost对缺失值的处理方法：</p>
<p>把缺失值分别放到左叶子节点和右叶子节点中，计算增益。哪个增益大就放到哪个叶子节点。</p>
</li>
</ul>
<hr>
<ul>
<li>Hive四大表类型：<ul>
<li>内部表</li>
<li>外部表</li>
<li>分区表</li>
<li>桶表（或叫分桶表）</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li><p>能在O(1)时间内访问线性表的第i个元素的结构是 ( )</p>
<p><img src="/2020/01/12/笔试知识点/1582361004130.png" alt="1582361004130"></p>
</li>
</ul>
<p><img src="/2020/01/12/笔试知识点/1582360970415.png" alt="1582360970415"></p>
<hr>
<ul>
<li><p>只要数据元素保持有序，则查找时就可以采用折半查找方法 ( )</p>
<p><img src="/2020/01/12/笔试知识点/1582361114265.png" alt="1582361114265"></p>
</li>
</ul>
<hr>
<ul>
<li><p>一个长度为32的有序表，若采用二分查找一个不存在的元素，则比较次数最多是 ( )</p>
<p><img src="/2020/01/12/笔试知识点/1582361203067.png" alt="1582361203067"></p>
</li>
</ul>
<hr>
<ul>
<li><p>分块查找的基本思想是首先在索引表中进行查找，以便确定给定的关键字可能存在的块号，然后再在相应的块内进行顺序查找。( )</p>
<p><img src="/2020/01/12/笔试知识点/1582361360734.png" alt="1582361360734"></p>
</li>
</ul>
<hr>
<ul>
<li><p>下列说法中错误的是( )</p>
<p>A. 插入排序某些情况下复杂度为O(n)</p>
<p>B. 排序二叉树元素查找的复杂度可能为O(n)</p>
<p>C. 对于有序列表的排序最快的是快速排序</p>
<p>D. 在有序列表中通过二分查找的复杂度一定为O(logn)</p>
</li>
</ul>
<p>答案：C</p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582363721071.png" alt="1582363721071"></p>
<p>C选项应该为插入排序？</p>
<hr>
<ul>
<li><p>在长度为n的顺序线性表中顺序查找值为x的元素时，查找成功时的平均查找长度（假定查找每个元素的概率均相等）为（）</p>
<p><img src="/2020/01/12/笔试知识点/1582363882820.png" alt="1582363882820"></p>
</li>
</ul>
<hr>
<ul>
<li><p>折半查找与二元查找树的时间性能在最坏的情况下是相同的 ( )</p>
<p><img src="/2020/01/12/笔试知识点/1582363973719.png" alt="1582363973719"></p>
</li>
</ul>
<hr>
<ul>
<li><p>使用KMP算法在文本串S中找m模式串P是一种常见的方法。假设S=P={xyxyyxxyx}，亦即将S对自己进行匹配，匹配过程中正确的next数组是( )</p>
<p><img src="/2020/01/12/笔试知识点/1582364106629.png" alt="1582364106629"></p>
</li>
</ul>
<p>解析：参考 <a href="https://blog.csdn.net/qq_37969433/article/details/82947411" target="_blank" rel="noopener">https://blog.csdn.net/qq_37969433/article/details/82947411</a></p>
<p><img src="/2020/01/12/笔试知识点/1582364410421.png" alt="1582364410421"></p>
<hr>
<h5 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h5><p><span style="color:red">基选归堆不变（运行时间不发生变化，与初始状态无关）</span></p>
<p><span style="color:red">快选希堆不稳（是不稳定的排序） </span></p>
<ul>
<li><p>已给图，( )是该图的正确的拓扑排序序列</p>
<p>​    <img src="/2020/01/12/笔试知识点/1582371132616.png" alt="1582371132616"></p>
</li>
<li><p>在用邻接表表示图时，拓扑排序算法时间复杂度为( )</p>
<p><img src="/2020/01/12/笔试知识点/1582374420342.png" alt="1582374420342"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582374447488.png" alt="1582374447488"></p>
</li>
</ul>
<hr>
<ul>
<li><p>下面的排序方法中，关键字比较次数与记录的初始排序无关的是( )</p>
<p><img src="/2020/01/12/笔试知识点/1582371218204.png" alt="1582371218204"></p>
</li>
</ul>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582371246385.png" alt="1582371246385"></p>
<p><img src="https://qypx.github.io/2020/01/10/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/1578640411160.png" alt="1578640411160"></p>
<p><span style="color:red">基选归堆不变（运行时间不发生变化，与初始状态无关）</span></p>
<hr>
<ul>
<li><p>下列排序算法不稳定的有 ( )</p>
<p><img src="/2020/01/12/笔试知识点/1582372396395.png" alt="1582372396395"></p>
</li>
</ul>
<p><span style="color:red">快选希堆不稳（是不稳定的排序） </span></p>
<hr>
<ul>
<li><p>下列说法错误的是( )</p>
<p><img src="/2020/01/12/笔试知识点/1582372339161.png" alt="1582372339161"></p>
</li>
</ul>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582372667692.png" alt="1582372667692"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582372732725.png" alt="1582372732725"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582372932412.png" alt="1582372932412"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582372984413.png" alt="1582372984413"></p>
<p><img src="/2020/01/12/笔试知识点/1582373764364.png" alt="1582373764364"></p>
<p><img src="/2020/01/12/笔试知识点/1582373826092.png" alt="1582373826092"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582373868980.png" alt="1582373868980"></p>
<p>以下来源于百度百科：</p>
<p>基数排序：最低位优先(Least Significant Digit first)法，简称LSD法：</p>
<p><img src="/2020/01/12/笔试知识点/1582374257291.png" alt="1582374257291"></p>
<p><img src="/2020/01/12/笔试知识点/1582374278992.png" alt="1582374278992"></p>
<p><img src="/2020/01/12/笔试知识点/1582374296292.png" alt="1582374296292"></p>
<hr>
<ul>
<li><p>下列排序算法中，( ) 在某趟排序结束后不一定能选出一个元素放到其最终位置上</p>
<p><img src="/2020/01/12/笔试知识点/1582374591201.png" alt="1582374591201"></p>
</li>
</ul>
<p>解析：</p>
<p>选 择 排 序 (Selection sort)： 是 一 种 简 单 直 观 的 排 序 算 法 。 它 的 工 作 原 理 是 每 一 次 从 待 排 序 的 数 据 元 素 中 选 出 最 小 （ 或 最 大 ） 的 一 个元 素 ， 存 放 在 序 列 的 起 始 位 置 ， 直 到 全 部 待 排 序 的 数 据 元 素 排 完 ，所 以 每 一 趟 选 择 的 元 素 都 会 放 在 他 的 最 终 位 置 </p>
<p>冒 泡 排 序 ：它 重 复 地 走 访 过 要 排 序 的 数 列 ， 一 次 比 较 两 个 元 素 ， 如 果 他 们 的 顺 序 错 误 就 把 他 们 交 换 过 来 。 走 访 数 列 的 工 作 是 重 复 地 进 行 直 到 没 有 再 需 要 交 换 ， 也 就 是 说 该 数 列 已 经 排 序 完 成 。 比 如 按 照 升 序 排 序 则 每 一 趙 会 将 前 面 未 排 序 部 分 的 最 大 的 往 后 交 换 到 已 排 序 的 最 前 面 ， 为 其 最 终 位 置 </p>
<p>堆 排 序 ：如 果 要 求 升 序 则 建 立 大 根 堆 ， 降 序 则 建 立 小 根 堆 ， 堆 顶 元 素 为 最 大 或 者 最 小 的 元 素 ， 将 这 个 元 素 与 最 后 一 个 位 置 的 元 素 交 换 ， 再 将 剩 余 元 素 还 原 成 大 小 跟 堆 ， 每 一 趙 都 会 选 出 一 个 未 排 序 中 的 最 大 或 者 最 小 放 大 他 的 最 终 位 置 </p>
<p>希 尔 排 序： 由 于 是 按 照 增 量 排 序 ， 步 长 不 同 可 能 元 素 不 一 定 到 他 最 终 位 置 ， 所 以 选 C </p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582375139504.png" alt="1582375139504"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582381646518.png" alt="1582381646518"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582381694491.png" alt="1582381694491"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582381746786.png" alt="1582381746786"></p>
<hr>
<ul>
<li><p>下面( )排序算法在输入数据逆序情况下排序速度最快</p>
<p><img src="/2020/01/12/笔试知识点/1582381909114.png" alt="1582381909114"></p>
</li>
<li><p>对于基本有序的序列，按照哪种排序方式最快：</p>
<p><img src="/2020/01/12/笔试知识点/1582381995803.png" alt="1582381995803"></p>
</li>
</ul>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582382048981.png" alt="1582382048981"></p>
<hr>
<p><img src="/2020/01/12/笔试知识点/1582382128578.png" alt="1582382128578"></p>
<p>解析：</p>
<p><img src="/2020/01/12/笔试知识点/1582382202047.png" alt="1582382202047"></p>
<hr>]]></content>
      <categories>
        <category>笔试</category>
      </categories>
      <tags>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title>sql语言</title>
    <url>/2020/01/12/sql%E8%AF%AD%E8%A8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="DDL与DML"><a href="#DDL与DML" class="headerlink" title="DDL与DML"></a>DDL与DML</h3><p>DDL: maintaining structure of database. (CREATE, DROP, ALTER, RENAME)</p>
<p>DML: maintaining contents of database. (SELECT, INSERT, DELETE, UPDATE)</p>
<p><img src="/2020/01/12/sql语言/1578825616684.png" alt="1578825616684"></p>
<a id="more"></a>
<h5 id="INSERT"><a href="#INSERT" class="headerlink" title="INSERT"></a>INSERT</h5><p><img src="/2020/01/12/sql语言/1578900159995.png" alt="1578900159995"></p>
<blockquote>
<p>注：字符为单引号</p>
</blockquote>
<p><code>INSERT INTO tablename {column1,column2,…}values(exp1,exp2,…);</code>  //插入</p>
<h5 id="DELETE"><a href="#DELETE" class="headerlink" title="DELETE"></a>DELETE</h5><p><img src="/2020/01/12/sql语言/1578900315795.png" alt="1578900315795"></p>
<h5 id="UPDATE"><a href="#UPDATE" class="headerlink" title="UPDATE"></a>UPDATE</h5><p><img src="/2020/01/12/sql语言/1578900364614.png" alt="1578900364614"></p>
<h5 id="CREATE"><a href="#CREATE" class="headerlink" title="CREATE"></a>CREATE</h5><p><img src="/2020/01/12/sql语言/1578899962419.png" alt="1578899962419"></p>
<p><strong>CREATE的时候，先CREATE没有外键的表，最后CREATE右外键的表</strong></p>
<h5 id="DROP"><a href="#DROP" class="headerlink" title="DROP"></a>DROP</h5><p><img src="/2020/01/12/sql语言/1578900950689.png" alt="1578900950689"></p>
<p><strong>DROP的时候，先DROP有外键的表，最后DROP没有外键的表</strong></p>
<h5 id="ALTER"><a href="#ALTER" class="headerlink" title="ALTER"></a>ALTER</h5><p>例如增加一列</p>
<p><img src="/2020/01/12/sql语言/1578901179360.png" alt="1578901179360"></p>
<h5 id="RENAME"><a href="#RENAME" class="headerlink" title="RENAME"></a>RENAME</h5><p><img src="/2020/01/12/sql语言/1578901685944.png" alt="1578901685944"></p>
<h3 id="语法顺序与执行顺序"><a href="#语法顺序与执行顺序" class="headerlink" title="语法顺序与执行顺序"></a>语法顺序与执行顺序</h3><p><img src="/2020/01/12/sql语言/1578825674160.png" alt="1578825674160"></p>
<p><img src="/2020/01/12/sql语言/1578825736061.png" alt="1578825736061"></p>
<p>相当于就是 SELECT [DISTINCT] 的顺序换了一下。</p>
<h3 id="Aggregate-Functions"><a href="#Aggregate-Functions" class="headerlink" title="Aggregate Functions"></a>Aggregate Functions</h3><p><img src="/2020/01/12/sql语言/1596791792580.png" alt="1596791792580"></p>
<h3 id="操作符"><a href="#操作符" class="headerlink" title="操作符"></a>操作符</h3><p><img src="/2020/01/12/sql语言/1596791382343.png" alt="1596791382343"></p>
<h3 id="找最大值"><a href="#找最大值" class="headerlink" title="找最大值"></a>找最大值</h3><p><img src="/2020/01/12/sql语言/1596791476146.png" alt="1596791476146"></p>
<p>If two different items have highest price, 第一个query会把两个都返回，第二个query只会返回一个</p>
<p>例子：</p>
<p><a href="http://sqlfiddle.com/#!9/492887/22" target="_blank" rel="noopener">http://sqlfiddle.com/#!9/492887/22</a></p>
<p><img src="/2020/01/12/sql语言/1597394612354.png" alt="1597394612354"></p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> blockfloor <span class="keyword">as</span> <span class="string">"Floor"</span>,</span><br><span class="line">       <span class="keyword">count</span>(*) <span class="keyword">AS</span>  <span class="string">"No of available rooms"</span></span><br><span class="line"><span class="keyword">FROM</span> room</span><br><span class="line"><span class="keyword">WHERE</span> unavailable=<span class="string">'0'</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> blockfloor</span><br><span class="line"><span class="keyword">HAVING</span> <span class="keyword">count</span>(*) =</span><br><span class="line">  (<span class="keyword">SELECT</span> <span class="keyword">max</span>(zz) <span class="keyword">AS</span> highest_total</span><br><span class="line">   <span class="keyword">FROM</span></span><br><span class="line">     ( <span class="keyword">SELECT</span> blockfloor ,</span><br><span class="line">              <span class="keyword">count</span>(*) <span class="keyword">AS</span> zz</span><br><span class="line">      <span class="keyword">FROM</span> room</span><br><span class="line">      <span class="keyword">WHERE</span> unavailable=<span class="string">'0'</span></span><br><span class="line">      <span class="keyword">GROUP</span> <span class="keyword">BY</span> blockfloor ) <span class="keyword">AS</span> t );</span><br></pre></td></tr></table></figure>
<p>注：以下写法错误：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> BlockFloor, <span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> <span class="string">"maximum number of rooms available"</span></span><br><span class="line"><span class="keyword">FROM</span> Room</span><br><span class="line"><span class="keyword">WHERE</span> Unavailable=<span class="number">0</span></span><br><span class="line"><span class="keyword">GROUP</span> <span class="keyword">BY</span> BlockFloor</span><br><span class="line"><span class="keyword">HAVING</span> <span class="keyword">COUNT</span>(*) = </span><br><span class="line">	(<span class="keyword">SELECT</span> <span class="keyword">MAX</span>(<span class="keyword">COUNT</span>(*))</span><br><span class="line">	<span class="keyword">FROM</span> Room</span><br><span class="line">	<span class="keyword">WHERE</span> Unavailable = <span class="number">0</span></span><br><span class="line">	<span class="keyword">GROUP</span> <span class="keyword">BY</span> BlockFloor);</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/sql语言/1597394696134.png" alt="1597394696134"></p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title>sql语句中的drop, truncate, delete</title>
    <url>/2020/01/12/sql%E8%AF%AD%E5%8F%A5%E4%B8%AD%E7%9A%84drop-truncate-delete/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>参考：</p>
<p><a href="https://blog.csdn.net/lovezhaohaimig/article/details/80184994" target="_blank" rel="noopener">https://blog.csdn.net/lovezhaohaimig/article/details/80184994</a></p>
<p><a href="https://www.cnblogs.com/xianyao/p/11613021.html" target="_blank" rel="noopener">https://www.cnblogs.com/xianyao/p/11613021.html</a></p>
<ol>
<li><code>drop table 表名称</code></li>
</ol>
<p>作用：删除内容和定义，释放空间。简单来说就是把整个表去掉.以后要新增数据是不可能的,除非新增一个表。</p>
<p>把表的结构也删除了 下次要使用的时候要重新创建表的结构再插入数据。</p>
<p><strong>即删除表内容及表结构（或表定义）</strong>。</p>
<p><strong>不能回滚</strong></p>
<ol>
<li><code>truncate table 表名称</code></li>
</ol>
<p>作用：删除内容、释放空间但不删除定义。与drop不同的是,他只是清空表数据而已,不删除表结构。</p>
<p>truncate table test 后，向test表添加数据，id标识列连续了(体现了truncate删除是释放空间）</p>
<p>插入的字段的id重新从1开始递增 1、2、3…..<br><strong>即删除表内容，不删除表结构</strong>。</p>
<p><strong>in MySQL, resets auto_increment PKs</strong></p>
<p><strong>不能回滚</strong></p>
<ol>
<li><code>delete from 表名称 where 列名称 = 值</code></li>
</ol>
<p>作用：删除整表中的行，表结构不会删除。</p>
<p>删除内容不删除定义，不释放空间。</p>
<p>用delete删除数据，然后添加。可以看到添加之后id标识不连续。（说明delete删除不释放空间）</p>
<p>如果重新插入数据时对应的id在上次基础之上递增 4、5、6….</p>
<p>delete语句执行删除的过程是每次从表中删除一行，并且同时将该行的删除操作作为事务记录在日志中保存,以便进行回滚操作。</p>
<p><strong>即不带where的delete: 删除表内容，不删除表结构</strong></p>
<p><strong>可回滚</strong></p>
<ul>
<li><p>执行速度，一般来说: drop&gt; truncate &gt; delete。</p>
</li>
<li><p>delete语句是数据库操作语言(dml)，这个操作会放到 rollback segment中，事务提交之后才生效；如果有相应的 trigger，执行的时候将被触发。</p>
</li>
<li><p>truncate、drop 是数据库定义语言(ddl)，操作立即生效，原数据不放到 rollback segment 中，不能回滚，操作不触发 trigger。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title>两数之和</title>
    <url>/2020/01/12/%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/two-sum/" target="_blank" rel="noopener">两数之和（难度：简单）</a></p>
<p><img src="/2020/01/12/两数之和/1578808347100.png" alt="1578808347100"></p>
<h4 id="方法一：暴力法"><a href="#方法一：暴力法" class="headerlink" title="方法一：暴力法"></a>方法一：暴力法</h4><p>遍历每个元素 x，并查找是否存在一个值与 target - x相等的目标元素。\</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt; nums.length; j++) &#123;</span><br><span class="line">                <span class="keyword">if</span> (nums[j] == target - nums[i]) &#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; i, j &#125;;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"No two sum solution"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n^2)</p>
<p>空间复杂度：O(1)</p>
<hr>
<h4 id="方法二：两遍哈希表"><a href="#方法二：两遍哈希表" class="headerlink" title="方法二：两遍哈希表"></a>方法二：两遍哈希表</h4><p>为了对运行时间复杂度进行优化，我们需要一种更有效的方法来检查数组中是否存在目标元素。如果存在，我们需要找出它的索引。保持数组中的每个元素与其索引相互对应的最好方法是什么？哈希表。</p>
<p>通过以空间换取速度的方式，我们可以将查找时间从 O(n)降低到 O(1)。<strong>哈希表正是为此目的而构建的，它支持以 近似恒定的时间进行快速查找</strong>。我用“近似”来描述，是因为一旦出现冲突，查找用时可能会退化到 O(n)。但只要你仔细地挑选哈希函数，在哈希表中进行查找的用时应当被摊销为 O(1)。</p>
<p><strong>使用两次迭代。在第一次迭代中，我们将每个元素的值和它的索引添加到表中。然后，在第二次迭代中，我们将检查每个元素所对应的目标元素（target - nums[i]）是否存在于表中。</strong>注意，该目标元素不能是 nums[i]本身！</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            map.put(nums[i], i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> complement = target - nums[i];</span><br><span class="line">            <span class="keyword">if</span> (map.containsKey(complement) &amp;&amp; map.get(complement) != i) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123; i, map.get(complement) &#125;;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"No two sum solution"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)，遍历两次，由于哈希表将查找时间缩短到 O(1) ，所以时间复杂度为 O(n)。</p>
<p>空间复杂度：O(n)，所需的额外空间取决于哈希表中存储的元素数量。</p>
<hr>
<h4 id="方法三：一遍哈希表"><a href="#方法三：一遍哈希表" class="headerlink" title="方法三：一遍哈希表"></a>方法三：一遍哈希表</h4><p>在进行迭代并将元素插入到表中的同时，回过头来检查表中是否已经存在当前元素所对应的目标元素。如果它存在，那我们已经找到了对应解，并立即将其返回。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span>(map.containsKey(target - nums[i]))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;map.get(target - nums[i]), i&#125;;</span><br><span class="line">            map.put(nums[i],i);</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[] &#123;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度-2"><a href="#复杂度-2" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)，只遍历一次。</p>
<p>空间复杂度：O(n)。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>哈希表</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>最长连续递增序列</title>
    <url>/2020/01/12/%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E9%80%92%E5%A2%9E%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-continuous-increasing-subsequence/" target="_blank" rel="noopener">最长连续递增序列（难度：简单）</a></p>
<p><img src="/2020/01/12/最长连续递增序列/1578807734778.png" alt="1578807734778"></p>
<p><img src="/2020/01/12/最长连续递增序列/1578807775519.png" alt="1578807775519"></p>
<p><strong>代码</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findLengthOfLCIS</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length&lt;=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> nums.length;</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> max = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; nums[i-<span class="number">1</span>])&#123;</span><br><span class="line">                count++;</span><br><span class="line">                max = Math.max(max,count);</span><br><span class="line">            &#125; <span class="keyword">else</span></span><br><span class="line">                count=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> max;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/最长连续递增序列/1578807884555.png" alt="1578807884555"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>排序算法</title>
    <url>/2020/01/10/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/2020/01/10/排序算法/1578640411160.png" alt="1578640411160"></p>
<p>排序算法的稳定性，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj，Ai原来在位置前，排序后Ai还是要在Aj位置前。</p>
<p><span style="color:red">* 基选归堆不变（运行时间不发生变化，与初始状态无关）</span></p>
<p><span style="color:red">* 快选希堆不稳（是不稳定的排序） </span></p>
<p><u>快 速 排 序 ：</u> </p>
<p>思 想 ： </p>
<p>1 ． 在 待 排 序 的 元 素 任 取 一 个 元 素 作 为 基 准 （ 通 常 选 第 一 个 元 素 ， 但 最 的 选 择 方 法 是 从 待 排 序 元 素 中 随 机 选 取 一 个 作 为 基 准 ） ， 称 为 基 准 元 素 ； </p>
<p>2 ． 将 待 排 序 的 元 素 进 行 分 区 ， 比 基 准 元 素 大 的 元 素 放 在 它 的 右 边 ， 比 其 小 的 放 在 它 的 左 边 ； </p>
<p>3 ． 对 左 右 两 个 分 区 重 复 以 上 步 骤 直 到 所 有 元 素 都 是 有 序 的 </p>
<p> <u>冒 泡 排 序 ：</u> </p>
<p>1 ． 比 较 相 邻 的 元 素 。 如 果 第 一 个 比 第 二 个 大 ， 就 交 换 他 们 两 个 </p>
<p>2 ． 对 每 一 对 相 邻 元 素 作 同 样 的 工 作 ， 从 开 始 第 一 对 到 结 尾 的 最 后 一 对 。 在 这 一 点 ， 最 后 的 元 素 应 该 会 是 最 大 的 数 。 </p>
<p>3 ． 针 对 所 有 的 元 素 重 复 以 上 的 步 骤 ， 除 了 最 后 一 个 </p>
<p>4 ． 持 续 每 次 对 越 来 越 少 的 元 素 重 复 上 面 的 步 骤 ， 直 到 没 有 任 何 一 对 数 字 需 要 比 较 。 </p>
<p><u>归 并 排 序 ：</u> </p>
<p>第 一 步 ： 申 请 空 间 ， 使 其 大 小 为 两 个 已 经 排 序 序 列 之 和 ， 该 空 间 用 来 存 放 合 并 后 的 序 列 </p>
<p>第 二 步 ： 设 定 两 个 指 针 ， 最 初 位 置 分 别 为 两 个 已 经 排 序 序 列 的 起 始 位 置 </p>
<p>第 三 步 ： 比 较 两 个 指 针 所 指 向 的 元 素 ， 选 择 相 对 小 的 元 素 放 入 到 合 并 空 </p>
<p>间 ， 并 移 动 指 针 到 下 一 位 置 </p>
<p>重 复 步 骤 3 直 到 某 一 指 针 超 出 序 列 尾 </p>
<p>将 另 一 序 列 剩 下 的 所 有 元 素 直 接 复 制 到 合 并 序 列 尾 </p>
<p><u>插 入 排 序 ：</u> </p>
<p>1 ． 从 有 序 数 列 和 无 序 数 列 { a2 ， a3 ,  …, an} 开 始 进 行 排 序 </p>
<p>2 ． 处 理 第 i 个 元 素 时 { i ： 2 ， 3 ，… , n } , 数 列 { a1 ， a2 ，…， ai-1} 是 已 有 序 的 ， 而 数 列 {ai,ai+1, …， an } 是 无 序 的 。 用 ai 与 ai-1, a i-2, …， a1 进 行 比 较 ， 找 出 合 适 的 位 置 将 ai 插 入 ； </p>
<p>3 ． 重 复 第 二 步 ， 共 进 行 n - i 次 插 入 处 理 ， 数 列 全 部 有 序 。 </p>
<p><u>选 择 排 序 (Selection sort)：</u></p>
<p>是 一 种 简 单 直 观 的 排 序 算 法 。 它 的 工 作 原 理 是 每 一 次 从 待 排 序 的 数 据 元 素 中 选 出 最 小 （ 或 最 大 ） 的 一 个元 素 ， 存 放 在 序 列 的 起 始 位 置 ， 直 到 全 部 待 排 序 的 数 据 元 素 排 完 ，所 以 每 一 趟 选 择 的 元 素 都 会 放 在 他 的 最 终 位 置 </p>
<p>第 i 趟排序，找到L[i…n]中最小的元素与L[i]交换位置，这样保证每一趟排序确定一个元素的最终位置</p>
<p><u>堆 排 序 ：</u></p>
<p>如 果 要 求 升 序 则 建 立 大 根 堆 ， 降 序 则 建 立 小 根 堆 ， 堆 顶 元 素 为 最 大 或 者 最 小 的 元 素 ， 将 这 个 元 素 与 最 后 一 个 位 置 的 元 素 交 换 ， 再 将 剩 余 元 素 还 原 成 大 小 跟 堆 ， 每 一 趙 都 会 选 出 一 个 未 排 序 中 的 最 大 或 者 最 小 放 大 他 的 最 终 位 置 </p>
<p><u>希 尔 排 序 (shell’s sort)：</u> </p>
<p>希尔排序(Shell’s Sort)是<a href="https://baike.baidu.com/item/插入排序/7214992" target="_blank" rel="noopener">插入排序</a>的一种，又称“缩小增量排序”（Diminishing Increment Sort），是直接插入<a href="https://baike.baidu.com/item/排序算法/5399605" target="_blank" rel="noopener">排序算法</a>的一种更高效的改进版本。希尔排序是非稳定排序算法。</p>
<p>希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，<a href="https://baike.baidu.com/item/算法/209025" target="_blank" rel="noopener">算法</a>便终止。</p>
<p>由 于 是 按 照 增 量 排 序 ， 步 长 不 同 可 能 元 素 不 一 定 到 他 最 终 位 置 </p>
]]></content>
      <tags>
        <tag>知识点</tag>
      </tags>
  </entry>
  <entry>
    <title>Matrix Factorization Methods</title>
    <url>/2020/01/09/Matrix-Factorization-Methods/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Collaborative Filtering has been criticized as having limited scalability, since computing similarity matrices on very large sets of items or users can take a lot of computing horsepower. I don’t really buy this, however. Technologies such as Apache Spark allow you to distribute the construction of this matrix across a cluster if you need to. <strong>A legitimate problem with collaborative filtering is that it’s sensitive to noisy data and sparse data. You’ll only get really good results if you have a large data set to work with that’s nice and clean. </strong></p>
<p>接下来介绍一些<strong>Model-based methods</strong>. Instead of 寻找相似的物品或相似的用户, we apply data science and machine learning techniques to extract predictions from our ratings data.</p>
<p><img src="/2020/01/09/Matrix-Factorization-Methods/1578547347570.png" alt="1578547347570"></p>
<p>There are a wide variety of techniques that fall under the category of matrix factorization. They managed to find broader features of users and items on their own, like action movies or romantic. They are described by matrices. The general idea is to describe users and movies as combinations of different amounts of each feature. For example, Bob is defined as being 80% an action fan and 20% a comedy fan. We’d then know to match him up with movies that are blend about 80% action and 20% comedy. </p>
<p><img src="/2020/01/09/Matrix-Factorization-Methods/1578559424817.png" alt="1578559424817"></p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>Neighborhood-Based Collaborative Filtering 协同过滤</title>
    <url>/2020/01/07/Neighborhood-Based-Collaborative-Filtering/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>This is the idea of leveraging the behavior of others to inform what you might enjoy. At a very high level, it means finding other people like you and recommending stuff they liked. Or it might mean finding other things similar to the thing that you like. </p>
<p>That’s why we call it collaborative filtering. It’s recommending stuff based on other people’s collaborative behavior. </p>
<p>The heart of neighborhood-based collaborative filtering is the ability to find people similar to you, or items similar to items you’ve liked.</p>
<h3 id="1-Measuring-Similarity-and-Sparsity"><a href="#1-Measuring-Similarity-and-Sparsity" class="headerlink" title="1. Measuring Similarity, and Sparsity"></a>1. Measuring Similarity, and Sparsity</h3><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578372382962.png" alt="1578372382962"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578372454415.png" alt="1578372454415"></p>
<p>这里的余弦相似度和前面content-based中的余弦相似度的区别在于：Our dimensions would be things like his: Did this user like this thing? Or was this thing liked by this user? So every user or every thing might constitute its own dimension, and the dimensions are based on user behavior instead of content attributes.</p>
<p>The big challenge in measuring these similarities based on behavior data is the <strong>sparsity</strong> of the data we’re working with. This means that it’s tough for collaborative filtering to work well unless you have a lot of user behavior data to work with. You can’t compute a meaningful cosine similarity between two people when they have nothing in common, or between two items when they have no people in common. </p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578373973291.png" alt="1578373973291"></p>
<p>This is why collaborative filtering works well for big companies like Amazon and Netflix. They have millions of users and so they have enough data to generate meaningful relations in spite of the data sparsity. </p>
<p>Sparsity also introduces some computational challenges. You don’t want to waste time storing and processing all of that missing data, so under the hood we end up using structures like <strong>sparse arrays</strong> that avoid storing all that empty spaces in this matrix. </p>
<h3 id="2-Similarity-Metrics"><a href="#2-Similarity-Metrics" class="headerlink" title="2. Similarity Metrics"></a>2. Similarity Metrics</h3><h4 id="Adjusted-Cosine"><a href="#Adjusted-Cosine" class="headerlink" title="Adjusted Cosine"></a>Adjusted Cosine</h4><p>It’s applicable mostly to measuring the similarity between users based on their ratings. It’s based on the idea that different people might have different baselines. What Bob considers a three star movie, maybe different from what Alice considers a three star movie. </p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578374644148.png" alt="1578374644148"></p>
<p>Adjusted cosine attempts to normalize these differences. Instead of measuring similarities between people based on their raw rating values, we instead measure similarities based on the difference between a user’s rating for an item and their average rating for all items. </p>
<p>Now this sounds good on paper, but in practice, data sparsity can really mess you up here. You can only get a meaningful average, or a baseline of an individual’s ratings if they have rated a lot of stuff for you to take the average of in the first place. 若有许多用户只评价了一部电影，then that data will be totally wasted with the adjusted cosine metric. 不管他们评了多少分，the difference between it and that user’s mean will be zero at that point. </p>
<p>So, adjusted cosine might be worth experimenting with, but only if you know that most of your users have rated a lot of stuff implicitly or explicitly. And if you have that much data to begin with, these differences between individuals will start to work themselves out anyway. So, you’re not likely to see as much of a difference as you might expect when using adjusted cosine. </p>
<h4 id="item-based-pearson-similarity"><a href="#item-based-pearson-similarity" class="headerlink" title="(item-based) pearson similarity"></a>(item-based) pearson similarity</h4><p>与adjusted cosine的区别在于, we look at the difference between rating and the average from all users for that given item.  </p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578376440604.png" alt="1578376440604"></p>
<p>You can think of pearson similarity as measuring the similarity between people by how much they diverge from the average person’s behavior. 例如，假设大多数人都喜欢Star Wars, people who hate Star Wars are going to get a very strong similarity score from pearson similarity, because they share opinions that are not mainstream.</p>
<p>Note that the only difference between this and adjusted cosine is whether we’re talking about users or items. 这门课使用的suprise library, refers to adjusted cosine as user-based pearson similarity, because it’s basically the same thing.</p>
<h4 id="spearman-rank-correlation"><a href="#spearman-rank-correlation" class="headerlink" title="spearman rank correlation"></a>spearman rank correlation</h4><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578376851254.png" alt="1578376851254"></p>
<ul>
<li>Instead of using an average rating value for a movie, 我们使用 its rank amongst all movies based on their average rating. </li>
<li>Instead of individual ratings for a movie, we’d rank that movie amongst all that individual’s ratings. </li>
</ul>
<p>Spearman的主要优势在于 it can deal with ordinal data effectively. 例如，if you had a rating scale, where the difference in meaning between different rating values were not the same. I’ve never seen this actually used in real world applications, but you may encounter it in the academic literature.</p>
<h4 id="mean-squared-difference"><a href="#mean-squared-difference" class="headerlink" title="mean squared difference"></a>mean squared difference</h4><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578377776225.png" alt="1578377776225"></p>
<p>另一方面，我们可以将它应用到item上：x和y指两个不同的item, and then we’d be looking at the differences in ratings from the people these items have in common (所有评价过这两个item的人对这两个item评分的差异).</p>
<p>There are two ways of doing collaborative filtering, item based and user based, and it’s important to remember that most of these similarity metrics can apply to either approach. </p>
<p>MSD 要比余弦相似度更好理解， 但 in practice, 你通常会发现cosine works better.</p>
<h4 id="jaccard-similarity"><a href="#jaccard-similarity" class="headerlink" title="jaccard similarity"></a>jaccard similarity</h4><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578385168727.png" alt="1578385168727"></p>
<p>jaccard similarity 没有使用实际的rating vlaue. If you are dealing with implicit ratings, for example, just the fact that somebody watched something, in this case, Jaccard can be a reasonable choice that’s very fast to compute. </p>
<h4 id="Recap"><a href="#Recap" class="headerlink" title="Recap"></a>Recap</h4><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578385386398.png" alt="1578385386398"></p>
<ul>
<li>Cosine similarity is almost always a reasonable thing to start with.</li>
<li>Adjust cosine and Pearson are two different terms for basically the same thing. It’s mean centered cosine similarities. The idea is to deal with unusual rating behavior that deviates from the mean, but in practice, it can sometimes do more harm than good.</li>
<li>Spearman ranking correlation is the same idea as Pearson, using ranking instead of raw ratings, and it’s not something you are likely to be using in practice.</li>
<li>MSD is mean squared difference, which is just an easier similarity metric to warp your head around than cosine similarity, but in practice, it usually doesn’t perform better.</li>
<li>Jaccard similarity is just looking at how many items two users have in common, or how many users two items have in common, divided by how many items or users they have between both of them. It’s really simple and well suited to implicit ratings, like binary actions, like purchasing or view something. But you can also apply cosine similarities to implicit ratings too.</li>
<li>So, and the end of the day, cosine similarity remains my default go to similarity metric. </li>
</ul>
<h3 id="3-协同过滤"><a href="#3-协同过滤" class="headerlink" title="3. 协同过滤"></a>3. 协同过滤</h3><h4 id="3-1-User-based-Collaborative-Filtering-基于用户的协同过滤-UserCF"><a href="#3-1-User-based-Collaborative-Filtering-基于用户的协同过滤-UserCF" class="headerlink" title="3.1 User-based Collaborative Filtering 基于用户的协同过滤(UserCF)"></a>3.1 User-based Collaborative Filtering 基于用户的协同过滤(UserCF)</h4><p>与基于物品的协同过滤类似的，不同的是，基于物品的协同过滤的原理是用户 U 购买了 A 物品，推荐给用户 U 和 A 相似的物品 B、C、D。而基于用户的协同过滤，是先计算用户 U 与其他的用户的相似度，然后取和 U 最相似的几个用户，把他们购买过的物品推荐给用户U。</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578386125836.png" alt="1578386125836"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578386158223.png" alt="1578386158223"></p>
<hr>
<h5 id="3-1-1-计算用户之间的相似度"><a href="#3-1-1-计算用户之间的相似度" class="headerlink" title="3.1.1 计算用户之间的相似度"></a>3.1.1 计算用户之间的相似度</h5><p>参考 <a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
<p>为了计算用户相似度，我们首先要把用户购买过物品的索引数据转化成物品被用户购买过的索引数据，即物品的倒排索引：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1596012706765.png" alt="1596012706765"></p>
<p>建立好物品的倒排索引后，就可以根据相似度公式计算用户之间的相似度：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1596012763141.png" alt="1596012763141"></p>
<p>其中 $N(a)$ 表示用户 $a$ 购买物品的数量，$N(b)$ 表示用户 $b$ 购买物品的数量，$N(a)∩N(b)$ 表示用户 $a$ 和 $b$ 购买相同物品的数量。有了用户的相似数据，针对用户 U 挑选 k 个最相似的用户，把他们购买过的物品中，U 未购买过的物品推荐给用户 U 即可。</p>
<hr>
<h5 id="3-1-2-举例"><a href="#3-1-2-举例" class="headerlink" title="3.1.2 举例"></a>3.1.2 举例</h5><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578455133171.png" alt="1578455133171"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578455288882.png" alt="1578455288882"></p>
<ul>
<li>每个人和自己的余弦相似度是1</li>
<li>Bob 和 Ted的余弦相似度是0，因为他们没有评价过相同的电影</li>
<li>矩阵的上三角部分和下三角部分是对称的</li>
<li>对于 Bob 和 Ann, 虽然他们评价过不同的电影，当我们考虑相似度时，我们只看他们共同评价过的电影。在这个例子中，他们共同评价过的电影只有一部，并且评分都为5，所以他们的相似度得分为1 (100%)。</li>
</ul>
<blockquote>
<p>注：两个用户的相似度为100%并不一定代表他们喜欢相同的东西，也可以代表他们都讨厌相同的东西（例如，若 Bob 和 Ann 都给Star Wars打1分，他们仍然是100% similar）。事实上，the math behind cosine similarity works out such that <strong>if you only have one movie in common, you end up with 100% similarity no matter what. </strong>Even if Bob loved Star Wars and Ann hated it, in a sparse data situation, they both end up 100% similar. Sparse data is a huge problem with collaborative filtering, and it can lead to weird results. And sometimes, you need to enforce a minimum threshold on how many movies users have in common before you consider them at all.</p>
</blockquote>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578456962753.png" alt="1578456962753"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578457107702.png" alt="1578457107702"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578457502291.png" alt="1578457502291"></p>
<p>除了normalizing, 还可以例如将评分为1、2的转换成negative score, 方法不唯一，没有标准的方法，可通过试验看 what works best for the data you have.</p>
<p>应该adding in the score for a given movie if we encounter it more than once.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578457620591.png" alt="1578457620591"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578457759908.png" alt="1578457759908"></p>
<h5 id="3-1-3-Recap"><a href="#3-1-3-Recap" class="headerlink" title="3.1.3 Recap"></a>3.1.3 Recap</h5><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578457999015.png" alt="1578457999015"></p>
<h5 id="3-1-4-User-based-Collaborative-Filtering-Hands-On"><a href="#3-1-4-User-based-Collaborative-Filtering-Hands-On" class="headerlink" title="3.1.4 User-based Collaborative Filtering, Hands-On"></a>3.1.4 User-based Collaborative Filtering, Hands-On</h5><p>code walkthrough</p>
<p>CollaborativeFiltering文件夹里的：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578458631113.png" alt="1578458631113"></p>
<p>运行SimpleUserCF.py</p>
<h4 id="3-2-Item-based-Collaborative-Filtering-基于物品的协同过滤-ItemCF"><a href="#3-2-Item-based-Collaborative-Filtering-基于物品的协同过滤-ItemCF" class="headerlink" title="3.2 Item-based Collaborative Filtering 基于物品的协同过滤(ItemCF)"></a>3.2 Item-based Collaborative Filtering 基于物品的协同过滤(ItemCF)</h4><p>Look at the things you liked, and recommend stuff that’s similar to those things. </p>
<p>核心思想：给用户推荐那些和他们之前喜欢的物品相似的物品。</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578458842316.png" alt="1578458842316"></p>
<p>一些原因为什么使用物品之间的相似度可能比使用用户之间的相似度更好：</p>
<ul>
<li>Items tend to be of a more permanent nature than people. An individual’s test may change very quickly over the span of their lives. Your math book will always be similar to other math books. As such, you can get away with computing an item similarity matrix less often than user similarities, because it won’t change very quickly.</li>
<li>You usually have far fewer items to deal with than people. There are way more people than there are things to recommend to them in most cases. 即物品相似度矩阵会比用户相似度矩阵会小很多，这样不仅 make it simpler to store that matrix, it makes faster to compute as well. And when you’re dealing with massive systems like Amazon and Netflix, computational efficiency is very important. Not only does it require fewer resources, it means you can regenerate your similarities between items more often, making your system more responsive when new items are introduced.</li>
<li>使用 item similarities also makes for a better experience for new users. 一个新用户只要表现出了对某个物品的兴趣，你可以推荐与那个物品相似的物品给该用户，而使用基于用户的协同过滤，you wouldn’t have any recommendations for a new user at all until they make it into the next build of your user similarity matrix.</li>
</ul>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578463648320.png" alt="1578463648320"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578463881122.png" alt="1578463881122"></p>
<p>在这个例子中，所有的相似度都为0或1，是因为数据量比较小。In the real world, you’d see more interesting and meaningful numbers here.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578464579773.png" alt="1578464579773"></p>
<hr>
<h5 id="3-2-1-计算物品相似度的方法"><a href="#3-2-1-计算物品相似度的方法" class="headerlink" title="3.2.1 计算物品相似度的方法"></a>3.2.1 计算物品相似度的方法</h5><p>参考 <a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
<p>基于物品的协同过滤算法首先计算物品之间的相似度， 计算相似度的方法有以下几种：</p>
<p><strong>1. 基于共同喜欢物品的用户列表计算</strong></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1596011528508.png" alt="1596011528508"></p>
<p>在此，分母中 $N(i)$ 是购买物品 $i$ 的用户数，$N(j)$ 是购买物品 $j$ 的用户数，而分子 $N(i)∩N(j)$是同时购买物品 $i$ 和物品 $j$ 的用户数。可见上述的公式的核心是计算同时购买这件商品的人数比例 。当同时购买这两个物品的人数越多，他们的相似度也就越高。另外值得注意的是，在分母中我们用了物品总购买人数做惩罚，也就是说某个物品可能很热门，导致它经常会被和其他物品一起购买，所以除以它的总购买人数，来降低它和其他物品的相似分数。</p>
<p><strong>2. 基于余弦的相似度计算</strong></p>
<p>上面的方法计算物品相似度是直接计算同时购买这两个物品的人数。但是也可能存在用户购买了但不喜欢的情况，所以如果数据集包含了具体的<strong>评分数据</strong>，我们可以进一步把用户评分引入到相似度计算中 。</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1596011935928.png" alt="1596011935928"></p>
<p>其中 $n_{ki}$ 是用户 $k$ 对物品 $i$ 的评分，如果没有评分则为 0。</p>
<p><strong>3. 热门物品的惩罚</strong></p>
<p>对于热门物品的问题，可以用如下公式解决：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1596012034088.png" alt="1596012034088"></p>
<p>当 $\alpha ∈ (0，0.5)$时，$N(i)$ 越小，惩罚得越厉害，从而会使热门物品相关性分数下降。</p>
<hr>
<h5 id="3-2-2-Item-based-Collaborative-Filtering-Hands-On"><a href="#3-2-2-Item-based-Collaborative-Filtering-Hands-On" class="headerlink" title="3.2.2 Item-based Collaborative Filtering, Hands-On"></a>3.2.2 Item-based Collaborative Filtering, Hands-On</h5><p>code walkthrough</p>
<p>CollaborativeFiltering文件夹里的：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578458631113.png" alt="1578458631113"></p>
<p>运行SimpleItemCF.py</p>
<p>Item-based collaborative filtering is what Amazon used with outstanding success.</p>
<p>You need to test it out on several real people if possible, and then move to a large scale A/B test to see if this algorithm really is better or worse than whatever you might have today.</p>
<hr>
<h4 id="3-3-矩阵分解"><a href="#3-3-矩阵分解" class="headerlink" title="3.3 矩阵分解"></a>3.3 矩阵分解</h4><p>参考 <a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
<p>上述计算会得到一个相似度矩阵，而这个矩阵的大小和维度都是很大的，需要进行降维处理，用到的是SVD的降维方法，具体可以参考：<a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Machine Learning/8. ML特征工程和优化方法#25-降维方法" target="_blank" rel="noopener">降维方法</a></p>
<p><strong>基于稀疏自编码的矩阵分解</strong></p>
<p>矩阵分解技术在推荐领域的应用比较成熟，但是通过上一节的介绍，我们不难发现矩阵分解本质上只通过一次分解来对原矩阵进行逼近，特征挖掘的层次不够深入。另外矩阵分解也没有运用到物品本身的内容特征，例如书本的类别分类、音乐的流派分类等。随着神经网络技术的兴起，笔者发现通过多层感知机，可以得到更加深度的特征表示，并且可以对内容分类特征加以应用。首先，我们介绍一下稀疏自编码神经网络的设计思路。</p>
<ol>
<li><p><strong>基础的自编码结构</strong></p>
<p>最简单的自编码结构如下图，构造个三层的神经网络，我们让输出层等于输入层，且中间层的维度远低于输入层和输出层，这样就得到了第一层的特征压缩。</p>
<p><img src="https://camo.githubusercontent.com/c056188f3498f28ff6bfe618b81642ba7711a797/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31332d32342d34382e706e67" alt="img"></p>
<p>简单来说自编码神经网络尝试学习<strong>中间层约等于输入层</strong>的函数。换句话说，它尝试逼近一个恒等函数。如果网络的输入数据是完全随机的，比如每一个输入都是一个跟其他特征完全无关的独立同分布高斯随机变 ，那么这一压缩表示将会非常难于学习。但是如果输入数据中隐含着 些特定的结构，比如某些输入特征是彼此相关的，那么这一算法就可以发现输入数据中的这些相关性。</p>
</li>
<li><p><strong>多层结构</strong></p>
<p>基于以上的单层隐藏层的网络结构，我们可以扩展至多层网络结构，学习到更高层次的抽象特征。</p>
<p><img src="https://camo.githubusercontent.com/77fdc47c74a72f3b3c1b57ab29ec08452697eb42/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31332d33362d35312e6a7067" alt="img"></p>
</li>
</ol>
<hr>
<h3 id="4-Exercise"><a href="#4-Exercise" class="headerlink" title="4. Exercise"></a>4. Exercise</h3><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578468263883.png" alt="1578468263883"></p>
<p>我们之前是选取的top-n，例如item-based: 选择用户评价前10的电影，再找similar items；user-based: 选择与用户相似度排前10的用户，再…</p>
<p>Maybe it would be better if instead of taking the top k sources for recommendation candidates, we just use any source above some given quality threshold. 例如，用户评价4星以上的电影 should generate item-based recommendation candidates, no matter how many or how few of them there may be.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578468513742.png" alt="1578468513742"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578468541742.png" alt="1578468541742"></p>
<p>可以发现一个小的改变可以使得结果很不一样。Often, you don’t just want to test different recommendation algorithms, you want to test different variations and parameters on those algorithms. In this case, I not only want to test the idea of using a threshold instead of a top k approach, I’d also want to test many different threshold values to find the best one. In the real world, you’ll find that your biggest problem is just not having enough time to run all of the different experiments you want to run to make your recommendations  better. </p>
<h3 id="5-Evaluating-Collaborative-Filtering-Systems-Offline"><a href="#5-Evaluating-Collaborative-Filtering-Systems-Offline" class="headerlink" title="5. Evaluating Collaborative Filtering Systems Offline"></a>5. Evaluating Collaborative Filtering Systems Offline</h3><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578469111053.png" alt="1578469111053"></p>
<p>Now, although <strong>we can’t measure accuracy with user based or item based collaborative filtering, because they don’t make rating predictions</strong>, we can still measure hit rate, because it is still a top-N recommender.</p>
<h4 id="code-walkthrough"><a href="#code-walkthrough" class="headerlink" title="code walkthrough"></a>code walkthrough</h4><p>CollaborativeFiltering文件夹里的：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578458631113.png" alt="1578458631113"></p>
<p>运行EvaluateUserCF.py</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578469413099.png" alt="1578469413099"></p>
<p>That was surprisingly fast. One really nice property of collaborative filtering is how quickly it can generate recommendations for any given individual, once we’ve built up the similarity matrix.</p>
<p>结果5.5% is pretty good.</p>
<h4 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h4><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578469688733.png" alt="1578469688733"></p>
<p>与EvaluateUserCF.py相比需要改变的地方：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578470341309.png" alt="1578470341309"></p>
<p>item-based的hit rate只有0.5%，相比user-based的5.5%，要差一点。</p>
<p>Item-based should be a superior approach, and that’s been proven in industry. 这里item-based要差一点应该是数据的原因。而且这只是offline evaluation. If we were to test both algorithms on real-world people using real-world data in an A/B test, the results could end up being very different.</p>
<h3 id="6-KNN-Recommenders"><a href="#6-KNN-Recommenders" class="headerlink" title="6. KNN Recommenders"></a>6. KNN Recommenders</h3><p>The concept of collaborative filtering has been applied to recommender systems that do make rating predictions, and these are generally referred to in the literature as KNN recommenders.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578471356190.png" alt="1578471356190"></p>
<p>In this sort of system, we generate recommendation candidates by predicting the ratings of everything a user hasn’t already rated, and selecting the top k items with the highest predicted ratings. This obviously isn’t a terribly efficient approach, but since we’re predicting rating values, we can measure the offline accuracy of the system using train/test or cross-validation, which is useful in the research world.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578478326957.png" alt="1578478326957"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578479201990.png" alt="1578479201990"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578479315924.png" alt="1578479315924"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578479574982.png" alt="1578479574982"></p>
<h4 id="Running-User-and-Item-based-KNN-on-MovieLens"><a href="#Running-User-and-Item-based-KNN-on-MovieLens" class="headerlink" title="Running User and Item-based KNN on MovieLens"></a>Running User and Item-based KNN on MovieLens</h4><p>code walkthrough</p>
<p>CollaborativeFiltering文件夹里的：</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578458631113.png" alt="1578458631113"></p>
<p>运行KNNBakeOff.py</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578479972763.png" alt="1578479972763"></p>
<p>如果只看accuracy, KNN recommendation看上去是一个好方法，但是如果看 top-n recommendations, item-based和user-based推荐的都是些没听说过的电影 (obscure)，反而 random recommendation looks a lot better from a subjective standpoint.</p>
<p>So, on the surface, it looks like we may have made a system that’s pretty good at predicting ratings of movies people have already seen, but might not be very good at producing top-n recommendations.</p>
<h4 id="Exercise-1"><a href="#Exercise-1" class="headerlink" title="Exercise"></a>Exercise</h4><p>Experiment with different KNN parameters.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578480409983.png" alt="1578480409983"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578480533805.png" alt="1578480533805"></p>
<p>虽然msd比cosine的RMSE要低一点，但它们推荐的内容是一样的</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578480727372.png" alt="1578480727372"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578480843642.png" alt="1578480843642"></p>
<p>Well, it’s actually pretty well known that KNN doesn’t work well in practice. Unfortunately, some people conclude that collaborative filtering in general is some naive approach that should be replaced with completely different techniques. But as we’ve seen, collaborative filtering isn’t the problem, it’s forcing collaborative filtering to make rating predictions — that’s the problem. We had some pretty exciting results when we just focused on making top-N recommendations, and completely forgot about optimizing for rating accuracy, and it turns out that’s what at the heart of the problem. <strong>使用user-based CF和item-based CF,   top-N 推荐结果都是不错的。</strong></p>
<p>Ratings are not continuous in nature, and KNN treats them as though they are continuous values that can be predicted on a continuous scale. If you really want to go with KNN, it would be more appropriate to treat it as a rating classification problem than as a rating prediction problem. KNN is also very sensitive to sparse data.</p>
<p>The most fundamental thing is that accuracy isn’t everything. The main reason KNN produces underwhelming results is because it’s trying to solve the wrong problem. <strong>KNN recommender之所以推荐结果不好，是因为它解决的是rating prediction的问题，而不是推荐问题</strong>。</p>
<h3 id="7-Bleeding-Edge-Alert"><a href="#7-Bleeding-Edge-Alert" class="headerlink" title="7. Bleeding Edge Alert"></a>7. Bleeding Edge Alert</h3><p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578491595381.png" alt="1578491595381"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578491659157.png" alt="1578491659157"></p>
<p>The idea behind it is that users are modeled as vectors moving from one item to another in a multidimensional space. And you can predict sequences of events, like which movie a user is likely to watch next, by modeling these vectors.</p>
<p>The reason this paper is exciting is because it outperformed all of the best existing methods for recommending sequences of events in all but one case in one data set.</p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578491938065.png" alt="1578491938065"></p>
<p><img src="/2020/01/07/Neighborhood-Based-Collaborative-Filtering/1578492119528.png" alt="1578492119528"></p>
<p>Basic idea: You position individual items, like movies, in a transition space, where neighborhoods within this   space represent similarity between items. So items close together in this space are similar to each other. The dimensions corresponds to complex transition relationships between items. Since this technique depends on arranging items together into local, similar neighborhoods, I still classify it as a neighborhood -based method. </p>
<p>In this space, we can learn the vectors associated with individual users. Maybe a user who watches a Tom Cruise movie, is likely to move along to the next Tom Cruise movie, for example, and that transition would be represented by a vector in this space. We can then predict the next movie a user is like to watch by extrapolating along the vector we’ve associated with that user.</p>
<p>The paper provide the code in C++.</p>
<p>It’s all very advanced stuff, but it seems to work. So if you find yourself in the situation where you need to predict a sequence of events, like which movies or videos a person is likely to watch next given theirs past history, you might wanna do a search for translation-based recommendations and how it’s coming along in the real world.</p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>Content-Based Filtering</title>
    <url>/2020/01/06/Content-Based-Filtering/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Recommending items just based on the attributes of those items, instead of trying to use aggregate user behavior data.</p>
<h3 id="Cosine-Similarity"><a href="#Cosine-Similarity" class="headerlink" title="Cosine Similarity"></a>Cosine Similarity</h3><p><img src="/2020/01/06/Content-Based-Filtering/1578288453177.png" alt="1578288453177"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578288708324.png" alt="1578288708324"></p>
<p>为简单起见，假设电影只有两种类型：adventure和comedy. 一部电影若属于某种类型则为1，若不属于则为0.</p>
<p>角度 θ 一定程度上刻画了它们之间的相似度。我们想要将相似度刻画成[0,1]范围内的数，zero means not at all similar, and one means totally the same thing. 而 θ 的余弦值正好可以达到这个目的：θ 为90度，余弦值为0；θ 为0度，余弦值为1.  </p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578289233556.png" alt="1578289233556"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578289272295.png" alt="1578289272295"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578289294315.png" alt="1578289294315"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578289387292.png" alt="1578289387292"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578289605079.png" alt="1578289605079"></p>
<p>How do we assign a similarity score based on release years alone?</p>
<p>This is where some of the art of recommender systems comes in. You have to think about the nature of the data you have and what makes sense.</p>
<p>How far apart would two movies have to be for their release date alone to signify they are substantially different? A decade seems like a reasonable starting point. </p>
<p>Now we need to come up with some sort of mathematical function that smoothly scales that into the range zero to one. -&gt; 可选择指数衰减函数。</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578291075846.png" alt="1578291075846"></p>
<p>The choice of this function is completely arbitrary, but it seems like a reasonable starting point. In the real world, you’d test many variations of this function to see what really produces the best recommendations with real people. </p>
<h3 id="K-nearest-neighbors"><a href="#K-nearest-neighbors" class="headerlink" title="K-nearest-neighbors"></a>K-nearest-neighbors</h3><p>So how do we turn these similarities between movies based on their attributes into actual rating predictions?</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578292209772.png" alt="1578292209772"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578293123577.png" alt="1578293123577"></p>
<h3 id="Code-Walkthrough"><a href="#Code-Walkthrough" class="headerlink" title="Code Walkthrough"></a>Code Walkthrough</h3><p>ContentBased里的文件：</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578309826515.png" alt="1578309826515"></p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578310985921.png" alt="1578310985921"></p>
<p>从结果可以看到，Content-based algorithm比random recommendations 表现得要好。</p>
<h3 id="Bleeding-Edge-Alert"><a href="#Bleeding-Edge-Alert" class="headerlink" title="Bleeding Edge Alert"></a>Bleeding Edge Alert</h3><blockquote>
<p>注：We often refer to the current state of the art as leading edge, but technology that’s still so new that it’s unproven in the real world can be risky to work with, and so we call that bleeding edge. </p>
<p>This is where we highlight some new research that looks interesting and promising, but hasn’t really made it into mainstream yet with recommender systems. </p>
</blockquote>
<h4 id="mise-en-scene"><a href="#mise-en-scene" class="headerlink" title="mise en scene"></a>mise en scene</h4><p>Some recent research and content based filtering has surrounded the use of mise en scene data. Technically, mise en scene refers to the placement of objects in a scene, but the researchers are using this term a bit more loosely to refer to the properties of the scenes in a movie or movie trailer. </p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578311747376.png" alt="1578311747376"></p>
<p>The idea is to extract properties from the film itself that can be quantified and analyzed, and see if we can come up with better movie recommendations by examining the content of the movie itself scene by scene.</p>
<p>What sort of attributes are we talking about：</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578311877667.png" alt="1578311877667"></p>
<p>In principle, this should give us a feel as to the pacing and mood of the film, just based on the film itself.</p>
<p>Q：这样的数据和原来使用的 human generated genre classification 相比，是否更加有效？</p>
<p>更改代码：</p>
<p>去掉ContentKNNAlgorithm.py中第45行的注释，再在第46行上加上 <code>* mesSimilarity</code>:</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578312959234.png" alt="1578312959234"></p>
<p>再运行ContentRec.py，可得到结果如下：</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578314301934.png" alt="1578314301934"></p>
<p>从结果上看，RMSE actually got a lot worse. 一方面，This could just be an artifact of how we chose to compute mise en scene similarity scores. 另一方面，Accuracy isn’t really what we’re concerned with.</p>
<p>Again, sometimes developing recommendation systems is more an art than a science. You can’t really predict how real people will react to new recommendations they haven’t seen before. Personally, I’d be tempted to test this in an A/B test to see how it performs. </p>
<p>If you look at the research literature associated with mise en scene recommendations however, they note that it doesn’t do any favors to accuracy, but it does increase diversity. But again, increased diversity isn’t always a good thing when it comes to recommendations. It may just mean that you’re recommending random stuff that has no correlation to the user’s actually interest. Still, it was interesting to experiment with it, and it would be even more interesting to experiment with it using real people</p>
<p>Here’s a reference to the original research paper:</p>
<p><img src="/2020/01/06/Content-Based-Filtering/1578313486050.png" alt="1578313486050"></p>
<h3 id="Exercise"><a href="#Exercise" class="headerlink" title="Exercise"></a>Exercise</h3><ul>
<li>Use genre, release year, and mise en scene data independently.</li>
</ul>
<p><img src="/2020/01/06/Content-Based-Filtering/1578314783671.png" alt="1578314783671"></p>
<ul>
<li>See if you improve the release year based recommendations by sorting the k nearest neighbors within a given year by popularity. (sort the year-based recommendations by popularity as a secondary sort)</li>
</ul>
<p><img src="/2020/01/06/Content-Based-Filtering/1578315361933.png" alt="1578315361933"></p>
<p>Now by using popularity data, technically we’re no longer limiting our recommendations to content attributes. Popularity is behavior-based data.</p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>A Recommender Engine Framework</title>
    <url>/2020/01/05/A-Recommender-Engine-Framework/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>What we need now is a framework to let us easily experiment with new recommender system algorithms, evaluate them, and compare them against each other.</p>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578205315867.jpg" alt="1578205315867"></p>
<h3 id="1-Our-Recommender-Engine-Architecture"><a href="#1-Our-Recommender-Engine-Architecture" class="headerlink" title="1. Our Recommender Engine Architecture"></a>1. Our Recommender Engine Architecture</h3><p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578205676375.png" alt="1578205676375"></p>
<p>Object oriented design allows us to have base classes, for example, AlgoBase, that contain functions and variables that can be shared by other classes that inherit from that base class. 例如AlgoBase中实现了fit和test方法，则无论我们实际上使用的是什么算法，我们都可以调用fit和test方法。</p>
<p>Custom指的是any custom algorithm we might develop (自己写的recommender system), and make them part of the supriselib framework.</p>
<h4 id="Create-a-custom-algorithm"><a href="#Create-a-custom-algorithm" class="headerlink" title="Create a custom algorithm"></a>Create a custom algorithm</h4><p>So, how do you write your own recommender algorithm that’s compatible with surpiselib?</p>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578207092161.png" alt="1578207092161"></p>
<p>All you have to do is create a new class that inherits form AlgoBase, and as far as supriselib is concerned, your algorithm has one job: to predict ratings.</p>
<blockquote>
<p>As we mentioned, supriselib is built around the architecture of predicting the ratings of every movie for every user, and giving back the top predictions as your recommendations. </p>
</blockquote>
<p>Your class have to implement an estimate function.</p>
<p>When estimate is called by supriselib framework, it’s asking you to predict a rating for the user and item passed in. </p>
<blockquote>
<p>注：这里的user id和item id是inner id. Must be mapped back to the raw user and item ids in your source data.</p>
</blockquote>
<ul>
<li>Now, we want to do more than just predict ratings. 我们想要很简单的将之前在<code>RecommenderMetrics</code>中实现的不同的evaluation metrics应用到algorithms we work with. </li>
</ul>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578207683880.png" alt="1578207683880"></p>
<p>为了做到这一点，我们将创建一个新的class叫做<code>EvaluatedAlgoritm</code>，里面创建了一个新的函数叫做<code>Evaluate</code>，that runs all the metrics in RecommenderMetrics on that algorithm. So this class makes it easy to measure accuracy, coverage, diversity and everything else on a given algorithm.</p>
<ul>
<li><p>不同的评估方法，要求对数据集的不同分割方式，于是我们创建了另一个新的class: <code>EvaluationData</code>来做到这一点。</p>
</li>
<li><p>如何连接这一切？</p>
</li>
</ul>
<p>We create an <code>EvaluationData</code> instance with our data set, create an <code>EvaluatedAlgorithm</code> for each algorithm we want to evaluate, and call <code>Evaluate</code> on each algorithm using the same <code>EvaluationData</code>. Under the hood, <code>EvaluatedAlgorithm</code> will use all the functions we defined in <code>RecommenderMetrics</code> to measure accuracy, hit rate, diversity, novelty, and coverage.</p>
<ul>
<li>Since what we generally want to do is 比较不同推荐系统, we can make life even easier by writing a class that takes care of all the comparison for us. 于是我们创建了新的class：<code>Evaluator</code>.</li>
</ul>
<p>Ideally, we want to just submit algorithms we want to evaluate against each other into this class, and let it do everything from there.</p>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578208719473.png" alt="1578208719473"></p>
<p>The beauty of this is that you don’t even have to use the <code>EvalutedAlgorithm</code> or <code>EvaluatedData</code> classed at all, when you want to start playing around with new algorithms and testing them against each other. All you need to do is use this <code>Evaluator</code> class, which has a really simple interface.</p>
<p>将上述framework写好后，如下这是我们比较SVD算法与random算法所需要的所有代码：</p>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578208901255.png" alt="1578208901255"></p>
<h3 id="2-Code-Walkthrough"><a href="#2-Code-Walkthrough" class="headerlink" title="2. Code Walkthrough"></a>2. Code Walkthrough</h3><p>Framework文件夹里：</p>
<p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578209106245.png" alt="1578209106245"></p>
<h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><p><img src="/2020/01/05/A-Recommender-Engine-Framework/1578283638478.png" alt="1578283638478"></p>
<p>我们比较的是SVD和随机推荐。SVD is one of the best algorithms available right now, so it shouldn’t be surprise that SVD beats random recommendation in accuracy and hit rate no matter how we measure it.</p>
<ul>
<li>RMSE和MAE: lower is better.</li>
<li>Hit rate,包括cHR, ARHR: higher is better.</li>
<li>Coverage, diversity, novelty: need to apply some common sense to, as it’s not a clear higher-is-better sort of thing. There are trade-offs involved with these metrics.</li>
</ul>
<p>就Coverage而言，SVD的要低一些: that’s just because we are enforcing a quality threshold on the top-N recommendations we’re making with SVD, while our random recommender isn’t actually making totally random recommendations, it’s predicting movie ratings using what’s called a normal distribution centered around the average rating value, which ends up meaning all of the rating predictions it makes fall above our rating threshold, giving us 100% coverage. Having 100% coverage at the expense of having bad recommendations isn’t a trade-off worth making.</p>
<p>就Diversity和Novelty而言，SVD的都要低一些，这是我们所预期会出现的。</p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>Evaluate Recommender System</title>
    <url>/2020/01/04/Evaluate-Recommender-System/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h3 id="1-The-methodology-for-testing-recommender-systems-offline"><a href="#1-The-methodology-for-testing-recommender-systems-offline" class="headerlink" title="1. The methodology for testing recommender systems offline."></a>1. The methodology for testing recommender systems offline.</h3><h4 id="1-1-train-test-split"><a href="#1-1-train-test-split" class="headerlink" title="1.1 train/test split"></a>1.1 train/test split</h4><p><img src="/2020/01/04/Evaluate-Recommender-System/1578116193748.jpg" alt="1578116193748"></p>
<p>You measure your recommender system’s ability to predict how people rated things in the past.</p>
<p>If you do this over enough people, you can end up with a meaningful number that tells you <strong>how good your recommender system is at recommending things, or more specifically, recommending things people already watched and rated.</strong> That’s really all you can do, if you can’t test things out in an online system.</p>
<h4 id="1-2-k-fold-cross-validation"><a href="#1-2-k-fold-cross-validation" class="headerlink" title="1.2 k-fold cross-validation"></a>1.2 k-fold cross-validation</h4><p>If you really want to get fancy, it’s possible to improve on a single train/test split by using  a technique called k-fold cross validation.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578116897885.jpg" alt="1578116897885"></p>
<p>Instead of a single training set, we create many randomly assigned training sets. Each individual training set, or fold, is used to train your recommender system independently, and then we measure the accuracy of the resulting systems against your test set. So we end up with a score of how accurate each fold ends up predicting user ratings, and we can average them together.</p>
<p>This obviously takes a lot more computing power to do, but the advantage is that you don’t end up over-fitting to a single training set.</p>
<blockquote>
<p>注：By using train/test, all we can do is test our ability to predict how people rated movies they already saw. That’s not the point of a recommender system.  We want to recommend new things to people that they haven’t seen, but find interesting. However, that’s fundamentally impossible to test offline.</p>
</blockquote>
<p>We haven’t talked about how to actually come up with an accuracy metric when testing our recommender systems, so let’s cover a couple of different ways to do it.</p>
<h3 id="2-Accuracy-Metrics-RMSE-MAE"><a href="#2-Accuracy-Metrics-RMSE-MAE" class="headerlink" title="2. Accuracy Metrics (RMSE, MAE)"></a>2. Accuracy Metrics (RMSE, MAE)</h3><h4 id="2-1-MAE"><a href="#2-1-MAE" class="headerlink" title="2.1 MAE"></a>2.1 MAE</h4><p>We want to minimize MAE.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578117806539.JPG" alt="1578117806539"></p>
<h4 id="2-2-RMSE"><a href="#2-2-RMSE" class="headerlink" title="2.2 RMSE"></a>2.2 RMSE</h4><p>We want to minimize RMSE.</p>
<p>This is a more popular metric for a few reasons, but one is that <strong>it penalizes you more when your rating prediction is way off, and penalizes you less when your are reasonably close.</strong></p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578117900853.jpg" alt="1578117900853"></p>
<blockquote>
<p>注：就推荐系统而言，RMSE just doesn’t matter much in the real world. 人们并不关心你的系统对他们已经看过的电影的评分预测是否准确。What does matter is which movie you put in front of users in a top-N recommender list, and how those users react to those movies when they see them recommended.</p>
</blockquote>
<h3 id="3-Top-N-Hit-Rate-Many-Ways"><a href="#3-Top-N-Hit-Rate-Many-Ways" class="headerlink" title="3. Top-N Hit Rate - Many Ways"></a>3. Top-N Hit Rate - Many Ways</h3><p>Different ways to measure the effectivenss of top-n recommenders offline:</p>
<h4 id="3-1-Hit-Rate"><a href="#3-1-Hit-Rate" class="headerlink" title="3.1 Hit Rate"></a>3.1 Hit Rate</h4><p>You generate top-n recommendations for all of the users in your test set. <strong>If one of the recommendations in a user’s top-n recommendations is something  they actually rated, you consider that a hit.</strong> You actually managed to show the user something that they found interesting enough to watch on their own already, so we consider that a success. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578119273699.jpg" alt="1578119273699"></p>
<p>How to measure hit rate? Use leave-one-out cross validation.</p>
<h4 id="3-2-leave-one-out-cross-validation"><a href="#3-2-leave-one-out-cross-validation" class="headerlink" title="3.2 leave-one-out cross validation"></a>3.2 leave-one-out cross validation</h4><p>What we do is compute the top-n recommendations for each user in our training data, and intentionally remove one of those items from that user’s training data. We then test our recommender system’s ability to recommend that item that was left out in the top-n results it creates for that user in the testing phase.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578120352619.jpg" alt="1578120352619"></p>
<p>The trouble is that it’s a lot harder to get one specific movie right while testing than to just get one of the n recommendations. So “hit rate” with “leave-one-out” tends to be very small and difficult to measure, unless you have a very large data set to work with. But it’s a much more <strong>user focused metric</strong> when you know your recommender system will be producing top-n lists in the real world, which most of them do. </p>
<h4 id="3-3-ARHR"><a href="#3-3-ARHR" class="headerlink" title="3.3 ARHR"></a>3.3 ARHR</h4><p>This metric is just like “hit rate”, but it accounts for where in the top-n list you hits appear. Instead of summing up the number of hits, we sum up the reciprocal ranking of each hit.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578122155631.jpg" alt="1578122155631"></p>
<p>You end up getting more credit for successfully recommending an item in the top slot than in the bottom slot. Again, this is a more <strong>user focused metric</strong>, since users tend to focus on the beginning of lists. </p>
<h4 id="3-4-cHR"><a href="#3-4-cHR" class="headerlink" title="3.4 cHR"></a>3.4 cHR</h4><p>Throw away hits if our predicted rating is below some threshold.</p>
<p>The idea is that we shouldn’t get credit for recommending items to a user that we think they won’t actually enjoy. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578122704818.jpg" alt="1578122704818"></p>
<p>In this example, if we had a cutoff of three stars, we throw away the hits for the second and fourth items in these test results and our hit rate metric wouldn’t count them at all. </p>
<h4 id="3-5-rHR"><a href="#3-5-rHR" class="headerlink" title="3.5 rHR"></a>3.5 rHR</h4><p>Another way to look at hit rate is to break it down by predicted rating score.</p>
<p>It can be a good way to get an idea of the distribution of how good your algorithm thinks recommended movies are that actually get a hit.  Ideally, you want to recommend movies that they actually like, and breaking down the distribution gives you some sense of how well you’re doing in more detail.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578123016707.jpg" alt="1578123016707"></p>
<p>对每一个rating type (1,2,3,4,5), print out its hit rate.</p>
<h3 id="4-Coverage-Diversity-and-Novelty"><a href="#4-Coverage-Diversity-and-Novelty" class="headerlink" title="4. Coverage, Diversity and Novelty"></a>4. Coverage, Diversity and Novelty</h3><p>Accuracy isn’t the only thing that matters.</p>
<h4 id="4-1-Coverage-覆盖度"><a href="#4-1-Coverage-覆盖度" class="headerlink" title="4.1 Coverage 覆盖度"></a>4.1 Coverage 覆盖度</h4><p>The percentage of possible recommendations that your system is able to provide. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578123495150.jpg" alt="1578123495150"></p>
<p>It’s worth noting that coverage can be at odds with accuracy. If you enforce a higher quality threshold on the recommendations you make, then you might improve your accuracy at the expense of coverage. Finding the balance of where exactly you’re better off recommending nothing at all can be delicate. </p>
<p>Coverage can also be important to watch, because it gives you a sense of how quickly new items in your catalog will start to appear in your recommendations. When a new book come out on Amazon, it won’t appear in recommendations until at least a few people buy it, therefore establishing patterns with the purchase of other items. Until those patterns exist, that new book will reduce Amazon’s coverage metric.</p>
<h4 id="4-2-Diversity-多样性"><a href="#4-2-Diversity-多样性" class="headerlink" title="4.2 Diversity 多样性"></a>4.2 Diversity 多样性</h4><p>You can think of this as measure of how broad a variety of items your recommender system is putting in front of people. An example of low diversity would be a recommender system that just recommends the next books in a series that you’ve started reading, but doesn’t recommend book from different authors, or movies related to what you’ve read.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578124451718.jpg" alt="1578124451718"></p>
<p>Diversity, at least in the context of recommender systems, isn’t always a good thing. You can achieve very high diversity by just recommending completely random items. Unusually high diversity scores mean that you just have bad recommendations more often than not. You always need to look at diversity alongside metrics that measure the quality of the recommendations as well. </p>
<h4 id="4-3-Novelty-新颖性"><a href="#4-3-Novelty-新颖性" class="headerlink" title="4.3 Novelty 新颖性"></a>4.3 Novelty 新颖性</h4><p>Similarly, novelty sounds like a good thing, but often it isn’t. Novelty is a measure of how popular the items are that you are recommending. And again, just recommending random stuff would yield very high novelty scores, since the vast majority of items are not top sellers. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578124908363.jpg" alt="1578124908363"></p>
<p>Although novelty is measurable, what to do with it is in many ways subjective. There’s a concept of user trust in a recommender system. People want to see at least a few familiar items in their recommendations that make them say, “Yeah, that’s a good recommendation for me. The system seems good”. If you only recommend things people never heard of, they may conclude that your system doesn’t really know them. Also, popular items are usually popular for a reason. They’re enjoyable by a large segment of the population, so you would expect them to be good recommendations for a large segment of the population who hasn’t read or watched them yet. If you’re not recommending some popular items, you should probably question whether your recommender system is really working as it should.</p>
<p><strong>You need to strike a balance between familiar, popular items and what we call serendipitous discovery of new items that user has never heard of before. (balance between novelty and trust)</strong>. The familiar items establish trust with the user, and the new ones allow the user to discover entirely new things that they might love. </p>
<p>Novelty is important, because the whole point of recommender systems is to surface items in what we call “the long tail”.</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578125635846.jpg" alt="1578125635846"></p>
<p>Imagine this is a plot of the sales of every item in you catalog, sorted by sales. Y 轴代表sales (popularity)，X轴代表products. Most of sales来自于一小部分items，但是”long tail” makes up a large amount of sales as well. 黄色部分的item代表了人们各自感兴趣的东西. Recommender systems can help people discover those items in the long tail that are relevant to their own unique niche interests. If you can do that successfully, then the recommendations your system makes can help new authors get discovered, can help people explore their own passions, and make money for whoever you’re building the system for as well. Everybody wins.</p>
<h3 id="5-Churn-Responsiveness-and-A-B-Tests"><a href="#5-Churn-Responsiveness-and-A-B-Tests" class="headerlink" title="5. Churn, Responsiveness, and A/B Tests"></a>5. Churn, Responsiveness, and A/B Tests</h3><h4 id="5-1-Churn"><a href="#5-1-Churn" class="headerlink" title="5.1 Churn"></a>5.1 Churn</h4><p>Another thing we can measure is Churn. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578127764650.jpg" alt="1578127764650"></p>
<p>Churn can measure how sensitive your recommender system is to new user behavior. 如果用户rate了一部新电影，会使得他的推荐内容发生很大的变化吗？If so, your churn score will be high. Maybe just showing the same recommendations too many times is a bad idea itself. 如果一个用户总是看到相同的推荐，但是不点击进去，在某个时候你应该停止推荐它而给用户推荐其他的东西。Sometimes, a little bit of randomization in your top-n recommendations can keep them looking fresh, and expose your users to more items.</p>
<p>But, just like diversity and novelty, high churn is not in itself a good thing. You could maximize your churn metric by just recommending items completely at random, 但显然这不是好的推荐。</p>
<p><strong>All these metrics need to be looked at together, and you need to understand the trade-offs between them. </strong></p>
<h4 id="5-2-Responsiveness"><a href="#5-2-Responsiveness" class="headerlink" title="5.2 Responsiveness"></a>5.2 Responsiveness</h4><p><img src="/2020/01/04/Evaluate-Recommender-System/1578128338650.jpg" alt="1578128338650"></p>
<p>If you rate  a new movie, does it affect your recommendations immediately or next day after some nightly job runs? More responsiveness would always seem to be a good thing, but in the world of business, you have to decide how responsive your recommender really needs to be, since recommender systems that have instantaneous responsiveness are complex, difficult to maintain, and expensive to build. You need to strike your own balance between responsiveness and simplicity.</p>
<blockquote>
<p> ? What’s important</p>
<p>前面讲了许多evaluate推荐系统的方法：MAE, RMSE, Hit rate in various forms, coverage, diversity, novelty, churn, and responsiveness.</p>
<p>So how do you know what to focus on? It depends.</p>
<p>It may even depend on cultural factors. Some cultures may want more diversity and novelty, while other cultures may want to stick to things that are familiar with them. </p>
<p>It also depends on what you’re trying to achieve as a business. And usually,  a business is just trying to make money, which leads to one more way to evaluate recommender systems that is arguably the most important of all: online A/B tests!</p>
</blockquote>
<h4 id="5-3-Online-A-B-Tests"><a href="#5-3-Online-A-B-Tests" class="headerlink" title="5.3 Online A/B Tests"></a>5.3 Online A/B Tests</h4><p><img src="/2020/01/04/Evaluate-Recommender-System/1578129032852.jpg" alt="1578129032852"></p>
<hr>
<blockquote>
<p>参考：</p>
<p> <a href="https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System" target="_blank" rel="noopener">https://github.com/NLP-LOVE/ML-NLP/tree/master/Project/17.%20Recommendation%20System</a></p>
</blockquote>
<p>AB测试是一种很常用的在线评测算法的实验方法。它通过一定的规则将用户随机分成几组，并对不同组的用户采用不同的算法，然后通过统计不同组用户的各种不同的评测指标比较不同算法，比如可以统计不同组用户的点击率，通过点击率比较不同算法的性能。对AB测试感兴趣的读者可以浏览一下网站<a href="http://www.abtests.com/" target="_blank" rel="noopener">http://www.abtests.com/</a> ，该网站给出了很多通过实际AB测试提高网站用户满意度的例子，从中我们可以学习到如何进行合理的AB测试。</p>
<hr>
<p>Doing online A/B tests to tune your recommender system using your real customers, and measuring how they react to your recommendations. You can put recommendations from different algorithms in front of different sets of users, and measure if they actually buy, watch, or otherwise indicate interest in the recommendations you’ve presented. </p>
<p>By always testing changes to your recommender system using controlled, online experiments, you can see if they actually cause people to discover and purchase more new things than they would have otherwise.</p>
<p>None of the metrics we’ve discussed matter more than how real customers react to the recommendations you produce in the real world. You can have the most accurate rating predictions in the world, but if customers can’t find new items to buy or watch from your system, it will be worthless from a practical standpoint. </p>
<p>Online tests can help you to avoid introducing complexity that adds no value, and remember, complex systems are difficult to maintain.</p>
<p>SO REMEMBER, offline metrics such as accuracy, diversity, and novelty can all be indicators you can look at while developing recommender systems offline, but you should never declare victory until you’ve measured a real impact on real users from your work. <strong>User behavior is the ultimate test of your work.</strong></p>
<p><strong>Accurately predicted ratings don’t necessarily make for good video recommendations. At the end of the day, the results of online A/B tests are the only evaluation that matters for your recommender system.</strong></p>
<hr>
<p> A/B 测试，常见的指标有点击率、用户停留时间、 广告收入等，需要注意分析统计显著性。同时，需要注意短期的指标和长期的指标相结合， 一些短期指标的提升有时候反而会导致长期指标下降 比如 ，经常推荐美女或者搞笑类的内容会带来短期的点击率提高，但是可能会引起长期的用户粘性下降。设计者需要从自己的产品角度出发，根据产品的需要制定评估指标，这样才能更好地指导推荐系统的优化方向。常见的评价指标如下：</p>
<p><img src="https://camo.githubusercontent.com/fcefce67e348ce386471df934a041b367eb9b529/68747470733a2f2f67697465652e636f6d2f6b6b7765697368652f696d616765732f7261772f6d61737465722f4d4c2f323031392d392d385f31342d34332d35312e706e67" alt="img"></p>
<hr>
<p>Another thing you can do is just straight up ask your users, if they think specific recommendations are good. </p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578129889414.jpg" alt="1578129889414"></p>
<p>In practice though, it’s a tough thing to do. Users will probably be confused over whether you’re asking them to rate the item or rate the recommendation, so you won’t really know how to interpret this data. It also requires extra work form your customers with no clear payoff for them, so you’re unlikely to get enough ratings on your recommendations to be useful. </p>
<p>It’s best to just stick with online A/B tests, and measure how your customers vote with their wallets on the quality of your recommendations.</p>
<h3 id="Quiz"><a href="#Quiz" class="headerlink" title="Quiz"></a>Quiz</h3><p><img src="/2020/01/04/Evaluate-Recommender-System/1578196100106.jpg" alt="1578196100106"></p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578196212178.jpg" alt="1578196212178"></p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578196333798.jpg" alt="1578196333798"></p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578196377981.jpg" alt="1578196377981"></p>
<h3 id="Code-Walkthrough"><a href="#Code-Walkthrough" class="headerlink" title="Code Walkthrough"></a>Code Walkthrough</h3><p>使用Python中的library: Suprise. <a href="supriselib.com">SupriseLib’s documentation online</a></p>
<p>Suprise is built around measuring the accuracy of recommender systems. Although this is the wrong thing to focus on, it’s really the best we can do without access to a real, large-scale website of our own.</p>
<p>Evaluating文件夹里的：</p>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578201480503.jpg" alt="1578201480503"></p>
<p>RecommenderMetrics中实现了前面讲到的用来evaluate recommender system的各种metrics.</p>
<p>TestMetrics中调用了RecommenderMetrics中的方法来实现一个real recommender system并evaluate it.</p>
<h4 id="结果分析"><a href="#结果分析" class="headerlink" title="结果分析"></a>结果分析</h4><p><img src="/2020/01/04/Evaluate-Recommender-System/1578201799750.jpg" alt="1578201799750"></p>
<ul>
<li><p>RMSE大概0.9，MAE大概0.7。</p>
<p>On average, our guess of rating for a given movie for a given user, was off by about 0.7 stars. RMSE is higher, meaning that we got penalized for being way off more often than we’d like.</p>
<p>Remember, error metrics are bad.  你想要RMSE与MAE越低越好，if accuracy is your goal.</p>
</li>
</ul>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578201882902.jpg" alt="1578201882902"></p>
<ul>
<li>Hit Rate大概 3%，which actually isn’t that bad, considering that only one movie was left out from each user’s rating to test with. 这个数值本身很难解释是好是坏，除非有其他的推荐系统可供比较。</li>
<li>If we break it down by rating value, you can see that our hit rate did better at higher rating predictions, which make sense and it’s what we want to see. Hit Rate在评分越高的类型中表现得更好（例如，在评分为5的电影中，Hit Rate为 6%）。</li>
<li>Cumulative Hit Rate with a 4.0 threshold isn’t much lower than the raw hit rate, meaning that we’re doing a good job of recommending items we think are good recommendations.</li>
<li>ARHR is 0.01. It takes the ranking of the hits into account. Again, it has no real value until we have other recommender systems to compare it against.</li>
</ul>
<p><img src="/2020/01/04/Evaluate-Recommender-System/1578203470922.jpg" alt="1578203470922"></p>
<ul>
<li><p>We look at user coverage for which we have at least one 4-star rating prediction, ant it’s pretty high. That’s good.</p>
</li>
<li><p>Diversity is really high at 0.96, and novelty seems pretty high, with an average popularity rank of 491. Remember there are only a few thousand movies in our data set to begin with. </p>
<p>This tells us that our algorithm is going pretty deep into the long tail to get its recommendations and that could be a problem in the real world. Novelty比较高（平均受欢迎程度排名比较靠后），说明推荐的都是比较小众的电影（long tail）.</p>
</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>So even though our accuracy metrics look okay here, diversity and novelty is telling us that we’re recommending a lot of really obscure stuff. And that could be an issue when trying to establish user trust in the system. People generally want to see a few things that at least look familiar. So I would expect this particular algorithm wouldn’t do that well in an online A/B test, but you can never really know until  you actually try it. </p>
<p>Anyhow, we now have working code now for evaluating real recommender systems!</p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>Top-N Recommender Architecture</title>
    <url>/2020/01/03/Top-N-Recommender-Architecture/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/2020/01/03/Top-N-Recommender-Architecture/1578052647526.jpg" alt="1578052647526"></p>
<p><img src="/2020/01/03/Top-N-Recommender-Architecture/1578471196924.png" alt="1578471196924"></p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>RecSys Course Overview</title>
    <url>/2020/01/03/RecSys-Course-Overview/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>课程：</p>
<p><a href="https://www.udemy.com/course-dashboard-redirect/?course_id=1726410" target="_blank" rel="noopener"><img src="https://i.udemycdn.com/course/240x135/1726410_7b86.jpg" alt="Building Recommender Systems with Machine Learning and AI"></a><a href="https://www.udemy.com/course/building-recommender-systems-with-machine-learning-and-ai/learn/" target="_blank" rel="noopener"><strong>Building Recommender Systems with Machine Learning and AI</strong> </a></p>
<p><a href="https://sundog-education.com/RecSys/" target="_blank" rel="noopener">Course Materials</a></p>
<p><img src="/2020/01/03/RecSys-Course-Overview/1578048175249.jpg" alt="1578048175249"></p>
]]></content>
      <categories>
        <category>Recommender System</category>
      </categories>
      <tags>
        <tag>Recommender System</tag>
      </tags>
  </entry>
  <entry>
    <title>MapReduce</title>
    <url>/2020/01/03/MapReduce/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="1-MapReduce-fundamental-concepts"><a href="#1-MapReduce-fundamental-concepts" class="headerlink" title="1. MapReduce fundamental concepts"></a>1. MapReduce fundamental concepts</h4><p><img src="/2020/01/03/MapReduce/1578032618932.jpg" alt="1"></p>
<p><img src="/2020/01/03/MapReduce/20200103-142610.jpg" alt="20200103-142610"></p>
<p><img src="/2020/01/03/MapReduce/1578032937052.jpg" alt="1578032937052"></p>
<h5 id="1-1-Mapper"><a href="#1-1-Mapper" class="headerlink" title="1.1 Mapper"></a>1.1 Mapper</h5><p><img src="/2020/01/03/MapReduce/1578033123727.jpg" alt="1578033123727"></p>
<p><img src="/2020/01/03/MapReduce/20200103-143446.jpg" alt="20200103-143446"></p>
<p><img src="/2020/01/03/MapReduce/1578033212508.jpg" alt="1578033212508"></p>
<p><img src="/2020/01/03/MapReduce/1578033238182.jpg" alt="1578033238182"></p>
<p>Mapper: Extract and organize what we care about.</p>
<h5 id="1-2-Shuffle-and-Sort"><a href="#1-2-Shuffle-and-Sort" class="headerlink" title="1.2 Shuffle and Sort"></a>1.2 Shuffle and Sort</h5><p><img src="/2020/01/03/MapReduce/1578033463232.jpg" alt="1578033463232"></p>
<p><img src="/2020/01/03/MapReduce/20200103-144645.jpg" alt="20200103-144645"></p>
<h5 id="1-3-Reducer"><a href="#1-3-Reducer" class="headerlink" title="1.3 Reducer"></a>1.3 Reducer</h5><p><img src="/2020/01/03/MapReduce/1578034121206.jpg" alt="1578034121206"></p>
<p><img src="/2020/01/03/MapReduce/20200103-144953.jpg" alt="20200103-144953"></p>
<p><img src="/2020/01/03/MapReduce/1578034303323.jpg" alt="1578034303323"></p>
<hr>
<h4 id="2-How-MapReduce-distributes-processing"><a href="#2-How-MapReduce-distributes-processing" class="headerlink" title="2. How MapReduce distributes processing"></a>2. How MapReduce distributes processing</h4><p><img src="/2020/01/03/MapReduce/1578034389919.jpg" alt="1578034389919"></p>
<p><img src="/2020/01/03/MapReduce/0002.jpg" alt="0002"></p>
<hr>
<h4 id="3-MapReduce-a-real-example"><a href="#3-MapReduce-a-real-example" class="headerlink" title="3. MapReduce: a real example"></a>3. MapReduce: a real example</h4><p><img src="/2020/01/03/MapReduce/1578035985411.jpg" alt="1578035985411"></p>
<p><img src="/2020/01/03/MapReduce/1578036687341.jpg" alt="1578036687341"></p>
<p>Sometimes, it’s not easy to try to force a problem into this way of thinking, and that’s a big reason why other frameworks like Spark or Hive, or other ways of processing SQL style queries have become a little bit more popular that just writing raw MapReduce code.</p>
<p>But, still, if you can easily express something in terms of mapping and reducing, this can sometimes be the most efficient way of doing it.</p>
<p><img src="/2020/01/03/MapReduce/1578037510439.jpg" alt="1578037510439"></p>
<p>Then, the results all get passed into the MapReduce framework which does shuffle and sort for us. And then, we just have to write the Reducer.</p>
<p><img src="/2020/01/03/MapReduce/1578038403968.jpg" alt="1578038403968"></p>
<p>Here’s a complete Python MapReduce script.</p>
<p><img src="/2020/01/03/MapReduce/1578039179773.jpg" alt="1578039179773"></p>
<p>This is an entire MRJOB script in Python that would use MapReduce streaming to actually execute across a cluster.</p>
<hr>
<h4 id="4-Runing-MapReduce-with-MRJOB"><a href="#4-Runing-MapReduce-with-MRJOB" class="headerlink" title="4. Runing MapReduce with MRJOB"></a>4. Runing MapReduce with MRJOB</h4><p>首先需要安装一些东西</p>
<p>Run our MapReduce job in our Hadoop installation.</p>
<p><a href="https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963054#overview" target="_blank" rel="noopener">https://www.udemy.com/course/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/lecture/5963054#overview</a></p>
<p><img src="/2020/01/03/MapReduce/1578041252394.jpg" alt="1578041252394"></p>
<p><img src="/2020/01/03/MapReduce/1578041273664.jpg" alt="1578041273664"></p>
<p><img src="/2020/01/03/MapReduce/1578041300494.jpg" alt="1578041300494"></p>
<hr>
<h4 id="5-Challenge-Exercise"><a href="#5-Challenge-Exercise" class="headerlink" title="5. Challenge Exercise"></a>5. Challenge Exercise</h4><p><img src="/2020/01/03/MapReduce/1578043490000.jpg" alt="1578043490000"></p>
<p><img src="/2020/01/03/MapReduce/1578043550225.jpg" alt="1578043550225"></p>
<p><img src="/2020/01/03/MapReduce/1578043582794.jpg" alt="1578043582794"></p>
<p><img src="/2020/01/03/MapReduce/1578043608450.jpg" alt="1578043608450"></p>
<p><img src="/2020/01/03/MapReduce/1578043786325.jpg" alt="1578043786325"></p>
<hr>
<h4 id="6-Check-your-results"><a href="#6-Check-your-results" class="headerlink" title="6. Check your results"></a>6. Check your results</h4><p><img src="/2020/01/03/MapReduce/1578044582388.jpg" alt="1578044582388"></p>
<p>结果：</p>
<p><img src="/2020/01/03/MapReduce/1578044858078.jpg" alt="1578044858078"></p>
<p>movieId 50 是最popular的电影。</p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS and MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>有效的字母异位词</title>
    <url>/2020/01/02/%E6%9C%89%E6%95%88%E7%9A%84%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/valid-anagram/" target="_blank" rel="noopener">有效的字母异位词（难度：简单）</a></p>
<p><img src="/2020/01/02/有效的字母异位词/1.jpg" alt="1"></p>
<h4 id="方法一：哈希表"><a href="#方法一：哈希表" class="headerlink" title="方法一：哈希表"></a>方法一：哈希表</h4><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><ul>
<li>首先判断两个字符串长度是否相等，不相等则直接返回 false。</li>
<li>若相等，则初始化 26 个字母哈希表，遍历字符串 s 和 t</li>
<li><strong>s 负责在对应位置增加，t 负责在对应位置减少，如果哈希表的值都为 0，则二者是字母异位词</strong></li>
</ul>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。<br>空间复杂度：O(1)。尽管我们使用了额外的空间，但是空间的复杂性是 O(1)，因为无论 N 有多大，表的大小都保持不变。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><p>Java</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isAnagram</span><span class="params">(String s, String t)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(s.length() != t.length())</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span>[] alpha = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">26</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; s.length(); i++)&#123;</span><br><span class="line">            alpha[s.charAt(i) - <span class="string">'a'</span>]++;</span><br><span class="line">            alpha[t.charAt(i) - <span class="string">'a'</span>]--;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i : alpha)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i!=<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/有效的字母异位词/4.jpg" alt="4"></p>
<hr>
<h4 id="方法二：排序"><a href="#方法二：排序" class="headerlink" title="方法二：排序"></a>方法二：排序</h4><h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(nlogn)。</p>
<p>空间复杂度：O(1)，空间取决于排序实现，如果使用 <code>heapsort</code>，通常需要 O(1)辅助空间。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isAnagram</span><span class="params">(self, s: str, t: str)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">return</span> sorted(s) == sorted(t)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/有效的字母异位词/3.jpg" alt="3"></p>
<hr>
<h4 id="方法三：利用Python中的set"><a href="#方法三：利用Python中的set" class="headerlink" title="方法三：利用Python中的set()"></a>方法三：利用Python中的set()</h4><p>Python</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isAnagram</span><span class="params">(self, s: str, t: str)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> len(s) != len(t):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        set1 = set(s)</span><br><span class="line">        set2 = set(t)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> set2:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> set2:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> set1:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="keyword">if</span> s.count(i) != t.count(i):</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/有效的字母异位词/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>加一</title>
    <url>/2020/01/02/%E5%8A%A0%E4%B8%80/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/plus-one/" target="_blank" rel="noopener">加一（难度：简单）</a></p>
<p><img src="/2020/01/02/加一/1.jpg" alt="1"></p>
<h4 id="方法：数组遍历"><a href="#方法：数组遍历" class="headerlink" title="方法：数组遍历"></a>方法：数组遍历</h4><p><img src="/2020/01/02/加一/2.jpg" alt="2"></p>
<p>时间复杂度：O(n)</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] plusOne(<span class="keyword">int</span>[] digits) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = digits.length - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">            digits[i] = (digits[i]+<span class="number">1</span>) % <span class="number">10</span>;</span><br><span class="line">            <span class="keyword">if</span>(digits[i] != <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> digits;</span><br><span class="line">        &#125;</span><br><span class="line">        digits = <span class="keyword">new</span> <span class="keyword">int</span>[digits.length+<span class="number">1</span>];</span><br><span class="line">        digits[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> digits;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/加一/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>电话号码的字母组合</title>
    <url>/2020/01/02/%E7%94%B5%E8%AF%9D%E5%8F%B7%E7%A0%81%E7%9A%84%E5%AD%97%E6%AF%8D%E7%BB%84%E5%90%88/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/letter-combinations-of-a-phone-number/" target="_blank" rel="noopener">电话号码的字母组合（难度：中等）</a></p>
<p><img src="/2020/01/02/电话号码的字母组合/1.jpg" alt="1"></p>
<h4 id="方法：回溯"><a href="#方法：回溯" class="headerlink" title="方法：回溯"></a>方法：回溯</h4><p><img src="/2020/01/02/电话号码的字母组合/2.jpg" alt="2"></p>
<p><img src="https://pic.leetcode-cn.com/0ac574ab37f620221e702f57d6c4ffd0ba246abe41c43f9fc9637ab8f3365377-image.png" alt="img"></p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">letterCombinations</span><span class="params">(self, digits: str)</span> -&gt; List[str]:</span></span><br><span class="line">        phone = &#123;<span class="string">'2'</span>:[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>],</span><br><span class="line">                <span class="string">'3'</span>:[<span class="string">'d'</span>,<span class="string">'e'</span>,<span class="string">'f'</span>],</span><br><span class="line">                <span class="string">'4'</span>:[<span class="string">'g'</span>,<span class="string">'h'</span>,<span class="string">'i'</span>],</span><br><span class="line">                <span class="string">'5'</span>:[<span class="string">'j'</span>,<span class="string">'k'</span>,<span class="string">'l'</span>],</span><br><span class="line">                <span class="string">'6'</span>:[<span class="string">'m'</span>,<span class="string">'n'</span>,<span class="string">'o'</span>],</span><br><span class="line">                <span class="string">'7'</span>:[<span class="string">'p'</span>,<span class="string">'q'</span>,<span class="string">'r'</span>,<span class="string">'s'</span>],</span><br><span class="line">                <span class="string">'8'</span>:[<span class="string">'t'</span>,<span class="string">'u'</span>,<span class="string">'v'</span>],</span><br><span class="line">                <span class="string">'9'</span>:[<span class="string">'w'</span>,<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'z'</span>]&#125;</span><br><span class="line"></span><br><span class="line">        output = []</span><br><span class="line">        <span class="keyword">if</span> digits:</span><br><span class="line">            self.backtrack(<span class="string">""</span>, digits, phone, output)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backtrack</span><span class="params">(self, combination, digit, phone, output)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> len(digit)==<span class="number">0</span>:</span><br><span class="line">            output.append(combination)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> letter <span class="keyword">in</span> phone[digit[<span class="number">0</span>]]:</span><br><span class="line">            self.backtrack(combination+letter,digit[<span class="number">1</span>:], phone, output)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/电话号码的字母组合/4.jpg" alt="4"></p>
<p><img src="/2020/01/02/电话号码的字母组合/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>回溯算法</tag>
      </tags>
  </entry>
  <entry>
    <title>盛最多水的容器</title>
    <url>/2020/01/02/%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/container-with-most-water/" target="_blank" rel="noopener">盛最多水的容器（难度：中等）</a></p>
<p><img src="/2020/01/02/盛最多水的容器/1.jpg" alt="1"></p>
<h4 id="方法：双指针"><a href="#方法：双指针" class="headerlink" title="方法：双指针"></a>方法：双指针</h4><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>两线段之间形成的区域总是会受到其中较短那条长度的限制。此外，两线段距离越远，得到的面积就越大。</p>
<h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><ul>
<li><strong>在由线段长度构成的数组中使用两个指针，一个放在开始，一个置于末尾</strong>。</li>
<li>使用变量 max_area来持续存储到目前为止所获得的最大面积。 </li>
<li>在每一步中，我们会找出指针所指向的两条线段形成的区域，更新 max_area，<strong>并将指向较短线段的指针向较长线段那端移动一步</strong>。</li>
</ul>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)，一次扫描。</p>
<p>空间复杂度：O(1)，使用恒定的空间。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxArea</span><span class="params">(<span class="keyword">int</span>[] height)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = height.length - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> max_area = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">            max_area = Math.max(max_area, Math.min(height[left],height[right]) * (right-left));</span><br><span class="line">            <span class="keyword">if</span>(height[left] &lt; height[right])</span><br><span class="line">                left++;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                right--;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> max_area;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/盛最多水的容器/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>双指针</tag>
      </tags>
  </entry>
  <entry>
    <title>正则表达式匹配</title>
    <url>/2020/01/02/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/regular-expression-matching/" target="_blank" rel="noopener">正则表达式匹配（难度：困难）</a></p>
<p><img src="/2020/01/02/正则表达式匹配/1.jpg" alt="1"></p>
<p>转自：</p>
<blockquote>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/regular-expression-matching/solution/ji-yu-guan-fang-ti-jie-gen-xiang-xi-de-jiang-jie-b/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/regular-expression-matching/solution/ji-yu-guan-fang-ti-jie-gen-xiang-xi-de-jiang-jie-b/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<h4 id="一、处理点号「-」通配符"><a href="#一、处理点号「-」通配符" class="headerlink" title="一、处理点号「.」通配符"></a>一、处理点号「.」通配符</h4><p>点号可以匹配任意一个字符，其实是最简单的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(text, pattern)</span> -&gt; bool:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pattern: <span class="keyword">return</span> <span class="keyword">not</span> text</span><br><span class="line">    first_match = bool(text) <span class="keyword">and</span> pattern[<span class="number">0</span>] <span class="keyword">in</span> &#123;text[<span class="number">0</span>], <span class="string">'.'</span>&#125;</span><br><span class="line">    <span class="keyword">return</span> first_match <span class="keyword">and</span> isMatch(text[<span class="number">1</span>:], pattern[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure>
<h4 id="二、处理「-」通配符"><a href="#二、处理「-」通配符" class="headerlink" title="二、处理「*」通配符"></a>二、处理「*」通配符</h4><p>星号通配符可以让前一个字符重复任意次数，包括零次。那到底是重复几次呢？这需要计算机暴力穷举来算，假设重复 N 次吧。写递归的技巧是管好当下，之后的事抛给递归。具体到这里，不管 N 是多少，当前的选择只有两个：匹配 0 次、匹配 1 次。所以可以这样处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(text, pattern)</span> -&gt; bool:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> pattern: <span class="keyword">return</span> <span class="keyword">not</span> text</span><br><span class="line">    first_match = bool(text) <span class="keyword">and</span> pattern[<span class="number">0</span>] <span class="keyword">in</span> &#123;text[<span class="number">0</span>], <span class="string">'.'</span>&#125;</span><br><span class="line">    <span class="keyword">if</span> len(pattern) &gt;= <span class="number">2</span> <span class="keyword">and</span> pattern[<span class="number">1</span>] == <span class="string">'*'</span>:</span><br><span class="line">        <span class="comment"># 发现 '*' 通配符</span></span><br><span class="line">        <span class="keyword">return</span> isMatch(text, pattern[<span class="number">2</span>:]) <span class="keyword">or</span> \</span><br><span class="line">                first_match <span class="keyword">and</span> isMatch(text[<span class="number">1</span>:], pattern)</span><br><span class="line">    	<span class="comment"># 解释：如果发现有字符和 '*' 结合，</span></span><br><span class="line">        	<span class="comment"># 或者匹配该字符 0 次，然后跳过该字符和 '*'</span></span><br><span class="line">        	<span class="comment"># 或者当 pattern[0] 和 text[0] 匹配后，移动 text</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> first_match <span class="keyword">and</span> isMatch(text[<span class="number">1</span>:], pattern[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure>
<p>可以看到，我们是通过保留 pattern 中的「*」，同时向后推移 text，来实现「*」将字符重复匹配多次的功能。</p>
<h4 id="三、动态规划"><a href="#三、动态规划" class="headerlink" title="三、动态规划"></a>三、动态规划</h4><h5 id="暴力解法"><a href="#暴力解法" class="headerlink" title="暴力解法"></a>暴力解法</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(self, s: str, p: str)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> p:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">not</span> s</span><br><span class="line">        </span><br><span class="line">        first = s <span class="keyword">and</span> p[<span class="number">0</span>] <span class="keyword">in</span> &#123;s[<span class="number">0</span>],<span class="string">'.'</span>&#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> len(p) &gt;= <span class="number">2</span> <span class="keyword">and</span> p[<span class="number">1</span>]==<span class="string">'*'</span>:</span><br><span class="line">            <span class="keyword">return</span> self.isMatch(s,p[<span class="number">2</span>:]) <span class="keyword">or</span> (first <span class="keyword">and</span> self.isMatch(s[<span class="number">1</span>:],p))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> first <span class="keyword">and</span> self.isMatch(s[<span class="number">1</span>:],p[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/正则表达式匹配/2.jpg" alt="2"></p>
<h5 id="优化解法"><a href="#优化解法" class="headerlink" title="优化解法"></a>优化解法</h5><p>使用两个变量 <code>i</code>, <code>j</code> 记录当前匹配到的位置，从而避免使用子字符串切片，并且将 <code>i</code>, <code>j</code> 存入memo，避免重复计算。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isMatch</span><span class="params">(self, s: str, p: str)</span> -&gt; bool:</span></span><br><span class="line">        memo = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dp</span><span class="params">(i,j)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> (i,j) <span class="keyword">in</span> memo:</span><br><span class="line">                <span class="keyword">return</span> memo[(i,j)]</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> j==len(p):</span><br><span class="line">                <span class="keyword">return</span> i==len(s)</span><br><span class="line">            </span><br><span class="line">            first = i &lt; len(s) <span class="keyword">and</span> p[j] <span class="keyword">in</span> &#123;s[i],<span class="string">'.'</span>&#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> len(p) &gt;= j+<span class="number">2</span> <span class="keyword">and</span> p[j+<span class="number">1</span>]==<span class="string">'*'</span>:</span><br><span class="line">                <span class="keyword">return</span> dp(i,j+<span class="number">2</span>) <span class="keyword">or</span> (first <span class="keyword">and</span> dp(i+<span class="number">1</span>,j))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> first <span class="keyword">and</span> dp(i+<span class="number">1</span>,j+<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            memo[(i,j)] = ans</span><br><span class="line">            <span class="keyword">return</span> ans</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> dp(<span class="number">0</span>,<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/正则表达式匹配/3.jpg" alt="3"></p>
<h6 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h6><p>时间复杂度：用 T 和 P 分别表示匹配串和模式串的长度。对于 i=0, … , T 和 j=0, … , P 每一个 dp(i, j) 只会被计算一次，所以后面每次调用都是 O(1)的时间。因此，总时间复杂度为 O(TP) 。</p>
<p>空间复杂度：我们用到的空间仅有 O(TP)个 boolean 类型的缓存变量。所以，空间复杂度为 O(TP) 。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>单调递增的数字</title>
    <url>/2020/01/02/%E5%8D%95%E8%B0%83%E9%80%92%E5%A2%9E%E7%9A%84%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/monotone-increasing-digits/" target="_blank" rel="noopener">单调递增的数字（难度：中等）</a></p>
<p><img src="/2020/01/02/单调递增的数字/1.jpg" alt="1"></p>
<h4 id="方法："><a href="#方法：" class="headerlink" title="方法："></a>方法：</h4><p><img src="/2020/01/02/单调递增的数字/2.jpg" alt="2"></p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">monotoneIncreasingDigits</span><span class="params">(self, N: int)</span> -&gt; int:</span></span><br><span class="line">        s = list(str(N))</span><br><span class="line">        i = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;len(s) <span class="keyword">and</span> s[i<span class="number">-1</span>] &lt;= s[i]:</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> <span class="number">0</span> &lt; i &lt; len(s) <span class="keyword">and</span> s[i<span class="number">-1</span>] &gt; s[i]:</span><br><span class="line">            s[i<span class="number">-1</span>] = str(int(s[i<span class="number">-1</span>])<span class="number">-1</span>)</span><br><span class="line">            i-=<span class="number">1</span></span><br><span class="line">        s[i+<span class="number">1</span>:] = <span class="string">'9'</span>*(len(s)-i<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> int(<span class="string">''</span>.join(s))</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/单调递增的数字/3.jpg" alt="3"></p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(D)。其中 D≈logN，N 是数字的长度。<br>空间复杂度：O(D)。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>整数</tag>
      </tags>
  </entry>
  <entry>
    <title>移掉K位数字</title>
    <url>/2020/01/02/%E7%A7%BB%E6%8E%89K%E4%BD%8D%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/remove-k-digits/" target="_blank" rel="noopener">移掉K位数字（难度：中等）</a></p>
<p><img src="/2020/01/02/移掉K位数字/1.jpg" alt="1"></p>
<h4 id="方法：单调栈"><a href="#方法：单调栈" class="headerlink" title="方法：单调栈"></a>方法：单调栈</h4><p>维护一个递增栈，但当前元素小于栈顶元素，则移掉栈顶元素。</p>
<h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>转自</p>
<blockquote>
<p>作者：monkeybing<br>链接：<a href="https://leetcode-cn.com/problems/remove-k-digits/solution/cyu-yan-zhan-shi-xian-tan-xin-suan-fa-by-monkeybin/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/remove-k-digits/solution/cyu-yan-zhan-shi-xian-tan-xin-suan-fa-by-monkeybin/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>本题采用贪心思路：</p>
<ol>
<li>如果字符串按照数字大小升序排列，只需要删除最后K个字符即可；</li>
<li>如果非升序排列，需要从前到后遍历，删除字符串中每个逆序排列的字符。由于是从前到后遍历，所以先删除的一定是高位的数字，可以保证删除后得到的最终数字最小。</li>
</ol>
<p>举例来说：如果字符串num = “123456789”, k = 3，我们只需要删除最后3个数字，得到”123456”.<br>如果字符串num = “1432219”, k = 3，需要从前到后遍历查找逆序数字，进行删除，第一个逆序数字为’4’，第二个逆序数字为’3’，第三个逆序数字为第二个’2’，最后得到”1219”。</p>
<p><strong>所以可以采用栈实现，每次遍历，判断如果栈非空，且当前数字大于栈顶数字，且k还有剩余（不为0），将栈顶数字出栈。最后将当前数字入栈。</strong><br>如果遍历完成后，k仍有剩余，则依次将栈顶数字出栈。最后栈中保存的数字即为所求。按照从栈底到栈顶输出即可。<br>注意：特判场景，如果最后所有数字均出栈，即栈为空，需要返回”0”。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeKdigits</span><span class="params">(self, num: str, k: int)</span> -&gt; str:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> num <span class="keyword">or</span> k &lt;=<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> num</span><br><span class="line">        </span><br><span class="line">        stack = []</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> num:</span><br><span class="line">            <span class="keyword">while</span> stack <span class="keyword">and</span> k &gt; <span class="number">0</span> <span class="keyword">and</span> stack[<span class="number">-1</span>] &gt; c:</span><br><span class="line">                stack.pop()</span><br><span class="line">                k -= <span class="number">1</span></span><br><span class="line">            stack.append(c)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> k &gt; <span class="number">0</span>:</span><br><span class="line">            stack.pop()</span><br><span class="line">            k -= <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> stack:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'0'</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> str(int(<span class="string">''</span>.join(stack)))</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/02/移掉K位数字/2.jpg" alt="2"></p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n).</p>
<p>空间复杂度：O(n).</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>栈</tag>
        <tag>字符串</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title>贪心算法</title>
    <url>/2020/01/01/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>转自：</p>
<blockquote>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/non-overlapping-intervals/solution/tan-xin-suan-fa-zhi-qu-jian-diao-du-wen-ti-by-labu/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/non-overlapping-intervals/solution/tan-xin-suan-fa-zhi-qu-jian-diao-du-wen-ti-by-labu/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>什么是贪心算法呢？贪心算法可以认为是动态规划算法的一个特例，相比动态规划，使用贪心算法需要满足更多的条件（贪心选择性质），但是效率比动态规划要高。</p>
<p>比如说一个算法问题使用暴力解法需要指数级时间，如果能使用动态规划消除重叠子问题，就可以降到多项式级别的时间，如果满足贪心选择性质，那么可以进一步降低时间复杂度，达到线性级别的。</p>
<p>什么是贪心选择性质呢，简单说就是：每一步都做出一个局部最优的选择，最终的结果就是全局最优。注意哦，这是一种特殊性质，其实只有一部分问题拥有这个性质。</p>
<p>比如你面前放着 100 张人民币，你只能拿十张，怎么才能拿最多的面额？显然每次选择剩下钞票中面值最大的一张，最后你的选择一定是最优的。</p>
<p>然而，大部分问题明显不具有贪心选择性质。比如打牌，对手出对儿三，按照贪心策略，你应该出尽可能小的牌刚好压制住对方，但现实情况我们甚至可能会出王炸。这种情况就不能用贪心算法，而得使用动态规划解决，参见前文<a href="https://leetcode-cn.com/problems/stone-game/solution/jie-jue-bo-yi-wen-ti-de-dong-tai-gui-hua-tong-yong/" target="_blank" rel="noopener">动态规划解决博弈问题</a>。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>无重叠区间</title>
    <url>/2020/01/01/%E6%97%A0%E9%87%8D%E5%8F%A0%E5%8C%BA%E9%97%B4/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/non-overlapping-intervals/" target="_blank" rel="noopener">无重叠区间（难度：中等）</a></p>
<p><img src="/2020/01/01/无重叠区间/1.jpg" alt="1"></p>
<p>转自：</p>
<blockquote>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/non-overlapping-intervals/solution/tan-xin-suan-fa-zhi-qu-jian-diao-du-wen-ti-by-labu/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/non-overlapping-intervals/solution/tan-xin-suan-fa-zhi-qu-jian-diao-du-wen-ti-by-labu/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>本文解决一个很经典的贪心算法问题 Interval Scheduling（区间调度问题）。给你很多形如 <code>[start, end]</code>的闭区间，请你设计一个算法，算出这些区间中最多有几个互不相交的区间。<br>举个例子，<code>intvs = [[1,3], [2,4], [3,6]]</code>，这些区间最多有 2 个区间互不相交，即 <code>[[1,3], [3,6]]</code>，你的算法应该返回 2。注意边界相同并不算相交。</p>
<p>这个问题在生活中的应用广泛，比如你今天有好几个活动，每个活动都可以用区间 [start, end] 表示开始和结束的时间，请问你今天最多能参加几个活动呢？显然你一个人不能同时参加两个活动，所以说这个问题就是求这些时间区间的最大不相交子集。</p>
<h4 id="方法：贪心算法"><a href="#方法：贪心算法" class="headerlink" title="方法：贪心算法"></a>方法：贪心算法</h4><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><ol>
<li>从区间集合 intvs 中选择一个区间 x，这个 x 是在当前所有区间中结束最早的（end 最小）。</li>
<li>把所有与 x 区间相交的区间从区间集合 intvs 中删除。</li>
<li>重复步骤 1 和 2，直到 intvs 为空为止。之前选出的那些 x 就是最大不相交子集。</li>
</ol>
<p><img src="https://pic.leetcode-cn.com/678752f150168fc2e53a36d30e589b76ef81a95943c018b01bef6a548bfafeeb-file_1566313617208" alt="1"></p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">eraseOverlapIntervals</span><span class="params">(<span class="keyword">int</span>[][] intervals)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (intervals.length == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        </span><br><span class="line">		<span class="comment">// 按区间的end升序排列</span></span><br><span class="line">        Arrays.sort(intervals, <span class="keyword">new</span> Comparator&lt;<span class="keyword">int</span>[]&gt;()&#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span>[] b)</span></span>&#123;</span><br><span class="line">                <span class="keyword">return</span> a[<span class="number">1</span>] - b[<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">int</span> x_end = intervals[<span class="number">0</span>][<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>[] intv:intervals)&#123;</span><br><span class="line">            <span class="keyword">int</span> start = intv[<span class="number">0</span>];</span><br><span class="line">            <span class="keyword">if</span>(x_end &lt;= start)&#123;</span><br><span class="line">                count++;</span><br><span class="line">                x_end = intv[<span class="number">1</span>];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> intervals.length - count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(nlogn). 排序需要O(nlogn)的时间。</p>
<p>空间复杂度：O(1). 不需要额外空间。</p>
<p><img src="/2020/01/01/无重叠区间/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>区间</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title>判断子序列</title>
    <url>/2020/01/01/%E5%88%A4%E6%96%AD%E5%AD%90%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/is-subsequence/" target="_blank" rel="noopener">判断子序列（难度：简单）</a></p>
<p><img src="/2020/01/01/判断子序列/3.jpg" alt="3"></p>
<h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><p>利用Python切片，对s中的每个字符，若在t中，下一步比较index+1开始的字符串</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSubsequence</span><span class="params">(self, s: str, t: str)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> s:</span><br><span class="line">            <span class="keyword">if</span> i <span class="keyword">in</span> t:</span><br><span class="line">                t = t[t.index(i)+<span class="number">1</span>:]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/01/判断子序列/1.jpg" alt="1"></p>
<hr>
<h4 id="方法二：双指针"><a href="#方法二：双指针" class="headerlink" title="方法二：双指针"></a>方法二：双指针</h4><p>若相等，两个指针都往前移，若不等，快指针往前移。最后比较慢指针与s的长度。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isSubsequence</span><span class="params">(self, s: str, t: str)</span> -&gt; bool:</span></span><br><span class="line">        p1 = <span class="number">0</span></span><br><span class="line">        p2 = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> p1 &lt; len(s) <span class="keyword">and</span> p2 &lt; len(t):</span><br><span class="line">            <span class="keyword">if</span> s[p1] == t[p2]:</span><br><span class="line">                p1 += <span class="number">1</span></span><br><span class="line">            p2 += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> p1 == len(s):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/01/判断子序列/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title>缺失的第一个正数</title>
    <url>/2019/12/31/%E7%BC%BA%E5%A4%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%AD%A3%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/first-missing-positive/" target="_blank" rel="noopener">缺失的第一个正数（难度：困难）</a></p>
<p><img src="/2019/12/31/缺失的第一个正数/4.jpg" alt="4"></p>
<h4 id="方法一（空间复杂度不满足要求）"><a href="#方法一（空间复杂度不满足要求）" class="headerlink" title="方法一（空间复杂度不满足要求）"></a>方法一（空间复杂度不满足要求）</h4><p>遍历一遍数组，将元素装入HashSet，再从1开始，判断元素是否在HashSet中，若不存在，则该数为缺失的第一个正数。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n).</p>
<p>空间复杂度：O(n). </p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">firstMissingPositive</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Set&lt;Integer&gt; set = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num:nums)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!set.contains(num))</span><br><span class="line">                set.add(num);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> n = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(set.contains(n))</span><br><span class="line">                n++;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="keyword">return</span> n;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/缺失的第一个正数/1.jpg" alt="1"></p>
<hr>
<h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><h5 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h5><p>通过预处理保证数组中的数全为正数，遍历数组，当读到数字 a 时，替换索引a 处元素的符号为负数。最后返回正数所对应的索引。</p>
<h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><ul>
<li>首先检查1是否存在于数组中。如果没有，则已经完成，1 即为答案。</li>
<li>若1在数组中，则可将负数，零，和大于 n 的数替换为 1 。</li>
<li>遍历数组。当读到数字 a 时，替换索引a 处元素的符号。（即若数组中出现1，改变nums[1]的符号；若出现2，改变nums[2]的符号）<br>注意重复元素：只能改变一次符号。由于遇到数字n时，没有下标 n ，则使用索引0 处的元素来保存是否存在数字 n。</li>
<li>返回结果：<ul>
<li>从1开始遍历数组。返回第一个正数元素的下标。</li>
<li>如果 nums[0] &gt; 0，则返回 n 。</li>
<li>如果之前的步骤中没有发现 nums 中有正数元素，则返回n + 1。</li>
</ul>
</li>
</ul>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n).所有的操作一共只会遍历长度为 <code>N</code> 的数组 4 次。</p>
<p>空间复杂度：O(1).只使用了常数的空间。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">firstMissingPositive</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = nums.length;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(nums.length == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 查看数组中是否包含1</span></span><br><span class="line">        <span class="keyword">int</span> contains = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]==<span class="number">1</span>)&#123;</span><br><span class="line">                contains += <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(contains==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 替换小于等于0的数及大于n的数为1</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&lt;=<span class="number">0</span> || nums[i] &gt; n)</span><br><span class="line">                nums[i] = <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 遍历数组</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> a = Math.abs(nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(a==n)</span><br><span class="line">                nums[<span class="number">0</span>] = -Math.abs(nums[<span class="number">0</span>]);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                nums[a] = -Math.abs(nums[a]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 返回结果（索引0处要单独判断，因为若数组中未出现n,则nums[0]处的值会为正数，但不该返回索引0）</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; n; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&gt;<span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(nums[<span class="number">0</span>]&gt;<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> n;</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> n+<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/缺失的第一个正数/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>寻找重复数</title>
    <url>/2019/12/31/%E5%AF%BB%E6%89%BE%E9%87%8D%E5%A4%8D%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/find-the-duplicate-number/" target="_blank" rel="noopener">寻找重复数（难度：中等）</a></p>
<p><img src="/2019/12/31/寻找重复数/1.jpg" alt="1"></p>
<h4 id="方法一：排序"><a href="#方法一：排序" class="headerlink" title="方法一：排序"></a>方法一：排序</h4><h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：<em>O</em>(nlog(n))。</p>
<p>空间复杂度：O(1) (or O(n))，在这里，我们对 nums 进行排序，因此内存大小是恒定的。如果我们不能修改输入数组，那么我们必须为 nums 的副本分配线性空间，并对其进行排序。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findDuplicate</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]==nums[i-<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">return</span> nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/寻找重复数/2.jpg" alt="2"></p>
<hr>
<h4 id="方法二：集合（哈希表）"><a href="#方法二：集合（哈希表）" class="headerlink" title="方法二：集合（哈希表）"></a>方法二：集合（哈希表）</h4><h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)</p>
<p>空间复杂度：O(n)</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findDuplicate</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Set&lt;Integer&gt; set = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num : nums)&#123;</span><br><span class="line">            <span class="keyword">if</span>(set.contains(num))</span><br><span class="line">                <span class="keyword">return</span> num;</span><br><span class="line">            set.add(num);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/寻找重复数/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>缺失数字</title>
    <url>/2019/12/31/%E7%BC%BA%E5%A4%B1%E6%95%B0%E5%AD%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/missing-number/" target="_blank" rel="noopener">缺失数字（难度：简单）</a></p>
<p><img src="/2019/12/31/缺失数字/3.jpg" alt="3"></p>
<h4 id="方法一：数学方法"><a href="#方法一：数学方法" class="headerlink" title="方法一：数学方法"></a>方法一：数学方法</h4><p>用序列<code>[0,1,...,n]</code>的和减去给定的<code>nums</code>的和，可得到缺失的数字。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。</p>
<p>空间复杂度：O(1)。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">missingNumber</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        sum1 = sum(range(<span class="number">0</span>,len(nums)+<span class="number">1</span>)) <span class="comment"># 0,1,...,n 序列的和(或用高斯求和公式)</span></span><br><span class="line">        sum2 = sum(nums)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sum1 - sum2</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/缺失数字/1.jpg" alt="1"></p>
<p>高斯求和有溢出风险</p>
<hr>
<h4 id="方法二：位运算（异或运算）"><a href="#方法二：位运算（异或运算）" class="headerlink" title="方法二：位运算（异或运算）"></a>方法二：位运算（异或运算）</h4><p>先得到<code>[0,1,...,n]</code>的异或值，再将结果对数组<code>nums</code>中的每一个数进行一次异或运算，最终的异或结果即为这个缺失的数字。</p>
<p>在编写代码时，由于<code>[0,1,...,n]</code>恰好是这个数组的下标加上 n，因此可以用一次循环完成所有的异或运算。</p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。假设异或运算的时间复杂度是常数的。</p>
<p>空间复杂度：O(1)。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">missingNumber</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        res = len(nums) <span class="comment"># 一开始初始化为n</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(nums)):</span><br><span class="line">            res ^=  i ^ nums[i]</span><br><span class="line">        <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/31/缺失数字/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>回文链表</title>
    <url>/2019/12/29/%E5%9B%9E%E6%96%87%E9%93%BE%E8%A1%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/palindrome-linked-list/" target="_blank" rel="noopener">回文链表（难度：简单）</a></p>
<p><img src="/2019/12/29/回文链表/1.jpg" alt="1"></p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>使用快慢指针找到中点，对链表前半部分进行翻转。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)</p>
<p>空间复杂度：O(1)</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPalindrome</span><span class="params">(ListNode head)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(head==<span class="keyword">null</span> || head.next==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        </span><br><span class="line">        ListNode slow = head, fast = head;</span><br><span class="line">        ListNode pre = head, prepre = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 一遍遍历实现翻转前半部分</span></span><br><span class="line">        <span class="keyword">while</span>(fast != <span class="keyword">null</span> &amp;&amp; fast.next != <span class="keyword">null</span>)&#123;</span><br><span class="line">            pre = slow;</span><br><span class="line">            slow = slow.next;</span><br><span class="line">            fast = fast.next.next; <span class="comment">// 若链表长度为偶数，则fast最后会指向null，若为奇数，fast最后会指向最后一个元素</span></span><br><span class="line">            pre.next = prepre;</span><br><span class="line">            prepre = pre;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 循环结束后，若为偶数，slow指向后半部分第一个元素，若为奇数，slow指向中间的那个元素</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(fast != <span class="keyword">null</span>)</span><br><span class="line">            slow = slow.next;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span>(pre!=<span class="keyword">null</span> &amp;&amp; slow!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(pre.val != slow.val)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            pre = pre.next;</span><br><span class="line">            slow = slow.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/回文链表/2.jpg" alt="2"></p>
<p><img src="/2019/12/29/回文链表/20191229-214756.jpg" alt="20191229-214756"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>翻转二叉树</title>
    <url>/2019/12/29/%E7%BF%BB%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/invert-binary-tree/" target="_blank" rel="noopener">翻转二叉树（难度：简单）</a></p>
<p><img src="/2019/12/29/翻转二叉树/1.jpg" alt="1"></p>
<h4 id="方法：-递归"><a href="#方法：-递归" class="headerlink" title="方法： 递归"></a>方法： 递归</h4><h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n). 每个节点只被访问了一次。</p>
<p>空间复杂度：最坏情况下栈内需要存放 O(h)个方法调用，其中 h是树的高度。由于 h<em>∈</em>O<em>(</em>n)，可得出空间复杂度为 O(n)。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for a binary tree node.</span></span><br><span class="line"><span class="comment"> * public class TreeNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     TreeNode left;</span></span><br><span class="line"><span class="comment"> *     TreeNode right;</span></span><br><span class="line"><span class="comment"> *     TreeNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> TreeNode <span class="title">invertTree</span><span class="params">(TreeNode root)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(root==<span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> root;</span><br><span class="line">        TreeNode temp = invertTree(root.left);</span><br><span class="line">        root.left = invertTree(root.right);</span><br><span class="line">        root.right = temp;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/翻转二叉树/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title>存在重复元素2</title>
    <url>/2019/12/29/%E5%AD%98%E5%9C%A8%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/contains-duplicate-ii/" target="_blank" rel="noopener">存在重复元素2（难度：简单）</a></p>
<p><img src="/2019/12/29/存在重复元素2/1.jpg" alt="1"></p>
<h4 id="方法：哈希表"><a href="#方法：哈希表" class="headerlink" title="方法：哈希表"></a>方法：哈希表</h4><p>维护一个哈希表，里面始终最多包含 k 个元素，当出现重复值时则说明在 k 距离内存在重复元素。<br>每次遍历一个元素则将其加入哈希表中，如果哈希表的大小大于 k，则移除最前面的数字。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。我们会做 n 次 搜索，删除，插入操作，每次操作都耗费常数时间。</p>
<p>空间复杂度：O(min(n,k))。开辟的额外空间取决于散列表中存储的元素的个数，也就是滑动窗口的大小。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsNearbyDuplicate</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        Set&lt;Integer&gt; res = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(res.contains(nums[i]))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>; <span class="comment">// 因为res的大小维持为k</span></span><br><span class="line">            res.add(nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(res.size()&gt;k)</span><br><span class="line">                res.remove(nums[i-k]);   </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/存在重复元素2/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>存在重复元素</title>
    <url>/2019/12/29/%E5%AD%98%E5%9C%A8%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/contains-duplicate/" target="_blank" rel="noopener">存在重复元素（难度：简单）</a></p>
<p><img src="/2019/12/29/存在重复元素/1.jpg" alt="1"></p>
<h4 id="方法一：哈希表"><a href="#方法一：哈希表" class="headerlink" title="方法一：哈希表"></a>方法一：哈希表</h4><h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度 : O(n)。search() 和 insert() 各自使用 n 次，每个操作耗费常数时间。</p>
<p>空间复杂度 : O(n)。哈希表占用的空间与元素数量是线性关系。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsDuplicate</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Set&lt;Integer&gt; res = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num:nums)&#123;</span><br><span class="line">            <span class="keyword">if</span>(res.contains(num))</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            res.add(num);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/存在重复元素/3.jpg" alt="3"></p>
<p>另一种思路：利用Python中的set()，判断所得结果长度与原数组长度的关系</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">containsDuplicate</span><span class="params">(self, nums: List[int])</span> -&gt; bool:</span></span><br><span class="line">        set1 = set(nums)</span><br><span class="line">        <span class="keyword">if</span> len(set1) == len(nums):</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">True</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/存在重复元素/2.jpg" alt="2"></p>
<hr>
<h4 id="方法二：-排序"><a href="#方法二：-排序" class="headerlink" title="方法二： 排序"></a>方法二： 排序</h4><p>如果存在重复元素，排序后它们应该相邻。</p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度 : O<em>(</em>nlogn)。</p>
<p>空间复杂度 : O(1)。这取决于具体的排序算法实现，通常而言，使用 <code>堆排序</code> 的话，是 O(1)。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsDuplicate</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        Arrays.sort(nums);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]==nums[i+<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/存在重复元素/4.jpg" alt="4"></p>
<blockquote>
<p>注：对于一些特定的 n不太大的测试样例，方法一的运行速度可能会比方法二更慢。这是因为哈希表在维护其属性时有一些开销。要注意，程序的实际运行表现和 Big-O 符号表示可能有所不同。Big-O 只是告诉我们在 <strong>充分</strong>大的输入下，算法的相对快慢。因此，在 n不够大的情况下， O(n)的算法也可以比 O(nlogn)的更慢。</p>
</blockquote>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>数组中的第K个最大元素</title>
    <url>/2019/12/29/%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E7%AC%ACK%E4%B8%AA%E6%9C%80%E5%A4%A7%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/" target="_blank" rel="noopener">数组中的第K个最大元素（难度：中等）</a></p>
<p><img src="/2019/12/29/数组中的第K个最大元素/3.jpg" alt="3"></p>
<h4 id="方法一：排序"><a href="#方法一：排序" class="headerlink" title="方法一：排序"></a>方法一：排序</h4><p>先对数组进行排序，再返回倒数第 k 个元素。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(nlogn)</p>
<p>空间复杂度：O(1)</p>
<p>这个时间复杂度并不令人满意</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findKthLargest</span><span class="params">(self, nums: List[int], k: int)</span> -&gt; int:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">return</span> nums[-k]</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/数组中的第K个最大元素/1.jpg" alt="1"></p>
<hr>
<h4 id="方法二：最小堆"><a href="#方法二：最小堆" class="headerlink" title="方法二：最小堆"></a>方法二：最小堆</h4><p>建一个只能存K个数字的小顶堆，超过K时候，每加进来一个，堆顶就要弹出一个。数组遍历完，最终堆顶的元素就是第K大的（堆里其他元素都比它还要大）。</p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(nlogk). 向大小为 k 的堆中添加元素的时间复杂度为O(logk)，我们将重复该操作 n 次，故总时间复杂度为O(nlogk)。</p>
<p>空间复杂度：O(k).</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findKthLargest</span><span class="params">(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> k)</span> </span>&#123;</span><br><span class="line">        PriorityQueue&lt;Integer&gt; minHeap = <span class="keyword">new</span> PriorityQueue&lt;&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> num : nums)&#123;</span><br><span class="line">            minHeap.add(num);</span><br><span class="line">            <span class="keyword">if</span>(minHeap.size()&gt;k)</span><br><span class="line">                minHeap.poll();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> minHeap.poll();</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/29/数组中的第K个最大元素/2.jpg" alt="2"></p>
<hr>
<h4 id="方法三：快速选择"><a href="#方法三：快速选择" class="headerlink" title="方法三：快速选择"></a>方法三：快速选择</h4><p>详见<a href="https://leetcode-cn.com/problems/kth-largest-element-in-an-array/solution/shu-zu-zhong-de-di-kge-zui-da-yuan-su-by-leetcode/" target="_blank" rel="noopener">这里</a>.</p>
<h5 id="复杂度-2"><a href="#复杂度-2" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度 : 平均情况O<em>(</em>N)，最坏情况 O(N^2)。</p>
<p>空间复杂度 : O(1)。</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>移除链表元素</title>
    <url>/2019/12/29/%E7%A7%BB%E9%99%A4%E9%93%BE%E8%A1%A8%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/remove-linked-list-elements/" target="_blank" rel="noopener">移除链表元素（难度：简单）</a></p>
<p><img src="/2019/12/29/移除链表元素/1.jpg" alt="1"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">removeElements</span><span class="params">(ListNode head, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        ListNode dummy = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">        dummy.next = head;</span><br><span class="line"></span><br><span class="line">        ListNode cur = dummy;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(cur.next != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">if</span>(cur.next.val == val)&#123;</span><br><span class="line">                cur.next = cur.next.next;</span><br><span class="line">            &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">                cur = cur.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> dummy.next;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注：添加虚拟头节点解决头节点是要被删除的情况</p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>快乐数</title>
    <url>/2019/12/28/%E5%BF%AB%E4%B9%90%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/happy-number/" target="_blank" rel="noopener">快乐数（难度：简单）</a></p>
<p><img src="/2019/12/28/快乐数/2.jpg" alt="2"></p>
<h4 id="方法一：使用“快慢指针”思想找出循环"><a href="#方法一：使用“快慢指针”思想找出循环" class="headerlink" title="方法一：使用“快慢指针”思想找出循环"></a>方法一：使用“快慢指针”思想找出循环</h4><p>“快指针”每次走两步，“慢指针”每次走一步，当二者相等时，即为一个循环周期。此时，判断是不是因为1引起的循环，是的话就是快乐数，否则不是快乐数。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isHappy</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> slow = n;</span><br><span class="line">        <span class="keyword">int</span> fast = n;</span><br><span class="line">        <span class="keyword">do</span>&#123;</span><br><span class="line">            slow = helper(slow);</span><br><span class="line">            fast = helper(fast);</span><br><span class="line">            fast = helper(fast);</span><br><span class="line">        &#125; <span class="keyword">while</span>(slow != fast);</span><br><span class="line">        <span class="keyword">return</span> slow == <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">helper</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(n&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> re = n%<span class="number">10</span>;</span><br><span class="line">            sum += re*re;</span><br><span class="line">            n = n/<span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/快乐数/1.jpg" alt="1"></p>
<hr>
<h4 id="方法二：递归"><a href="#方法二：递归" class="headerlink" title="方法二：递归"></a>方法二：递归</h4><ul>
<li>不是快乐数的数称为不快乐数(unhappy number)，所有不快乐数的数位平方和计算，最后都会进入 4 → 16 → 37 → 58 → 89 → 145 → 42 → 20 → 4 的循环中</li>
<li>已知规律： [1 ~ 4] 中只有 1 是快乐数，[5 ~ ∞] 的数字要么回归到 1 要么回归到 4 或 3</li>
<li>因此仅需在 n &gt; 4 时调用递归</li>
</ul>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">isHappy</span><span class="params">(self, n: int)</span> -&gt; bool:</span></span><br><span class="line">        <span class="keyword">return</span> self.isHappy(sum(int(i) ** <span class="number">2</span> <span class="keyword">for</span> i <span class="keyword">in</span> str(n))) <span class="keyword">if</span> n &gt; <span class="number">4</span> <span class="keyword">else</span> n == <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/快乐数/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>求众数2</title>
    <url>/2019/12/28/%E6%B1%82%E4%BC%97%E6%95%B02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/majority-element-ii/" target="_blank" rel="noopener">求众数2（难度：中等）</a></p>
<p><img src="/2019/12/28/求众数2/1.jpg" alt="1"></p>
<h4 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h4><p>在Python中，先用set()找出所有出现的元素，再使用count()判断出现次数大于n/3的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums: List[int])</span> -&gt; List[int]:</span></span><br><span class="line">        set1 = set(nums)</span><br><span class="line">        <span class="keyword">return</span> [s <span class="keyword">for</span> s <span class="keyword">in</span> set1 <span class="keyword">if</span> nums.count(s) &gt; len(nums)//<span class="number">3</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/求众数2/2.jpg" alt="2"></p>
<p>然而时间复杂度不为O(n)。</p>
<hr>
<h4 id="方法二：Boyer-Moore-投票算法"><a href="#方法二：Boyer-Moore-投票算法" class="headerlink" title="方法二：Boyer-Moore 投票算法"></a>方法二：Boyer-Moore 投票算法</h4><p>超过n/3的数最多只能有两个。先选出两个候选人A,B（都令为nums[0]）。 遍历数组：</p>
<ol>
<li>若当前元素等于A，则A的票数++;</li>
<li><p>若当前元素等于B，则B的票数++；</p>
</li>
<li><p>若当前元素与A，B都不相等，那么检查此时A或B的票数是否减为0：</p>
<ul>
<li><p>若为0，则当前元素成为新的候选人；</p>
</li>
<li><p>若A、B票数均不为0，则A、B两个候选人的票数均减一；</p>
</li>
</ul>
</li>
</ol>
<p>遍历结束后选出了两个候选人，但是这两个候选人是否满足&gt;n//3，还需要再遍历一遍数组，找出两个候选人的具体票数。</p>
<p><strong>复杂度</strong></p>
<p>时间复杂度：O(n)</p>
<p>空间复杂度：O(1)</p>
<p><strong>代码</strong> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums: List[int])</span> -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span>(len(nums)==<span class="number">0</span>):</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        count1 = <span class="number">0</span></span><br><span class="line">        count2 = <span class="number">0</span></span><br><span class="line">        candidate1 = nums[<span class="number">0</span>]</span><br><span class="line">        candidate2 = nums[<span class="number">0</span>]</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num == candidate1:</span><br><span class="line">                count1 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> num == candidate2:</span><br><span class="line">                count2 += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> count1 == <span class="number">0</span>:</span><br><span class="line">                    candidate1 = num</span><br><span class="line">                    count1 += <span class="number">1</span></span><br><span class="line">                <span class="keyword">elif</span> count2 == <span class="number">0</span>:</span><br><span class="line">                    candidate2 = num</span><br><span class="line">                    count2 += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    count1 -= <span class="number">1</span>;</span><br><span class="line">                    count2 -= <span class="number">1</span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">return</span> set([num <span class="keyword">for</span> num <span class="keyword">in</span> [candidate1, candidate2] <span class="keyword">if</span> nums.count(num) &gt; len(nums)//<span class="number">3</span>]) <span class="comment">#加set的原因是避免返回两个相同的数</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/求众数2/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>多数元素</title>
    <url>/2019/12/28/%E5%A4%9A%E6%95%B0%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/majority-element/" target="_blank" rel="noopener">多数元素（难度：简单）</a></p>
<p><img src="/2019/12/28/多数元素/1.jpg" alt="1"></p>
<p><strong>注意：这样的元素只存在一个，因为出现次数大于n/2，若存在两个，则数组长度会超过n。</strong></p>
<h4 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a>方法一：</h4><p>在Python中，先用set()找出所有出现的元素，再使用count()判断出现次数大于n/2的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        set1 = set(nums)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> set1:</span><br><span class="line">            <span class="keyword">if</span> nums.count(s) &gt; len(nums)//<span class="number">2</span>:</span><br><span class="line">                <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/多数元素/2.jpg" alt="2"></p>
<hr>
<h4 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h4><p>先排序，再返回位于n/2位置的元素。</p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(nlogn)。用 Python 和 Java 将数组排序开销都为 O(nlogn)，它占据了运行的主要时间。</p>
<p>空间复杂度：O(1)或O(n)。就地排序或使用线性空间将 <code>nums</code> 数组拷贝，然后再排序。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        nums.sort()</span><br><span class="line">        <span class="keyword">return</span> nums[len(nums)//<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/多数元素/3.jpg" alt="3"></p>
<hr>
<h4 id="方法三：Boyer-Moore-投票算法"><a href="#方法三：Boyer-Moore-投票算法" class="headerlink" title="方法三：Boyer-Moore 投票算法"></a>方法三：Boyer-Moore 投票算法</h4><p>从第一个数开始count=1，遇到相同的就加1，遇到不同的就减1，减到0就重新换个数开始计数，最后总能找到最多的那个。</p>
<h5 id="复杂度-1"><a href="#复杂度-1" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n)。严格执行了 n 次循环。</p>
<p>空间复杂度：O(1)。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">majorityElement</span><span class="params">(self, nums: List[int])</span> -&gt; int:</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        candidate = nums[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> count == <span class="number">0</span>:</span><br><span class="line">                candidate = num</span><br><span class="line">            <span class="keyword">if</span> num==candidate:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                count -= <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> candidate</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/多数元素/4.jpg" alt="4"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>寻找峰值</title>
    <url>/2019/12/28/%E5%AF%BB%E6%89%BE%E5%B3%B0%E5%80%BC/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/find-peak-element/" target="_blank" rel="noopener">寻找峰值（难度：中等）</a></p>
<p><img src="/2019/12/28/寻找峰值/1.jpg" alt="1"></p>
<h4 id="方法一：线性扫描"><a href="#方法一：线性扫描" class="headerlink" title="方法一：线性扫描"></a>方法一：线性扫描</h4><p>利用连续的两个元素 <code>nums[j]</code> 和 <code>nums[j+1]</code> 不会相等这一事实，我们可以从头开始遍历 <code>nums</code>数组，当遇到<code>nums[i] &gt; nums[i+1]</code> ，即可判断 <code>nums[i]</code>为峰值。</p>
<p><strong>注意：不需要判断<code>nums[i]&gt;nums[i-1]</code>。这是由于“遍历会到达第i个元素”本身就说明上一个元素（第i- 1个）不满足 <code>nums[i] &gt; nums[i+1]</code>这一条件，也就说明 <code>nums[i-1] &lt; nums[i]</code>。</strong></p>
<h5 id="复杂度分析"><a href="#复杂度分析" class="headerlink" title="复杂度分析"></a>复杂度分析</h5><p>时间复杂度 : O(n)。  只进行一次遍历。<br>空间复杂度 : O(1)。 只使用了常数空间。</p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findPeakElement</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length - <span class="number">1</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i] &gt; nums[i+<span class="number">1</span>])</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nums.length-<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h4 id="方法二：二分法查找"><a href="#方法二：二分法查找" class="headerlink" title="方法二：二分法查找"></a>方法二：二分法查找</h4><h5 id="复杂度分析-1"><a href="#复杂度分析-1" class="headerlink" title="复杂度分析"></a>复杂度分析</h5><p>时间复杂度 : O(logn)。  每一步都将搜索空间减半。<br>空间复杂度 : O(1)。 只使用了常数空间。</p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findPeakElement</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> left = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> right = nums.length-<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = (left+right)/<span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span>(nums[mid]&gt;nums[mid+<span class="number">1</span>]) <span class="comment">// 往左搜索</span></span><br><span class="line">                right = mid;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&lt;nums[mid+<span class="number">1</span>]) <span class="comment">// 往右搜索</span></span><br><span class="line">                left = mid+<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> left;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/寻找峰值/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>最长重复子数组</title>
    <url>/2019/12/28/%E6%9C%80%E9%95%BF%E9%87%8D%E5%A4%8D%E5%AD%90%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/" target="_blank" rel="noopener">最长重复子数组（难度：中等）</a></p>
<p><img src="/2019/12/28/最长重复子数组/1.jpg" alt="1"></p>
<h4 id="方法：动态规划"><a href="#方法：动态规划" class="headerlink" title="方法：动态规划"></a>方法：动态规划</h4><blockquote>
<p>作者：LeetCode<br>链接：<a href="https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/solution/zui-chang-zhong-fu-zi-shu-zu-by-leetcode/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/maximum-length-of-repeated-subarray/solution/zui-chang-zhong-fu-zi-shu-zu-by-leetcode/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>设 <code>dp[i][j]</code>为 <code>A[i:]</code> 和 <code>B[j:]</code> 的最长公共前缀，那么答案为所有 <code>dp[i][j]</code> 中的最大值 <code>max(dp[i][j])</code>。若 <code>A[i] == B[j]</code>，状态转移方程为 <code>dp[i][j] = dp[i + 1][j + 1] + 1</code>，否则为 <code>dp[i][j] = 0</code>。</p>
<p><strong>复杂度分析</strong></p>
<p>时间复杂度：O(M*N)，其中 M和 N是数组 A 和 B 的长度。<br>空间复杂度：O(M*N)，即为数组 <code>dp</code> 使用的空间。</p>
<p><strong>代码</strong></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findLength</span><span class="params">(<span class="keyword">int</span>[] A, <span class="keyword">int</span>[] B)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[A.length+<span class="number">1</span>][B.length+<span class="number">1</span>]; <span class="comment">// 长度加1是为了后面的dp[i+1][j+1]</span></span><br><span class="line">        <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = A.length-<span class="number">1</span>; i&gt;=<span class="number">0</span>; i--)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = B.length-<span class="number">1</span>; j&gt;=<span class="number">0</span>; j--)&#123;</span><br><span class="line">                <span class="keyword">if</span>(A[i] == B[j])</span><br><span class="line">                    dp[i][j] = dp[i+<span class="number">1</span>][j+<span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">                res = Math.max(res,dp[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/28/最长重复子数组/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>最大连续1的个数</title>
    <url>/2019/12/27/%E6%9C%80%E5%A4%A7%E8%BF%9E%E7%BB%AD1%E7%9A%84%E4%B8%AA%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/max-consecutive-ones/" target="_blank" rel="noopener">最大连续1的个数（难度：简单）</a></p>
<p><img src="/2019/12/27/最大连续1的个数/1.jpg" alt="1"></p>
<h4 id="方法一：一次遍历"><a href="#方法一：一次遍历" class="headerlink" title="方法一：一次遍历"></a>方法一：一次遍历</h4><p><img src="/2019/12/27/最大连续1的个数/2.jpg" alt="2"></p>
<p><strong>复杂度分析</strong></p>
<ul>
<li>时间复杂度：O(N)。N是数组的长度。</li>
<li>空间复杂度：O(1)，仅仅使用了 <code>count</code> 和 <code>maxCount</code>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findMaxConsecutiveOnes</span><span class="params">(self, nums)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        maxcount = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> num <span class="keyword">in</span> nums:</span><br><span class="line">            <span class="keyword">if</span> num == <span class="number">0</span>:</span><br><span class="line">                maxcount = max(maxcount, count)</span><br><span class="line">                count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                count += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> max(maxcount,count)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/27/最大连续1的个数/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>区域和检索 - 数组不可变</title>
    <url>/2019/12/27/%E5%8C%BA%E5%9F%9F%E5%92%8C%E6%A3%80%E7%B4%A2-%E6%95%B0%E7%BB%84%E4%B8%8D%E5%8F%AF%E5%8F%98/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/range-sum-query-immutable/" target="_blank" rel="noopener">区域和检索 - 数组不可变（难度：简单）</a></p>
<p><img src="/2019/12/27/区域和检索-数组不可变/1.jpg" alt="1"></p>
<p><img src="/2019/12/27/区域和检索-数组不可变/2.jpg" alt="2"></p>
<hr>
<h5 id="方法二：-缓存"><a href="#方法二：-缓存" class="headerlink" title="方法二： 缓存"></a>方法二： 缓存</h5><p><img src="/2019/12/27/区域和检索-数组不可变/3.jpg" alt="3"></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NumArray</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] sum;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NumArray</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        sum = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length+<span class="number">1</span>]; <span class="comment">// 多增加一位</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            sum[i+<span class="number">1</span>] = sum[i] + nums[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sumRange</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> sum[j+<span class="number">1</span>] - sum[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Your NumArray object will be instantiated and called as such:</span></span><br><span class="line"><span class="comment"> * NumArray obj = new NumArray(nums);</span></span><br><span class="line"><span class="comment"> * int param_1 = obj.sumRange(i,j);</span></span><br><span class="line"><span class="comment"> */</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意，在上面的代码中，我们插入了一个虚拟 0 作为 sum 数组中的第一个元素。这个技巧可以避免在 sumrange 函数中进行额外的条件检查。</p>
</blockquote>
<p><img src="/2019/12/27/区域和检索-数组不可变/4.jpg" alt="4"></p>
<p><img src="/2019/12/27/区域和检索-数组不可变/5.jpg" alt="5"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>最长上升子序列</title>
    <url>/2019/12/27/%E6%9C%80%E9%95%BF%E4%B8%8A%E5%8D%87%E5%AD%90%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-increasing-subsequence/" target="_blank" rel="noopener">最长上升子序列（难度：中等）</a></p>
<p><img src="/2019/12/27/最长上升子序列/1.jpg" alt="1"></p>
<h4 id="方法：动态规划"><a href="#方法：动态规划" class="headerlink" title="方法：动态规划"></a>方法：动态规划</h4><p><img src="/2019/12/27/最长上升子序列/2.jpg" alt="2"></p>
<p><img src="/2019/12/27/最长上升子序列/3.jpg" alt="3"></p>
<p><img src="/2019/12/27/最长上升子序列/4.jpg" alt="4"></p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLIS</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.length==<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line">        <span class="keyword">int</span> ans = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            dp[i] = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(nums[i] &gt; nums[j])</span><br><span class="line">                    dp[i] = Math.max(dp[i], <span class="number">1</span> + dp[j]);</span><br><span class="line">            &#125;</span><br><span class="line">            ans = Math.max(ans, dp[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/27/最长上升子序列/5.jpg" alt="5"></p>
<h5 id="进阶：将时间复杂度降低到O-nlogn-。-使用贪心算法-二分查找"><a href="#进阶：将时间复杂度降低到O-nlogn-。-使用贪心算法-二分查找" class="headerlink" title="进阶：将时间复杂度降低到O(nlogn)。 使用贪心算法+二分查找"></a>进阶：将时间复杂度降低到O(nlogn)。 使用贪心算法+二分查找</h5>]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>完全平方数</title>
    <url>/2019/12/27/%E5%AE%8C%E5%85%A8%E5%B9%B3%E6%96%B9%E6%95%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/perfect-squares/" target="_blank" rel="noopener">完全平方数（难度：中等）</a></p>
<p><img src="/2019/12/27/完全平方数/1.jpg" alt="1"></p>
<h4 id="方法一：动态规划"><a href="#方法一：动态规划" class="headerlink" title="方法一：动态规划"></a>方法一：动态规划</h4><p>dp[i]表示i最少可以由几个平方数构成。</p>
<p>初试化dp=[0,1,2,…, n]，长度为n+1，最多次数就是全由1构成。</p>
<p>遍历dp，对于i，遍历区间[1,n]：</p>
<p>​        遍历所有平方数小于i的数j，遍历区间[1, sqrt(i)]</p>
<p>动态转移方程：</p>
<blockquote>
<p> dp[i] = min(dp[i], dp[i - j <em> j]+1)，i表示当前数字，j</em>j表示平方数</p>
</blockquote>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>时间复杂度：O(n*sqrt(n))</p>
<p>空间复杂度：O(n)</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">numSquares</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] dp = <span class="keyword">new</span> <span class="keyword">int</span>[n+<span class="number">1</span>]; <span class="comment">//dp[i]存放的是i最少可以由几个平方数构成， 初始化为[0,1,...,n]</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n; i++)&#123;</span><br><span class="line">            dp[i] = i;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; i-j*j &gt;= <span class="number">0</span>; j++)&#123;</span><br><span class="line">                dp[i] = Math.min(dp[i], dp[i-j*j]+<span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/27/完全平方数/2.jpg" alt="2"></p>
<hr>
<h4 id="方法二：广度优先搜索（BFS）"><a href="#方法二：广度优先搜索（BFS）" class="headerlink" title="方法二：广度优先搜索（BFS）"></a>方法二：广度优先搜索（BFS）</h4><p><img src="/2019/12/27/完全平方数/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>乘积最大子序列</title>
    <url>/2019/12/26/%E4%B9%98%E7%A7%AF%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/maximum-product-subarray/" target="_blank" rel="noopener">乘积最大子序列（难度：中等）</a></p>
<p><img src="/2019/12/26/乘积最大子序列/1.jpg" alt="1"></p>
<p><img src="/2019/12/26/乘积最大子序列/2.jpg" alt="2"></p>
<blockquote>
<p><strong>注意：不能只保存到当前为止的最大值，还需保存到当前为止的最小值，因为若下一个数是负数，那么以前的最小值（若为负数）会变成现在的最大值</strong>.</p>
</blockquote>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">maxProduct</span><span class="params">(<span class="keyword">int</span>[] nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> imax = nums[<span class="number">0</span>], imin = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">int</span> ans = nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(nums[i]&lt;<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">int</span> temp = imin;</span><br><span class="line">                imin = imax;</span><br><span class="line">                imax = temp;</span><br><span class="line">            &#125;</span><br><span class="line">            imax = Math.max(imax*nums[i], nums[i]);</span><br><span class="line">            imin = Math.min(imin*nums[i], nums[i]);</span><br><span class="line">            ans = Math.max(ans,imax);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ans;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/26/乘积最大子序列/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>链表中的下一个更大节点</title>
    <url>/2019/12/26/%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/next-greater-node-in-linked-list/" target="_blank" rel="noopener">链表中的下一个更大节点（难度：中等）</a></p>
<p><img src="/2019/12/26/链表中的下一个更大节点/1.jpg" alt="1"></p>
<p><img src="/2019/12/26/链表中的下一个更大节点/2.jpg" alt="2"></p>
<h4 id="方法：单调栈"><a href="#方法：单调栈" class="headerlink" title="方法：单调栈"></a>方法：单调栈</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] nextLargerNodes(ListNode head) &#123;</span><br><span class="line">        Stack&lt;Integer&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10000</span>];</span><br><span class="line">        <span class="keyword">int</span>[] arr2 = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">10000</span>];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> length = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(head != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="comment">// 栈里存放索引</span></span><br><span class="line">            arr2[length] = head.val;</span><br><span class="line">            <span class="keyword">while</span>(!stack.empty() &amp;&amp; arr2[stack.peek()] &lt; head.val)&#123;</span><br><span class="line">                arr[stack.pop()] = head.val;</span><br><span class="line">            &#125;</span><br><span class="line">            stack.push(length);</span><br><span class="line">            head = head.next;</span><br><span class="line">            length++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> res[] = <span class="keyword">new</span> <span class="keyword">int</span>[length];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;length; i++)&#123;</span><br><span class="line">            res[i] = arr[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/26/链表中的下一个更大节点/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>下一个更大元素2</title>
    <url>/2019/12/26/%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E5%85%83%E7%B4%A02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/next-greater-element-ii/" target="_blank" rel="noopener">下一个更大元素2（难度：中等）</a></p>
<p><img src="/2019/12/26/下一个更大元素2/1.jpg" alt="1"></p>
<h4 id="方法：单调栈"><a href="#方法：单调栈" class="headerlink" title="方法：单调栈"></a>方法：单调栈</h4><h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p>转自：</p>
<blockquote>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/next-greater-element-ii/solution/dan-diao-zhan-jie-jue-next-greater-number-yi-lei-2/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/next-greater-element-ii/solution/dan-diao-zhan-jie-jue-next-greater-number-yi-lei-2/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>同样是 Next Greater Number，现在假设给你的数组是个环形的，如何处理？</p>
<p>首先，计算机的内存都是线性的，没有真正意义上的环形数组，但是我们可以模拟出环形数组的效果，一般是通过 % 运算符求模（余数），获得环形特效：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] arr = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> n = arr.length, index = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    print(arr[index % n]);</span><br><span class="line">    index++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到 Next Greater Number 的问题，增加了环形属性后，问题的难点在于：<strong>这个 Next 的意义不仅仅是当前元素的右边了，有可能出现在当前元素的左边。</strong></p>
<p>我们可以考虑这样的思路：<strong>将原始数组 “翻倍”，</strong>就是在后面再接一个原始数组，这样的话，按照之前“比身高”的流程，每个元素不仅可以比较自己右边的元素，而且也可以和左边的元素比较了。</p>
<p><img src="https://pic.leetcode-cn.com/c6dda3c6d50dddbd4518619829834235a8f84be0f34f3b32974ad6d8e76cc3b1-file_1560500960943" alt="ink-image (2)"></p>
<h4 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h4><p>时间复杂度：O(n)</p>
<p>空间复杂度：O(n)</p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] nextGreaterElements(<span class="keyword">int</span>[] nums) &#123;</span><br><span class="line">        <span class="keyword">int</span> n = nums.length;</span><br><span class="line">        Stack&lt;Integer&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums.length];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>*n-<span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)&#123; <span class="comment">// i从2*n-1开始</span></span><br><span class="line">            <span class="keyword">while</span>(!stack.empty() &amp;&amp; stack.peek() &lt;= nums[i%n])&#123;</span><br><span class="line">                stack.pop();</span><br><span class="line">            &#125;</span><br><span class="line">            res[i%n] = stack.empty() ? -<span class="number">1</span> : stack.peek();</span><br><span class="line">            stack.push(nums[i%n]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/2019/12/26/下一个更大元素2/2.jpg" alt="2"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>打家劫舍3</title>
    <url>/2019/12/26/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/house-robber-iii/" target="_blank" rel="noopener">打家劫舍3（难度：中等）</a></p>
<p><img src="/2019/12/26/打家劫舍3/1.jpg" alt="题目"></p>
<p>以下内容转载自：</p>
<blockquote>
<p>作者：reals<br>链接：<a href="https://leetcode-cn.com/problems/house-robber-iii/solution/san-chong-fang-fa-jie-jue-shu-xing-dong-tai-gui-hu/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/house-robber-iii/solution/san-chong-fang-fa-jie-jue-shu-xing-dong-tai-gui-hu/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p>本题目本身就是动态规划的树形版本，通过此题解，可以了解一下树形问题在动态规划问题解法<br>我们通过3个方法不断递进解决问题</p>
<ul>
<li>解法1通过递归实现，虽然解决了问题，但是复杂度太高</li>
<li>解法2通过解决方法1中的重复子问题，实现了性能的百倍提升</li>
<li>解法3 直接省去了重复子问题，性能又提升了一步</li>
</ul>
<p><img src="/2019/12/26/打家劫舍3/2.jpg" alt="2"></p>
<p><img src="/2019/12/26/打家劫舍3/3.jpg" alt="3"></p>
<p><img src="/2019/12/26/打家劫舍3/4.jpg" alt="4"></p>
<p><img src="/2019/12/26/打家劫舍3/5.jpg" alt="5"></p>
<p><img src="/2019/12/26/打家劫舍3/6.jpg" alt="6"></p>
<p><img src="/2019/12/26/打家劫舍3/7.jpg" alt="7"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>打家劫舍2</title>
    <url>/2019/12/26/%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/house-robber-ii/" target="_blank" rel="noopener">打家劫舍2（难度：中等）</a></p>
<p><img src="/2019/12/26/打家劫舍2/题目.jpg" alt="题目"></p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p><strong>此题是 <a href>198. 打家劫舍</a> 的拓展版：</strong> 唯一的区别是此题中的房间是<strong>环状排列</strong>的（即首尾相接），而 198 题中的房间是<strong>单排排列</strong>的。</p>
<p><img src="/2019/12/26/打家劫舍2/1.jpg" alt="1"></p>
<p><img src="/2019/12/26/打家劫舍2/2.jpg" alt="2"></p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p><img src="/2019/12/26/打家劫舍2/3.jpg" alt="3"></p>
<p><img src="/2019/12/26/打家劫舍2/4.jpg" alt="4"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>创建单链表的头插法与尾插法</title>
    <url>/2019/12/26/%E5%88%9B%E5%BB%BA%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E5%A4%B4%E6%8F%92%E6%B3%95%E4%B8%8E%E5%B0%BE%E6%8F%92%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://blog.csdn.net/qq_41028985/article/details/82859199" target="_blank" rel="noopener">原文</a></p>
<h4 id="头插法创建单链表"><a href="#头插法创建单链表" class="headerlink" title="头插法创建单链表"></a>头插法创建单链表</h4><p><img src="/2019/12/26/创建单链表的头插法与尾插法/1577345110132.jpg" alt="图1"></p>
<p><img src="/2019/12/26/创建单链表的头插法与尾插法/1.jpg" alt="1"></p>
<h4 id="尾插法创建单链表"><a href="#尾插法创建单链表" class="headerlink" title="尾插法创建单链表"></a>尾插法创建单链表</h4><p><img src="/2019/12/26/创建单链表的头插法与尾插法/2.jpg" alt="2"></p>
<p><img src="/2019/12/26/创建单链表的头插法与尾插法/3.jpg" alt="3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>两数相加2</title>
    <url>/2019/12/26/%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/add-two-numbers-ii/" target="_blank" rel="noopener">两数相加2（难度：中等）</a></p>
<p><img src="/2019/12/26/两数相加2/1577344361644.jpg" alt="题目"></p>
<h4 id="方法：双栈-头插法"><a href="#方法：双栈-头插法" class="headerlink" title="方法：双栈 + 头插法"></a>方法：双栈 + 头插法</h4><p><img src="/2019/12/26/两数相加2/1577344797002.jpg" alt="code"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>下一个更大元素1</title>
    <url>/2019/12/25/%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%A4%A7%E5%85%83%E7%B4%A01/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/next-greater-element-i/" target="_blank" rel="noopener">下一个更大元素1（难度：简单）</a></p>
<p><img src="/2019/12/25/下一个更大元素1/1577281453752.jpg" alt="题目"></p>
<p><img src="/2019/12/25/下一个更大元素1/1577281497407.jpg" alt="方法"></p>
<p><img src="/2019/12/25/下一个更大元素1/1577281548614.jpg" alt="code"></p>
<h4 id="图解"><a href="#图解" class="headerlink" title="图解"></a>图解</h4><p><img src="/2019/12/25/下一个更大元素1/20191225-215434.jpg" alt="图解"></p>
<hr>
<h4 id="另一种写法（从后往前）"><a href="#另一种写法（从后往前）" class="headerlink" title="另一种写法（从后往前）"></a>另一种写法（从后往前）</h4><p>转自：</p>
<blockquote>
<p>作者：labuladong<br>链接：<a href="https://leetcode-cn.com/problems/next-greater-element-i/solution/dan-diao-zhan-jie-jue-next-greater-number-yi-lei-w/" target="_blank" rel="noopener">https://leetcode-cn.com/problems/next-greater-element-i/solution/dan-diao-zhan-jie-jue-next-greater-number-yi-lei-w/</a><br>来源：力扣（LeetCode）</p>
</blockquote>
<p><img src="/2019/12/25/下一个更大元素1/1.jpg" alt="1"></p>
<p>模板：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; nextGreaterElement(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;&amp; nums) &#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; ans(nums.size()); <span class="comment">// 存放答案的数组</span></span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = nums.size() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123; <span class="comment">// 倒着往栈里放</span></span><br><span class="line">        <span class="keyword">while</span> (!s.empty() &amp;&amp; s.top() &lt;= nums[i]) &#123; <span class="comment">// 判定个子高矮</span></span><br><span class="line">            s.pop(); <span class="comment">// 矮个起开，反正也被挡着了。。。</span></span><br><span class="line">        &#125;</span><br><span class="line">        ans[i] = s.empty() ? <span class="number">-1</span> : s.top(); <span class="comment">// 这个元素身后的第一个高个</span></span><br><span class="line">        s.push(nums[i]); <span class="comment">// 进队，接受之后的身高判定吧！</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>for 循环要从后往前扫描元素，因为我们借助的是栈的结构，倒着入栈，其实是正着出栈。while 循环是把两个“高个”元素之间的元素排除，因为他们的存在没有意义，前面挡着个“更高”的元素，所以他们不可能被作为后续进来的元素的 Next Great Number 了。</p>
<p>这个算法的时间复杂度不是那么直观，如果你看到 for 循环嵌套 while 循环，可能认为这个算法的复杂度也是 O(n^2)，但是实际上这个算法的复杂度只有 O(n)。</p>
<p>分析它的时间复杂度，要从整体来看：总共有 n 个元素，每个元素都被 push 入栈了一次，而最多会被 pop 一次，没有任何冗余操作。所以总的计算规模是和元素规模 n 成正比的，也就是 O(n) 的复杂度。</p>
<h5 id="本题代码"><a href="#本题代码" class="headerlink" title="本题代码"></a>本题代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] nextGreaterElement(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2) &#123;</span><br><span class="line">        Stack&lt;Integer&gt; stack = <span class="keyword">new</span> Stack&lt;&gt;();</span><br><span class="line">        Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[nums1.length];</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = nums2.length-<span class="number">1</span>; i &gt;= <span class="number">0</span>; i--)&#123; <span class="comment">// 倒着往栈里放</span></span><br><span class="line">            <span class="keyword">while</span>(!stack.empty() &amp;&amp; nums2[i]&gt;=stack.peek())&#123;</span><br><span class="line">                stack.pop();</span><br><span class="line">            &#125;</span><br><span class="line">            map.put(nums2[i],stack.empty()?-<span class="number">1</span>:stack.peek());</span><br><span class="line">            stack.push(nums2[i]);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums1.length; i++)</span><br><span class="line">            res[i] = map.get(nums1[i]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>数组</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title>删除列表中的节点</title>
    <url>/2019/12/25/%E5%88%A0%E9%99%A4%E5%88%97%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/delete-node-in-a-linked-list/" target="_blank" rel="noopener">删除列表中的节点（难度：简单）</a></p>
<p><img src="/2019/12/25/删除列表中的节点/捕获.JPG" alt="题目"></p>
<p><img src="/2019/12/25/删除列表中的节点/1577280000099.jpg" alt="方法"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>删除排序链表中的重复元素2</title>
    <url>/2019/12/25/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A02/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list-ii/" target="_blank" rel="noopener">删除排序链表中的重复元素2（难度：中等）</a></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素2/1577278156148.jpg" alt="题目"></p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p><img src="/2019/12/25/删除排序链表中的重复元素2/1577278207894.jpg" alt="1577278207894"></p>
<h4 id="画解"><a href="#画解" class="headerlink" title="画解"></a>画解</h4><p><img src="/2019/12/25/删除排序链表中的重复元素2/20191225-210253.jpg" alt="画解"></p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p>(Java)</p>
<p><img src="/2019/12/25/删除排序链表中的重复元素2/1577279243671.jpg" alt="code"></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素2/1577279306551.jpg" alt="结果"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>删除排序链表中的重复元素</title>
    <url>/2019/12/25/%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-list/" target="_blank" rel="noopener">删除排序链表中的重复元素（难度：简单）</a></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素/1577268363569.jpg" alt="题目"></p>
<h4 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h4><p><img src="/2019/12/25/删除排序链表中的重复元素/1577268482086.jpg" alt="思路"></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素/1577268503067.jpg" alt="1577268503067"></p>
<h4 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h4><p><img src="/2019/12/25/删除排序链表中的重复元素/1577268572469.jpg" alt="1577268572469"></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素/1577268850082.jpg" alt="结果"></p>
<h4 id="画解"><a href="#画解" class="headerlink" title="画解"></a>画解</h4><p><img src="/2019/12/25/删除排序链表中的重复元素/1577268614488.jpg" alt="画解1"></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素/1577268643223.jpg" alt="画解2"></p>
<p><img src="/2019/12/25/删除排序链表中的重复元素/1577268718737.jpg" alt="画解3"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>最长回文串</title>
    <url>/2019/12/25/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E4%B8%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-palindrome/" target="_blank" rel="noopener">最长回文串（难度：简单）</a></p>
<p><img src="/2019/12/25/最长回文串/1577266515330.jpg" alt="题目"></p>
<p><img src="/2019/12/25/最长回文串/20191225-174159.jpg" alt="思路"></p>
<p><img src="/2019/12/25/最长回文串/1577267022201.jpg" alt="code"></p>
<p><img src="/2019/12/25/最长回文串/1577267058050.jpg" alt="结果"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>回文</tag>
      </tags>
  </entry>
  <entry>
    <title>最长回文子串</title>
    <url>/2019/12/25/%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/" target="_blank" rel="noopener">最长回文子串（难度：中等）</a></p>
<p><img src="/2019/12/25/最长回文子串/0001.jpg" alt="0001"></p>
<p><img src="/2019/12/25/最长回文子串/0002.jpg" alt="0002"></p>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>回文</tag>
      </tags>
  </entry>
  <entry>
    <title>最长公共子序列</title>
    <url>/2019/12/25/%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://leetcode-cn.com/problems/longest-common-subsequence/" target="_blank" rel="noopener">最长公共子序列（难度：中等）</a></p>
<p><img src="/2019/12/25/最长公共子序列/question.JPG" alt="题目"></p>
<h3 id="方法：动态规划"><a href="#方法：动态规划" class="headerlink" title="方法：动态规划"></a>方法：动态规划</h3><p><img src="/2019/12/25/最长公共子序列/1.JPG" alt="图1"></p>
<p><img src="/2019/12/25/最长公共子序列/2.JPG" alt="图2"></p>
<h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><p><img src="/2019/12/25/最长公共子序列/code.JPG" alt="code"></p>
<p><img src="/2019/12/25/最长公共子序列/3.JPG" alt="图3"></p>
<h5 id="复杂度"><a href="#复杂度" class="headerlink" title="复杂度"></a>复杂度</h5><p>数据复杂度：O(mn)</p>
<p>空间复杂度：O(mn)</p>
<hr>
<h4 id="最长公共子串"><a href="#最长公共子串" class="headerlink" title="最长公共子串"></a>最长公共子串</h4><p>最长公共子串（Longest Common Substring）与最长公共子序列（Longest Common Subsequence）的区别： <strong>子串要求在原字符串中是连续的，而子序列则只需保持相对顺序一致，并不要求连续</strong>。例如X = {a, Q, 1, 1}; Y = {a, 1, 1, d, f}那么，{a, 1, 1}是X和Y的最长公共子序列，但不是它们的最长公共字串。</p>
<p><strong>描述：</strong></p>
<p>计算两个字符串的最大公共子串（Longest Common Substring）的长度，字符不区分大小写。</p>
<p><strong>方法</strong></p>
<p>求子串的方法和求子序列方法类似：</p>
<p><img src="/2019/12/25/最长公共子序列/1578644196190.png" alt="1578644196190"></p>
<h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">longestCommonSubsequence</span><span class="params">(String text1, String text2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n1 = text1.length();</span><br><span class="line">        <span class="keyword">int</span> n2 = text2.length();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> dp[][] = <span class="keyword">new</span> <span class="keyword">int</span>[n1+<span class="number">1</span>][n2+<span class="number">1</span>]; <span class="comment">//多增加一行一列</span></span><br><span class="line">        <span class="keyword">int</span> longest = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= n1; i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>; j &lt;= n2; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(text1.charAt(i-<span class="number">1</span>) == text2.charAt(j-<span class="number">1</span>))</span><br><span class="line">                    dp[i][j] = dp[i-<span class="number">1</span>][j-<span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">                    longest = Math.max(longest,dp[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> longest;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>HDFS-Overview</title>
    <url>/2019/12/16/HDFS-Overview/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="/2019/12/16/HDFS-Overview/0001.jpg" alt="0001"></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>HDFS and MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>Hadoop Introduction</title>
    <url>/2019/12/15/Hadoop-Introduction/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="History"><a href="#History" class="headerlink" title="History"></a>History</h1><p><img src="/2019/12/15/Hadoop-Introduction/hadoop-history.JPG" alt="hadoop-history"></p>
<h1 id="Hadoop-Ecosystem"><a href="#Hadoop-Ecosystem" class="headerlink" title="Hadoop Ecosystem"></a>Hadoop Ecosystem</h1><p><img src="/2019/12/15/Hadoop-Introduction/hadoop-ecosystem.JPG" alt="hadoop-ecosystem"></p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>Hadoop Introduction</tag>
      </tags>
  </entry>
  <entry>
    <title>Data Preprocessing</title>
    <url>/2019/09/21/Data-Preprocessing/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>以下内容来自Udemy上的课程: <a href="https://www.udemy.com/machinelearning/" target="_blank" rel="noopener"><strong>Machine Learing A-Z: Hands-On Python &amp; R in Data Science</strong></a>.</p>
<p><a href="https://www.superdatascience.com/pages/machine-learning" target="_blank" rel="noopener">datasets download</a></p>
<p>使用数据：</p>
<p><img src="/2019/09/21/Data-Preprocessing/data.JPG" alt="data"></p>
<h2 id="1-Missing-data"><a href="#1-Missing-data" class="headerlink" title="1. Missing data"></a>1. Missing data</h2><p>Common strategy: replace the missing data by the mean, median, or most frequent value of the feature column.</p>
<h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Imputer</span><br><span class="line">imputer = Imputer(missing_values = <span class="string">'NaN'</span>, strategy = <span class="string">'mean'</span>, axis = <span class="number">0</span>)</span><br><span class="line">imputer = imputer.fit(X[:, <span class="number">1</span>:<span class="number">3</span>])</span><br><span class="line">X[:, <span class="number">1</span>:<span class="number">3</span>] = imputer.transform(X[:, <span class="number">1</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h4 id="R"><a href="#R" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = read.csv(<span class="string">'Data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Taking care of missing data</span></span><br><span class="line">dataset$Age = ifelse(is.na(dataset$Age),</span><br><span class="line">                     ave(dataset$Age, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                     dataset$Age)</span><br><span class="line">dataset$Salary = ifelse(is.na(dataset$Salary),</span><br><span class="line">                        ave(dataset$Salary, FUN = <span class="keyword">function</span>(x) mean(x, na.rm = <span class="literal">TRUE</span>)),</span><br><span class="line">                        dataset$Salary)</span><br><span class="line">                        </span><br><span class="line"><span class="comment"># 法二</span></span><br><span class="line">dataset$Age = ifelse(is.na(dataset$Age),</span><br><span class="line">                     mean(dataset$Age, na.rm = <span class="literal">TRUE</span>),</span><br><span class="line">                     dataset$Age)</span><br><span class="line"></span><br><span class="line">dataset$Salary = ifelse(is.na(dataset$Salary),</span><br><span class="line">                        mean(dataset$Salary, na.rm = <span class="literal">TRUE</span>),</span><br><span class="line">                        dataset$Salary)</span><br></pre></td></tr></table></figure>
<h2 id="2-Categorical-data"><a href="#2-Categorical-data" class="headerlink" title="2. Categorical data"></a>2. Categorical data</h2><h4 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/pic1.JPG" alt="pic1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/pic2.JPG" alt="pic2"></p>
<p>But the model will think that France has higher value than Spain -&gt; that’s not the case, we have no order here. 如果是S, M, L of a T-shirt, 不必使用下面的OneHotEncoder方法</p>
<p><img src="/2019/09/21/Data-Preprocessing/dummy-encoding.JPG" alt="dummy encoding"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])  <span class="comment"># which column you want to encode</span></span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result1.JPG" alt="result1"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Encoding the Dependent Variable</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">For the dependent variable, we are only going to use LabelEncoder, </span></span><br><span class="line"><span class="string">because since this is the dpendent variable, the machine learning model will know</span></span><br><span class="line"><span class="string">that it's a category, and that there is no oder between the two</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">labelencoder_y = LabelEncoder()</span><br><span class="line">y = labelencoder_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result2.JPG" alt="result2"></p>
<a id="more"></a>
<p>完整代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values</span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding categorical data</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding the Independent Variable</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder, OneHotEncoder</span><br><span class="line">labelencoder_X = LabelEncoder()</span><br><span class="line">X[:, <span class="number">0</span>] = labelencoder_X.fit_transform(X[:, <span class="number">0</span>])</span><br><span class="line">onehotencoder = OneHotEncoder(categorical_features = [<span class="number">0</span>])  <span class="comment"># which column you want to encode</span></span><br><span class="line">X = onehotencoder.fit_transform(X).toarray()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encoding the Dependent Variable</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">For the dependent variable, we are only going to use LabelEncoder, </span></span><br><span class="line"><span class="string">because since this is the dpendent variable, the machine learning model will know</span></span><br><span class="line"><span class="string">that it's a category, and that there is no oder between the two</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">labelencoder_y = LabelEncoder()</span><br><span class="line">y = labelencoder_y.fit_transform(y)</span><br></pre></td></tr></table></figure>
<h4 id="R-1"><a href="#R-1" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Encoding categorical data</span></span><br><span class="line">dataset$Country = factor(dataset$Country,</span><br><span class="line">                         levels = c(<span class="string">'France'</span>, <span class="string">'Spain'</span>, <span class="string">'Germany'</span>),</span><br><span class="line">                         labels = c(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line">dataset$Purchased = factor(dataset$Purchased,</span><br><span class="line">                           levels = c(<span class="string">'No'</span>, <span class="string">'Yes'</span>),</span><br><span class="line">                           labels = c(<span class="number">0</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/21/Data-Preprocessing/result3.JPG" alt="result3"></p>
<p><img src="/2019/09/21/Data-Preprocessing/result4.JPG" alt="result4"></p>
<h2 id="3-train-test-split"><a href="#3-train-test-split" class="headerlink" title="3. train_test_split"></a>3. train_test_split</h2><h4 id="Python-2"><a href="#Python-2" class="headerlink" title="Python"></a>Python</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values <span class="comment"># :-1 -&gt; take all the column except the last one</span></span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="R-2"><a href="#R-2" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = read.csv(<span class="string">'Data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages('caTools')</span></span><br><span class="line"><span class="keyword">library</span>(caTools)</span><br><span class="line">set.seed(<span class="number">123</span>)</span><br><span class="line">split = sample.split(dataset$Purchased, SplitRatio = <span class="number">0.8</span>) <span class="comment"># 这里取因变量</span></span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set = subset(dataset, split == <span class="literal">TRUE</span>)</span><br><span class="line">test_set = subset(dataset, split == <span class="literal">FALSE</span>)</span><br></pre></td></tr></table></figure>
<h2 id="4-Feature-Scaling"><a href="#4-Feature-Scaling" class="headerlink" title="4. Feature Scaling"></a>4. Feature Scaling</h2><p>Lots of machine learning models are based on Euclidean distance. Since the salary has a much wider range of values, the eulidean distance will be dominated by the salary. </p>
<p>Even if the machine learning models are not based on euclidean distance, we will still need to do feature scaling, because the algorithms will converge much faster, that will be the case for decision trees.</p>
<p><strong><em>Feature Scaling:</em></strong> Putting our variables in the same range (in the same scale),  so that no varaible is dominated by the other.</p>
<p><img src="/2019/09/21/Data-Preprocessing/feature-scaling.JPG" alt="feature scaling"></p>
<p><strong><em>Question 1: Do we need to fit and transform dummy variables?</em></strong></p>
<p><img src="/2019/09/21/Data-Preprocessing/show1.JPG" alt="show1"></p>
<p>It depends on the context. Depends on how much you want to keep interpretation in your models. Because if we scale dummy variables, it will be good because everything will be on the same scale, it will be good for our predicitons, but we will lose interpretation of knowing which observation belongs to which country.</p>
<p><strong><em>Qustion 2: Do we need to apply feature scaling to y?</em></strong></p>
<p>we don’t need to do it if it is a classification problem  with categorical dependent variable. But for regression, where the dependent variable will take a huge range of values, we will need to apply feature scaling to y as well.</p>
<h4 id="Python-3"><a href="#Python-3" class="headerlink" title="Python"></a>Python</h4><p>以下代码中scale了dummy variable</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Importing the dataset</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">'Data.csv'</span>)</span><br><span class="line">X = dataset.iloc[:, :<span class="number">-1</span>].values <span class="comment"># :-1 -&gt; take all the column except the last one</span></span><br><span class="line">y = dataset.iloc[:, <span class="number">3</span>].values</span><br><span class="line"></span><br><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line"><span class="comment"># most of time we don't need to do feature scaling, beacuse feature scaling is a tool</span></span><br><span class="line"><span class="comment"># included most of time in the machine learning libraries, </span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">sc_X = StandardScaler()</span><br><span class="line">X_train = sc_X.fit_transform(X_train)</span><br><span class="line">X_test = sc_X.transform(X_test)</span><br></pre></td></tr></table></figure>
<p>Feature scaling on X_test is the same as the feature scaling on the X_train(scaled on the same bases)</p>
<p><img src="/2019/09/21/Data-Preprocessing/result5.JPG" alt="result5"></p>
<p>The result is between -1 and 1.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sc_y = StandardScaler()</span><br><span class="line">y_train = sc_y.fit_transform(y_train.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<h4 id="R-3"><a href="#R-3" class="headerlink" title="R"></a>R</h4><figure class="highlight r"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Splitting the dataset into the Training set and Test set</span></span><br><span class="line"><span class="comment"># install.packages('caTools')</span></span><br><span class="line"><span class="keyword">library</span>(caTools)</span><br><span class="line">set.seed(<span class="number">123</span>)</span><br><span class="line">split = sample.split(dataset$Purchased, SplitRatio = <span class="number">0.8</span>)</span><br><span class="line"><span class="comment"># spilt结果为TRUE,FALSE, TRUE -&gt; go to training set, FALSE -&gt; go to test set</span></span><br><span class="line">training_set = subset(dataset, split == <span class="literal">TRUE</span>)</span><br><span class="line">test_set = subset(dataset, split == <span class="literal">FALSE</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feature Scaling</span></span><br><span class="line">training_set = scale(training_set)</span><br><span class="line">test_set = scale(test_set)</span><br></pre></td></tr></table></figure>
<p>直接这样运行会出错：</p>
<p><img src="/2019/09/21/Data-Preprocessing/result6.JPG" alt="result6"></p>
<p><img src="/2019/09/21/Data-Preprocessing/result7.JPG" alt="result7"></p>
<p>We’re going to exclude categories from the feature scaling, we’re not going to apply feature scaling on those columns.</p>
<figure class="highlight r"><table><tr><td class="code"><pre><span class="line">training_set[,<span class="number">2</span>:<span class="number">3</span>] = scale(training_set[,<span class="number">2</span>:<span class="number">3</span>])</span><br><span class="line">test_set[,<span class="number">2</span>:<span class="number">3</span>] = scale(test_set[,<span class="number">2</span>:<span class="number">3</span>])</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>MachineLearningA-Z</tag>
      </tags>
  </entry>
  <entry>
    <title>Python working directory</title>
    <url>/2019/09/17/Python-working-directory/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul>
<li>更改当前路径</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(<span class="string">"E:/machine learning"</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>获取当前路径</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd()</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>数据框操作</title>
    <url>/2019/09/02/dataframe-operation/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一、创建dataframe</p>
<ul>
<li>法一</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dat = pd.DataFrame(&#123;<span class="string">'id'</span>:[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], <span class="string">'string'</span>: [<span class="string">'a'</span>, <span class="string">'b'</span>,<span class="string">'c'</span>]&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li>法二（若已有现成的list）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dat = pd.DataFrame([n_clusters_start, score], columns = [<span class="string">"分类数"</span>, <span class="string">"得分"</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">exclamationCount = <span class="keyword">lambda</span> text: sum([<span class="number">1</span> <span class="keyword">for</span> x <span class="keyword">in</span> text <span class="keyword">if</span> x == <span class="string">'!'</span>])</span><br><span class="line">EC = tweet.apply(<span class="keyword">lambda</span> x:exclamationCount(x))</span><br><span class="line">EC = EC.tolist()</span><br><span class="line">questionMarkCount = <span class="keyword">lambda</span> text: sum([<span class="number">1</span> <span class="keyword">for</span> x <span class="keyword">in</span> text <span class="keyword">if</span> x == <span class="string">'?'</span>])</span><br><span class="line">QC = tweet.apply(<span class="keyword">lambda</span> x:questionMarkCount(x))</span><br><span class="line">QC = QC.tolist()</span><br><span class="line">dat = pd.DataFrame(&#123;<span class="string">'EC'</span>:EC,<span class="string">'QC'</span>:QC&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eachLetterCount = <span class="keyword">lambda</span> text,letter: sum([<span class="number">1</span> <span class="keyword">for</span> x <span class="keyword">in</span> text.lower() <span class="keyword">if</span> x == letter])</span><br><span class="line"></span><br><span class="line">FList = []</span><br><span class="line">pattern = <span class="string">'abcdefghijklmnopqrstuvwxyz'</span></span><br><span class="line">j=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pattern:</span><br><span class="line">  F = tweet.apply(<span class="keyword">lambda</span> x:eachLetterCount(x,i))</span><br><span class="line">  F = F.tolist()</span><br><span class="line">  FList.append(F)</span><br><span class="line"></span><br><span class="line">res = pd.DataFrame(FList)</span><br><span class="line">res = res.transpose()</span><br><span class="line"></span><br><span class="line">pattern = <span class="string">'abcdefghijklmnopqrstuvwxyz'</span></span><br><span class="line">name = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> pattern:</span><br><span class="line">  name.append(<span class="string">"freqOf "</span> + i)</span><br><span class="line">res.columns = name</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/02/dataframe-operation/outcome.JPG" alt="结果"></p>
<p>二、数据框拼接（ignore_index = True, 重新分配索引）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 两种方式，concat、 append都可以</span></span><br><span class="line">result = pd.concat([result1, result2], ignore_index = <span class="literal">True</span>) <span class="comment"># 默认axis = 0 -&gt; 粘贴行 </span></span><br><span class="line">result = result1.append(result2, ignore_index = <span class="literal">True</span>) <span class="comment"># 粘贴行</span></span><br><span class="line"></span><br><span class="line">RF_eval = pd.concat([RF_eval, eval_raw], axis = <span class="number">1</span>) <span class="comment"># 粘贴列</span></span><br></pre></td></tr></table></figure></p>
<p>三、删掉列<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RF_eval.drop([<span class="string">'raw'</span>], axis = <span class="number">1</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<p>四、删掉行<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dat = dat.drop(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>五、提取行索引<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">index0 = res.index[res[<span class="string">'label'</span>] == <span class="number">0</span>].tolist()</span><br><span class="line">X0 = X[index0] <span class="comment"># X为矩阵</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>读取与保存csv和txt文件</title>
    <url>/2019/09/02/%E8%AF%BB%E5%8F%96%E4%B8%8E%E4%BF%9D%E5%AD%98csv%E5%92%8Ctxt%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h4 id="一、csv文件"><a href="#一、csv文件" class="headerlink" title="一、csv文件"></a>一、csv文件</h4><ul>
<li>读取</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train = pd.read_csv(<span class="string">"Google_Stock_Price_Train.csv"</span>)</span><br><span class="line">train.head()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/02/读取与保存csv和txt文件/1594120531625.png" alt="1594120531625"></p>
<p>若文件中无列表头，需设定header = None，否则第一行会被识别为标题（如下图）</p>
<p><img src="/2019/09/02/读取与保存csv和txt文件/1594120744906.png" alt="1594120744906"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">"dataset.csv"</span>, header=<span class="literal">None</span>)</span><br><span class="line">data.head()</span><br><span class="line"><span class="comment">#data.columns = ['date','open','high','low','close','volume']</span></span><br></pre></td></tr></table></figure>
<p><img src="/2019/09/02/读取与保存csv和txt文件/1594120675413.png" alt="1594120675413"></p>
<p>或者用names指定需要的列表头</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_csv(<span class="string">'dataset.csv'</span>, names =  [<span class="string">'date'</span>,<span class="string">'open'</span>,<span class="string">'high'</span>,<span class="string">'low'</span>,<span class="string">'close'</span>,<span class="string">'volume'</span>])</span><br></pre></td></tr></table></figure>
<ul>
<li>保存</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">save = pd.DataFrame(np_data, columns = [<span class="string">'year'</span>, <span class="string">'month'</span>, <span class="string">'day'</span>])</span><br><span class="line">save.to_csv(<span class="string">'E:\test\modified.csv'</span>, index = <span class="literal">False</span>, header = <span class="literal">False</span>) <span class="comment"># index = False, header = False表示不保存行索引和列标题</span></span><br><span class="line"><span class="comment"># save.to_csv("RF_test.csv", index = False)</span></span><br></pre></td></tr></table></figure>
<h4 id="二、txt文件"><a href="#二、txt文件" class="headerlink" title="二、txt文件"></a>二、txt文件</h4><ul>
<li>读取(注：法一和法二都有可能会造成行数缺少或数据分割不正确的现象，建议采用法三)</li>
</ul>
<p>法一</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train = pd.read_table(<span class="string">'train_tweets.txt'</span>, sep = <span class="string">'\t'</span>, header = <span class="literal">None</span>, encoding = <span class="string">"UTF-8"</span>)</span><br></pre></td></tr></table></figure>
<p>法二</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">train = pd.read_fwf(<span class="string">'train_tweets.txt'</span>, sep = <span class="string">'\t'</span>, header = <span class="literal">None</span>, encoding = <span class="string">"UTF-8"</span>)</span><br></pre></td></tr></table></figure>
<p>法三</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">####### example 1 #########</span></span><br><span class="line">ids = []</span><br><span class="line">tweets = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'/content/Twitter-Authorship/train_tweets.txt'</span>, encoding=<span class="string">'utf-8'</span>):</span><br><span class="line">    (id,tweet) = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    ids.append(id)</span><br><span class="line">    tweets.append(tweet)</span><br><span class="line">train = pd.DataFrame(&#123;<span class="string">"ID"</span>: ids, <span class="string">"tweet"</span>: tweets&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">####### example 2 #########</span></span><br><span class="line">stream = []</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> open(<span class="string">'dataset.txt'</span>):</span><br><span class="line">    row = [eval(i) <span class="keyword">for</span> i <span class="keyword">in</span> line.strip().split(<span class="string">' '</span>)]</span><br><span class="line">    stream.append(row)</span><br><span class="line">    </span><br><span class="line">arms = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(stream)):</span><br><span class="line">    temp = stream[i][<span class="number">0</span>]</span><br><span class="line">    arms.append(temp)</span><br><span class="line">    </span><br><span class="line">rewards = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(stream)):</span><br><span class="line">    temp = stream[i][<span class="number">1</span>]</span><br><span class="line">    rewards.append(temp)</span><br><span class="line">    </span><br><span class="line">contexts = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(stream)):</span><br><span class="line">    contexts.append(stream[i][<span class="number">2</span>:])</span><br></pre></td></tr></table></figure>
<ul>
<li>保存(方法同csv)</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">RF_test.to_csv(<span class="string">"RF_test.txt"</span>, sep = <span class="string">'\t'</span>, index = <span class="literal">False</span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Markdown语法</title>
    <url>/2019/06/27/Markdown%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>(本文参考<a href="https://www.markdowntutorial.com/" target="_blank" rel="noopener">Markdown Tutorial</a>)</p>
<h4 id="1-加粗与斜体"><a href="#1-加粗与斜体" class="headerlink" title="1. 加粗与斜体"></a>1. 加粗与斜体</h4><ul>
<li>斜体：在文本两侧加上一个星号或一个下划线，例如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_unknown_或*unkown*</span><br></pre></td></tr></table></figure>
<p>效果如下：_unknown_</p>
<ul>
<li>加粗：在文本两侧加上两个星号或两个下划线, 例如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">__unknown__或**unknown**</span><br></pre></td></tr></table></figure>
<p>效果如下：<strong>unknown</strong></p>
<ul>
<li>注：斜体和加粗可以一起用，例如：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">**_of course_**</span><br></pre></td></tr></table></figure>
<p>效果如下：<strong>_of course_</strong></p>
<h4 id="2-标题-Headers"><a href="#2-标题-Headers" class="headerlink" title="2.标题(Headers)"></a>2.标题(Headers)</h4><p>在前面加#号, 一共有六级标题。一级标题为在前面加一个#号（# 一级标题），二级标题为在前面加两个#号（## 二级标题）。效果如下：</p>
<blockquote>
<h1 id="Header-one"><a href="#Header-one" class="headerlink" title="Header one"></a>Header one</h1><h2 id="Header-two"><a href="#Header-two" class="headerlink" title="Header two"></a>Header two</h2><h3 id="Header-three"><a href="#Header-three" class="headerlink" title="Header three"></a>Header three</h3><h4 id="Header-four"><a href="#Header-four" class="headerlink" title="Header four"></a>Header four</h4><h5 id="Header-five"><a href="#Header-five" class="headerlink" title="Header five"></a>Header five</h5><h6 id="Header-six"><a href="#Header-six" class="headerlink" title="Header six"></a>Header six</h6><p>plain text</p>
</blockquote>
<p>注：#号与文本之间有一个空格。</p>
<h4 id="3-链接"><a href="#3-链接" class="headerlink" title="3.链接"></a>3.链接</h4><ul>
<li><p>inline link</p>
<p>语法如下：</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[Visit GitHub!](www.github.com)</span><br></pre></td></tr></table></figure>
<p><a href="www.github.com">Visit GitHub!</a></p>
<p>再比如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[Yo<span class="string">u're **really, really** going to see this.](www.dailykitten.com)</span></span><br></pre></td></tr></table></figure>
<p><a href="www.dailykitten.com">You’re <strong>really, really</strong> going to see this.</a></p>
<ul>
<li>reference link</li>
</ul>
<p>语法如下：  </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Do you want to [see something fun][a fun place]?  </span><br><span class="line"></span><br><span class="line">Well, I have [a website <span class="keyword">for</span> you][another fun place]!</span><br><span class="line"></span><br><span class="line">[a fun place]: www.zombo.com</span><br><span class="line">    </span><br><span class="line">[another fun place]: www.stumbleupon.com</span><br></pre></td></tr></table></figure>
<p>效果如下：<br>Do you want to <a href="www.zombo.com">see something fun</a>?  </p>
<p>Well, I have <a href="www.stumbleupon.com">a website for you</a>!</p>
<p>一般可将链接地址写在Markdown文件的最后。使用refrence的好处是如果有许多链接都是指向一个地方，那么需要更改的时候只需要修改一次就行了。</p>
<h4 id="4-图片"><a href="#4-图片" class="headerlink" title="4.图片"></a>4.图片</h4><ul>
<li>inline link</li>
</ul>
<p>插入图片和插入链接类似，语法如下： </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">![A pretty tiger](https://upload.wikimedia.org/wikipedia/commons/<span class="number">5</span>/<span class="number">56</span>/Tiger<span class="number">.50</span>.jpg)</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/5/56/Tiger.50.jpg" alt="A pretty tiger"></p>
<p>注：</p>
<ol>
<li>[ ]中的内容可以空着，当网络不好，图片无法显示时（或某些其它原因）会显示[ ]中的文字</li>
<li>!和[ ]之间不要加空格</li>
</ol>
<ul>
<li>reference link</li>
</ul>
<p>语法如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">![Black cat][Black]</span><br><span class="line"></span><br><span class="line">![Orange cat][Orange]</span><br><span class="line"></span><br><span class="line">[Black]: https://upload.wikimedia.org/wikipedia/commons/a/a3/<span class="number">81</span>_INF_DIV_SSI.jpg  </span><br><span class="line">        </span><br><span class="line">[Orange]:http://icons.iconarchive.com/icons/google/noto-emoji-animals-nature/<span class="number">256</span>/<span class="number">22221</span>-cat-icon.png</span><br></pre></td></tr></table></figure>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/a/a3/81_INF_DIV_SSI.jpg" alt="Black cat"></p>
<p><img src="http://icons.iconarchive.com/icons/google/noto-emoji-animals-nature/256/22221-cat-icon.png" alt="Orange cat"></p>
<h4 id="5-Blockquotes"><a href="#5-Blockquotes" class="headerlink" title="5.Blockquotes"></a>5.Blockquotes</h4><p>当想引用一段话并让读者注意到时，可以采用如下方法：在文本前加上”&gt;”</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt; <span class="string">"In a few moments he was barefoot, his stockings folded in his pockets and his</span></span><br><span class="line"><span class="string">  canvas shoes dangling by their knotted laces over his shoulders and, picking a</span></span><br><span class="line"><span class="string">  pointed salt-eaten stick out of the jetsam among the rocks, he clambered down</span></span><br><span class="line"><span class="string">  the slope of the breakwater."</span></span><br></pre></td></tr></table></figure>
<p> 效果如下：</p>
<blockquote>
<p>“In a few moments he was barefoot, his stockings folded in his pockets and his<br>  canvas shoes dangling by their knotted laces over his shoulders and, picking a<br>  pointed salt-eaten stick out of the jetsam among the rocks, he clambered down<br>  the slope of the breakwater.”</p>
</blockquote>
<p>当引用多段话时，可以在每一部分前加上”&gt;”，例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&gt; His words seemed to have struck some deep chord <span class="keyword">in</span> his own nature. Had he spoken</span><br><span class="line">of himself, of himself as he was or wished to be? Stephen watched his face for some</span><br><span class="line">moments <span class="keyword">in</span> silence. A cold sadness was there. He had spoken of himself, of his own</span><br><span class="line">loneliness which he feared.  </span><br><span class="line">&gt;  </span><br><span class="line">&gt; —Of whom are you speaking? Stephen asked at length.  </span><br><span class="line">&gt;  </span><br><span class="line">&gt; Cranly did <span class="keyword">not</span> answer.</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<blockquote>
<p>His words seemed to have struck some deep chord in his own nature. Had he spoken<br>of himself, of himself as he was or wished to be? Stephen watched his face for some<br>moments in silence. A cold sadness was there. He had spoken of himself, of his own<br>loneliness which he feared.</p>
<p>—Of whom are you speaking? Stephen asked at length.</p>
<p>Cranly did not answer.</p>
</blockquote>
<p>Note: even blank lines must contain the caret character. This ensures that the entire blockquote is grouped together.</p>
<h4 id="6-列表-Lists"><a href="#6-列表-Lists" class="headerlink" title="6.列表(Lists)"></a>6.列表(Lists)</h4><h5 id="unordered-list"><a href="#unordered-list" class="headerlink" title="* unordered list"></a>* unordered list</h5><p>在前面加星号：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* Milk  </span><br><span class="line">* Eggs  </span><br><span class="line">* Salmon  </span><br><span class="line">* Butter</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<ul>
<li>Milk</li>
<li>Eggs</li>
<li>Salmon</li>
<li>Butter</li>
</ul>
<h5 id="odered-list"><a href="#odered-list" class="headerlink" title="* odered list"></a>* odered list</h5><p>在前面加数字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="number">1.</span> Crack three eggs over a bowl</span><br><span class="line"><span class="number">2.</span> Pour a gallon of milk into the bowl</span><br><span class="line"><span class="number">3.</span> Rub the salmon vigorously <span class="keyword">with</span> butter</span><br><span class="line"><span class="number">4.</span> Drop the salmon into the egg-milk bowl</span><br></pre></td></tr></table></figure>
<p>效果如下：</p>
<ol>
<li>Crack three eggs over a bowl</li>
<li>Pour a gallon of milk into the bowl</li>
<li>Rub the salmon vigorously with butter</li>
<li>Drop the salmon into the egg-milk bowl</li>
</ol>
<h5 id="nest-one-list-within-another"><a href="#nest-one-list-within-another" class="headerlink" title="* nest one list within another"></a>* nest one list within another</h5><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">* Tintin</span><br><span class="line"> * A reporter</span><br><span class="line"> * Has poofy orange hair</span><br><span class="line"> * Friends <span class="keyword">with</span> the world<span class="string">'s most awesome dog</span></span><br><span class="line"><span class="string">* Haddock</span></span><br><span class="line"><span class="string"> * A sea captain</span></span><br><span class="line"><span class="string"> * Has a fantastic beard</span></span><br><span class="line"><span class="string"> * Loves whiskey</span></span><br><span class="line"><span class="string">   * Possibly also scotch?</span></span><br></pre></td></tr></table></figure>
<ul>
<li>Tintin<ul>
<li>A reporter</li>
<li>Has poofy orange hair</li>
<li>Friends with the world’s most awesome dog</li>
</ul>
</li>
<li>Haddock<ul>
<li>A sea captain</li>
<li>Has a fantastic beard</li>
<li>Loves whiskey<ul>
<li>Possibly also scotch?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>建议最多建三层，否则文章结构会变得太混乱</p>
<h4 id="7-段落"><a href="#7-段落" class="headerlink" title="7.段落"></a>7.段落</h4><ul>
<li>hard break</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Do I contradict myself?</span><br><span class="line"></span><br><span class="line">Very well then I contradict myself,</span><br><span class="line"></span><br><span class="line">(I am large, I contain multitudes.)</span><br></pre></td></tr></table></figure>
<p>想换行时，空一行。效果如下：</p>
<p>Do I contradict myself?</p>
<p>Very well then I contradict myself,</p>
<p>(I am large, I contain multitudes.)</p>
<ul>
<li>soft break</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Do I contradict myself?··</span><br><span class="line">Very well then I contradict myself,··</span><br><span class="line">(I am large, I contain multitudes.)</span><br></pre></td></tr></table></figure>
<p>想换行时，打两个空格。上面每个点 ( · ) 代表一个空格。效果如下：</p>
<p>Do I contradict myself?<br>Very well then I contradict myself,<br>(I am large, I contain multitudes.)</p>
<h4 id="8-LaTex数学表达式"><a href="#8-LaTex数学表达式" class="headerlink" title="8. LaTex数学表达式"></a>8. LaTex数学表达式</h4><p>在Markdown文档中，可以使用<a href="https://www.latex-project.org/" target="_blank" rel="noopener">LaTex</a>符号创建数学表达式。例如：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">$$</span><br><span class="line">y = \frac&#123;a&#125;&#123;b+c&#125;</span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<script type="math/tex; mode=display">
y = \frac{a}{b+c}</script><p>(hexo中公式显示问题：在文章的Front-matter中加上：mathjax: true)</p>
<h4 id="9-Typora中，字体颜色"><a href="#9-Typora中，字体颜色" class="headerlink" title="9. Typora中，字体颜色"></a>9. Typora中，字体颜色</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;span style=&apos;color:red&apos;&gt;This is red&lt;/span&gt;</span><br><span class="line">&lt;span style=&quot;background:yellow&quot;&gt;高亮黄色&lt;/span&gt;</span><br></pre></td></tr></table></figure>
<p><span style="color:red">This is red</span></p>
<p><span style="background:yellow">高亮黄色</span></p>
<p>以上，本文介绍了一些基础的Markdown语法，想了解更多的Markdown知识可查询相关资料。</p>
]]></content>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>Jupyter Notebook中的快捷键</title>
    <url>/2019/06/27/Jupyter-Notebook%E4%B8%AD%E7%9A%84%E5%BF%AB%E6%8D%B7%E9%94%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul>
<li>shift+enter: 运行代码块</li>
<li>shift+tab: show the documentation pop up for the method</li>
<li>Esc+m: markdown语句</li>
</ul>
]]></content>
      <categories>
        <category>Jupyter Notebook</category>
      </categories>
      <tags>
        <tag>Jupyter Notebook</tag>
      </tags>
  </entry>
  <entry>
    <title>Advanced Python Types</title>
    <url>/2019/06/27/Advanced-Python-Types/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><ul>
<li>List</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">l = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]</span><br><span class="line">print(l)</span><br></pre></td></tr></table></figure>
<pre><code>[1, 2, 3]
</code></pre><p><img src="/2019/06/27/Advanced-Python-Types/1578053721585.jpg" alt="1578053721585"></p>
<p>List的拼接</p>
<p>注意：[1,2]是List不是Array（Array要用np.array()）<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> chain</span><br><span class="line">features = []</span><br><span class="line"><span class="keyword">for</span> (vec, wt) <span class="keyword">in</span> vecs_wt[<span class="number">0</span>:<span class="number">2</span>]:</span><br><span class="line">	features.append(vec)</span><br><span class="line">	newfeatures = list(chain(*features))</span><br></pre></td></tr></table></figure></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">[<span class="number">1</span>,<span class="number">2</span>] + [<span class="number">3</span>] + [<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<pre><code>[1, 2, 3, 4]
</code></pre><p>排序：</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1578053775703.jpg" alt="1578053775703"></p>
<ul>
<li><p>Tuple</p>
<p>Tuples are a lot like lists, but the main difference is that they are <strong>immutable</strong>. Once you create a tuple, you can’t change them.</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1578054069373.jpg" alt="1578054069373"></p>
</li>
</ul>
<ul>
<li><p>Dictionary</p>
<p>In other languages, you might know this as a map, or a hash table. It’s basically a lookup table, where you store values associated with some unique set of key values.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">d = &#123;<span class="string">'foo'</span>:<span class="number">1</span>, <span class="string">'bar'</span>:<span class="number">2.3</span>, <span class="string">'s'</span>:<span class="string">'my first dictionary'</span>&#125;</span><br><span class="line">print(d)</span><br></pre></td></tr></table></figure>
<pre><code>{&#39;s&#39;: &#39;my first dictionary&#39;, &#39;bar&#39;: 2.3, &#39;foo&#39;: 1}
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(d[<span class="string">'foo'</span>])</span><br></pre></td></tr></table></figure>
<pre><code>1
</code></pre><p><img src="/2019/06/27/Advanced-Python-Types/1578054637299.jpg" alt="1578054637299"></p>
<p>If you try to retrieve a value for a key that doesn’t exist, you will get an exception. </p>
<p>One way to avoid that is to use the _get_ function on the dictionary:</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1578054512678.jpg" alt="1578054512678"></p>
<p>Iterate:</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1578054588653.jpg" alt="1578054588653"></p>
<p><strong>遍历字典： keys()  、values() 、items()</strong>　　</p>
<p><a href="https://www.cnblogs.com/FlyingLiao/p/11192330.html" target="_blank" rel="noopener">https://www.cnblogs.com/FlyingLiao/p/11192330.html</a></p>
<ol>
<li>xxx.keys()    :    返回字典的所有的key     返回一个序列，序列中保存有字典的所有的键</li>
</ol>
<p>例：</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1584001011558.png" alt="1584001011558"></p>
<ol>
<li>xxx.values()     :   返回字典所有的值</li>
</ol>
<p>例：</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1584001175719.png" alt="1584001175719"></p>
<ol>
<li>xxx.items()    :  返回字典中所有的key和values   返回一个序列，序列中包含有双值子序列</li>
</ol>
<p>例：</p>
<p><img src="/2019/06/27/Advanced-Python-Types/1584001276582.png" alt="1584001276582"></p>
<p>Python中的defaultdict:</p>
<p><a href="mk:@MSITStore:C:\Python32\Doc\Python323.chm::/library/#collections.defaultdict" target="_blank" rel="noopener"><code>defaultdict</code></a><br>dict subclass that calls a factory function to supply missing values。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> collections</span><br><span class="line">dict = collections.defaultdict(int)</span><br></pre></td></tr></table></figure>
<p><em>defaultdict(int)</em>创建一个类似<em>dictionary</em>对象，里面任何的<em>values</em>都是<em>int</em>的实例，而且就算是一个不存在的<em>key</em>, <em>d[key]</em> 也有一个默认值，这个默认值是<em>int()</em>的默认值0.</p>
<p>按照字典的键或者值排序：</p>
<p><a href="https://blog.csdn.net/leokingszx/article/details/81154681" target="_blank" rel="noopener">https://blog.csdn.net/leokingszx/article/details/81154681</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">y = &#123;<span class="number">1</span>:<span class="number">3</span>, <span class="number">2</span>:<span class="number">2</span>, <span class="number">3</span>:<span class="number">1</span>&#125;</span><br><span class="line">by_key =  sorted(y.items(),key = <span class="keyword">lambda</span> item:item[<span class="number">0</span>])</span><br><span class="line">by_value = sorted(y.items(),key = <span class="keyword">lambda</span> item:item[<span class="number">1</span>])</span><br><span class="line">print(by_key)   <span class="comment">#结果为[(1, 3), (2, 2), (3, 1)]，即按照键名排列</span></span><br><span class="line">print(by_value) <span class="comment">#结果为[(3, 1), (2, 2), (1, 3)]，即按照键值排列</span></span><br></pre></td></tr></table></figure>
<p>当然，在这样处理后，得到的结果将变成元组。这样也可以理解，毕竟对于字典而言，本身是不提供排序的需求的。如果想按照里面的元素进行排列，那么将不得不对其类型进行转化。</p>
<p>另：Python中多条件排序：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line">y = &#123;<span class="string">"ab"</span>:<span class="number">1</span>, <span class="string">"b"</span>:<span class="number">2</span>, <span class="string">"a"</span>:<span class="number">1</span>&#125;</span><br><span class="line">by_key =  sorted(y.items(),key = <span class="keyword">lambda</span> item:(len(item[<span class="number">0</span>]),item[<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">print(by_key)  </span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> by_key:</span><br><span class="line">	print(value[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>[(‘a’, 1), (‘b’, 2), (‘ab’, 1)]</p>
<p>a<br>b<br>ab</p>
<ul>
<li>Array</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">print(np.array([<span class="number">1</span>,<span class="number">2</span>]))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[1 2]</span><br></pre></td></tr></table></figure>
<p>Array的合并</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">np.concatenate(要拼接的多个数组, axis = <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中的简单语法</title>
    <url>/2019/06/27/basic-python-type/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><strong>_缩进是python的灵魂_</strong></p>
<ul>
<li>查看内置函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dir(__builtins)</span><br></pre></td></tr></table></figure>
<ul>
<li>逻辑运算符</li>
</ul>
<p><img src="/2019/06/27/basic-python-type/logic-operator.jpg" alt="逻辑运算符"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df[(df[<span class="string">'id'</span>]&gt;=<span class="number">1</span>) &amp;&amp; (df[<span class="string">'id'</span>]&lt;=<span class="number">2</span>)]</span><br></pre></td></tr></table></figure>
<ul>
<li>比较操作符</li>
</ul>
<blockquote>
<p>>, &lt;, &gt;=, &lt;=, ==, != </p>
</blockquote>
<ul>
<li>Python中的双引号</li>
</ul>
<p>Python中双引号和单引号作用一样，即字符串可以用单引号也可以用双引号</p>
<ul>
<li>type()函数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">i = <span class="number">4</span></span><br><span class="line">type(i)</span><br></pre></td></tr></table></figure>
<pre><code>int
</code></pre><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">n = <span class="literal">None</span></span><br><span class="line">type(n)</span><br></pre></td></tr></table></figure>
<pre><code>NoneType
</code></pre><ul>
<li>dtype</li>
</ul>
<p>查看type<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train[<span class="string">"ID"</span>].dtype</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>dtype(‘O’)</p>
</blockquote>
<p>转换type<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train[<span class="string">"ID"</span>] = train[<span class="string">"ID"</span>].astype(np.int32)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>test blog</title>
    <url>/2019/06/26/test-blog/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>一篇测试文章.</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2019/06/26/hello-world/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><a id="more"></a>
<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
</search>
