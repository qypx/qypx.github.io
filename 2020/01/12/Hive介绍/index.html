<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hadoop,Hive,">










<meta name="keywords" content="Hadoop,Hive">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive介绍">
<meta property="og:url" content="http://qypx.github.io/2020/01/12/Hive介绍/index.html">
<meta property="og:site_name" content="qypx の blog">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603599880662.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603599824805.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603600131112.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603600188322.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603609902727.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610044780.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610161316.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610193337.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610402205.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603600496450.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603600549196.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603609992170.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610068333.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610449476.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610471246.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610518016.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610616445.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603610644871.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603613699566.png">
<meta property="og:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603614353762.png">
<meta property="og:updated_time" content="2020-10-26T11:11:54.364Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive介绍">
<meta name="twitter:image" content="http://qypx.github.io/2020/01/12/Hive介绍/1603599880662.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://qypx.github.io/2020/01/12/Hive介绍/">





<!-- 网页加载条 -->
<script src="https://neveryu.github.io/js/src/pace.min.js"></script>

  <title>Hive介绍 | qypx の blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">qypx の blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">机会是留给有准备的人的.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://qypx.github.io/2020/01/12/Hive介绍/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="qypx">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="qypx の blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hive介绍</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-01-12T20:26:40+08:00">
                2020-01-12
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2020-10-26T19:11:54+08:00">
                2020-10-26
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读量
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p> 参考：<br><a href="https://blog.csdn.net/PowerBlogger/article/details/83626449" target="_blank" rel="noopener">https://blog.csdn.net/PowerBlogger/article/details/83626449</a><br><a href="https://blog.csdn.net/u010886217/article/details/83796151" target="_blank" rel="noopener">https://blog.csdn.net/u010886217/article/details/83796151</a></p>
<p>更多内容见Hive官方文档<br><a href="https://cwiki.apache.org/confluence/display/Hive/Home#Home-UserDocumentation" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/Home#Home-UserDocumentation</a></p>
</blockquote>
<h3 id="1-什么是Hive？"><a href="#1-什么是Hive？" class="headerlink" title="1.什么是Hive？"></a>1.什么是Hive？</h3><p>Hive是建立在Hadoop上的，用来构建数据仓库的工具，里面有表的概念，可以使用SQL语句实现存储、查询和分析存储在 HDFS上的数据，这些SQL语句在Hive中称为HQL (HiveQL)，语法和SQL语句基本一样。<br>由于数据是杂乱无章的，所以Hive需要一份关于这些数据的元数据来管理和操作这些数据。这份元数据包括：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">元数据（</span><br><span class="line">行的分隔符（在映射成表的时候知道在哪里分行显示）</span><br><span class="line">字段分隔符（在映射成表的时候知道在哪里分列显示）</span><br><span class="line">字段的类型</span><br><span class="line">字段的名称</span><br><span class="line">）</span><br></pre></td></tr></table></figure>
<p>在Hive中，我们把数据存储在HDFS中，元数据默认存储在Hive自带的Derby数据库中，由于Derby不能实现并发访问，所以我们一般使用mysql进行替换。</p>
<h3 id="2-Hive的原理"><a href="#2-Hive的原理" class="headerlink" title="2.Hive的原理"></a>2.Hive的原理</h3><p><strong>Hive 将用户的 HQL 语句进行解析，优化，最终把一个个的HQL语句转换为 MapReduce 作业提交到 Hadoop 集群上，Hadoop进行作业的调度及监控，作业完成后将执行结果返回给用户。</strong>所以，<strong>Hive并不进行计算，只是把HQL解析为MapperReduce在HDFS集群中运行而已</strong>，所以Hive的效率并不高。</p>
<h3 id="3-Hive建表语句"><a href="#3-Hive建表语句" class="headerlink" title="3.Hive建表语句"></a><span id="jump3">3.Hive建表语句</span></h3><blockquote>
<p>参考<br><a href="https://blog.csdn.net/qq_36743482/article/details/78383964" target="_blank" rel="noopener">https://blog.csdn.net/qq_36743482/article/details/78383964</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML</a></p>
</blockquote>
<p>Hive建表方式共有三种：</p>
<ul>
<li>直接建表法</li>
<li>查询建表法</li>
<li>like建表法</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name    -- (Note: TEMPORARY available in Hive 0.14.0 and later)</span><br><span class="line">  [(col_name data_type [column_constraint_specification] [COMMENT col_comment], ... [constraint_specification])]</span><br><span class="line">  [COMMENT table_comment]</span><br><span class="line">  [PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)]</span><br><span class="line">  [CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS]</span><br><span class="line">  [SKEWED BY (col_name, col_name, ...)                  -- (Note: Available in Hive 0.10.0 and later)]</span><br><span class="line">     ON ((col_value, col_value, ...), (col_value, col_value, ...), ...)</span><br><span class="line">     [STORED AS DIRECTORIES]</span><br><span class="line">  [</span><br><span class="line">   [ROW FORMAT row_format] </span><br><span class="line">   [STORED AS file_format]</span><br><span class="line">     | STORED BY &apos;storage.handler.class.name&apos; [WITH SERDEPROPERTIES (...)]  -- (Note: Available in Hive 0.6.0 and later)</span><br><span class="line">  ]</span><br><span class="line">  [LOCATION hdfs_path]</span><br><span class="line">  [TBLPROPERTIES (property_name=property_value, ...)]   -- (Note: Available in Hive 0.6.0 and later)</span><br><span class="line">  [AS select_statement];   -- (Note: Available in Hive 0.5.0 and later; not supported for external tables)</span><br><span class="line"> </span><br><span class="line">CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.]table_name</span><br><span class="line">  LIKE existing_table_or_view_name</span><br><span class="line">  [LOCATION hdfs_path];</span><br><span class="line"> </span><br><span class="line">data_type</span><br><span class="line">  : primitive_type</span><br><span class="line">  | array_type</span><br><span class="line">  | map_type</span><br><span class="line">  | struct_type</span><br><span class="line">  | union_type  -- (Note: Available in Hive 0.7.0 and later)</span><br><span class="line"> </span><br><span class="line">primitive_type</span><br><span class="line">  : TINYINT</span><br><span class="line">  | SMALLINT</span><br><span class="line">  | INT</span><br><span class="line">  | BIGINT</span><br><span class="line">  | BOOLEAN</span><br><span class="line">  | FLOAT</span><br><span class="line">  | DOUBLE</span><br><span class="line">  | DOUBLE PRECISION -- (Note: Available in Hive 2.2.0 and later)</span><br><span class="line">  | STRING</span><br><span class="line">  | BINARY      -- (Note: Available in Hive 0.8.0 and later)</span><br><span class="line">  | TIMESTAMP   -- (Note: Available in Hive 0.8.0 and later)</span><br><span class="line">  | DECIMAL     -- (Note: Available in Hive 0.11.0 and later)</span><br><span class="line">  | DECIMAL(precision, scale)  -- (Note: Available in Hive 0.13.0 and later)</span><br><span class="line">  | DATE        -- (Note: Available in Hive 0.12.0 and later)</span><br><span class="line">  | VARCHAR     -- (Note: Available in Hive 0.12.0 and later)</span><br><span class="line">  | CHAR        -- (Note: Available in Hive 0.13.0 and later)</span><br><span class="line"> </span><br><span class="line">array_type</span><br><span class="line">  : ARRAY &lt; data_type &gt;</span><br><span class="line"> </span><br><span class="line">map_type</span><br><span class="line">  : MAP &lt; primitive_type, data_type &gt;</span><br><span class="line"> </span><br><span class="line">struct_type</span><br><span class="line">  : STRUCT &lt; col_name : data_type [COMMENT col_comment], ...&gt;</span><br><span class="line"> </span><br><span class="line">union_type</span><br><span class="line">   : UNIONTYPE &lt; data_type, data_type, ... &gt;  -- (Note: Available in Hive 0.7.0 and later)</span><br><span class="line"> </span><br><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]</span><br><span class="line">        [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)</span><br><span class="line">  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</span><br><span class="line"> </span><br><span class="line">file_format:</span><br><span class="line">  : SEQUENCEFILE</span><br><span class="line">  | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)</span><br><span class="line">  | RCFILE      -- (Note: Available in Hive 0.6.0 and later)</span><br><span class="line">  | ORC         -- (Note: Available in Hive 0.11.0 and later)</span><br><span class="line">  | PARQUET     -- (Note: Available in Hive 0.13.0 and later)</span><br><span class="line">  | AVRO        -- (Note: Available in Hive 0.14.0 and later)</span><br><span class="line">  | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)</span><br><span class="line">  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname</span><br><span class="line"> </span><br><span class="line">column_constraint_specification:</span><br><span class="line">  : [ PRIMARY KEY|UNIQUE|NOT NULL|DEFAULT [default_value]|CHECK  [check_expression] ENABLE|DISABLE NOVALIDATE RELY/NORELY ]</span><br><span class="line"> </span><br><span class="line">default_value:</span><br><span class="line">  : [ LITERAL|CURRENT_USER()|CURRENT_DATE()|CURRENT_TIMESTAMP()|NULL ] </span><br><span class="line"> </span><br><span class="line">constraint_specification:</span><br><span class="line">  : [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]</span><br><span class="line">    [, PRIMARY KEY (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]</span><br><span class="line">    [, CONSTRAINT constraint_name FOREIGN KEY (col_name, ...) REFERENCES table_name(col_name, ...) DISABLE NOVALIDATE </span><br><span class="line">    [, CONSTRAINT constraint_name UNIQUE (col_name, ...) DISABLE NOVALIDATE RELY/NORELY ]</span><br><span class="line">    [, CONSTRAINT constraint_name CHECK [check_expression] ENABLE|DISABLE NOVALIDATE RELY/NORELY ]</span><br></pre></td></tr></table></figure>
<p>(👆来自官网 <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL</a><br>[] 表示可选，| 表示选其一)</p>
<p>注：</p>
<ul>
<li>不使用 EXTERNAL 时，创建的是内部表。</li>
<li>表和列的注释（COMMENT）是字符串文字(单引号)。</li>
<li>要为表指定一个数据库，要么在<code>CREATE TABLE</code>语句之前使用<code>USE database_name</code>语句(在Hive 0.6和更高版本中)，要么用一个数据库名称限定表名(在Hive 0.7和更高版本中是“database _name.table.name”)。</li>
<li>See <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-AlterTable" target="_blank" rel="noopener">Alter Table</a> for more information about table comments, table properties, and SerDe properties.</li>
<li>See <a href="https://cwiki.apache.org/confluence/display/Hive/Tutorial#Tutorial-TypeSystem" target="_blank" rel="noopener">Type System</a> and <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types" target="_blank" rel="noopener">Hive Data Types</a> for details about the primitive and complex data types.</li>
</ul>
<p>这里我们针对里面的一些不同于关系型数据库的地方进行说明。</p>
<h4 id="3-1-row-format"><a href="#3-1-row-format" class="headerlink" title="3.1 row format"></a><span id="jump3.1">3.1 row format</span></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">row_format</span><br><span class="line">  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]</span><br><span class="line">        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]</span><br><span class="line">        [NULL DEFINED AS char]   -- (Note: Available in Hive 0.13 and later)</span><br><span class="line">  | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)]</span><br></pre></td></tr></table></figure>
<p>Hive将HDFS上的文件映射成表结构，通过分隔符来区分列（比如’,’ ‘;’ or ‘^’ 等），row format就是用于指定序列化和反序列化的规则。<br>比如对于以下记录：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1,xiaoming,book-TV-code,beijing:chaoyang-shagnhai:pudong</span><br><span class="line">2,lilei,book-code,nanjing:jiangning-taiwan:taibei</span><br><span class="line">3,lihua,music-book,heilongjiang:haerbin</span><br></pre></td></tr></table></figure>
<p><strong>逗号</strong>用于分割列，即FIELDS TERMINATED BY char，分割为如下列 <strong>ID</strong>、<strong>name</strong>、<strong>hobby</strong>（该字段是数组形式，通过 ‘-’ 进行分割，即COLLECTION ITEMS TERMINATED BY ‘-’）、<strong>address</strong>（该字段是键值对形式map，通过 ‘:’ 分割键值，即 MAP KEYS TERMINATED BY ‘:’）；<br>而FIELDS TERMINATED BY char用于区分不同条的数据，默认是换行符；</p>
<h4 id="3-2-file-format（HDFS文件存放的格式）"><a href="#3-2-file-format（HDFS文件存放的格式）" class="headerlink" title="3.2 file format（HDFS文件存放的格式）"></a>3.2 file format（HDFS文件存放的格式）</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">file_format:</span><br><span class="line">  : SEQUENCEFILE</span><br><span class="line">  | TEXTFILE    -- (Default, depending on hive.default.fileformat configuration)</span><br><span class="line">  | RCFILE      -- (Note: Available in Hive 0.6.0 and later)</span><br><span class="line">  | ORC         -- (Note: Available in Hive 0.11.0 and later)</span><br><span class="line">  | PARQUET     -- (Note: Available in Hive 0.13.0 and later)</span><br><span class="line">  | AVRO        -- (Note: Available in Hive 0.14.0 and later)</span><br><span class="line">  | JSONFILE    -- (Note: Available in Hive 4.0.0 and later)</span><br><span class="line">  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname</span><br></pre></td></tr></table></figure>
<p>默认TEXTFILE，即文本格式，可以直接打开。</p>
<h4 id="3-3-内部表与外部表"><a href="#3-3-内部表与外部表" class="headerlink" title="3.3 内部表与外部表"></a><span id="jump3.3">3.3 内部表与外部表</span></h4><p>关于内部表与外部表的更多内容见 <a href="#jump4.1">4.1 内部表</a>与 <a href="#jump4.2">4.2 外部表</a></p>
<p>不使用EXTERNAL子句创建的表称为管理表 (也叫做内部表) (managed table)，因为Hive管理它的数据。若要确定一个表是管理表还是外部表，使用 <a href="https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables#Managedvs.ExternalTables-DescribeTable/View/Column" target="_blank" rel="noopener">DESCRIBE FORMATTED table_name</a> command, which will display either MANAGED_TABLE or EXTERNAL_TABLE depending on table type.</p>
<p>默认情况下，Hive创建管理表，其中文件、元数据和统计信息由内部Hive进程管理 (By default Hive creates managed tables, where files, metadata and statistics are managed by internal Hive processes)。 有关管理表与外部表之间差异的详细信息，请参阅 <a href="https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables" target="_blank" rel="noopener">Managed vs. External Tables</a>。</p>
<h5 id="Feature-comparison"><a href="#Feature-comparison" class="headerlink" title="Feature comparison"></a>Feature comparison</h5><ul>
<li>ARCHIVE/UNARCHIVE/TRUNCATE/MERGE/CONCATENATE only work for managed tables</li>
<li>DROP deletes data for managed tables while it only deletes metadata for external ones</li>
<li>ACID/Transactional only works for managed tables</li>
<li><a href="https://issues.apache.org/jira/browse/HIVE-18513" target="_blank" rel="noopener">Query Results Caching</a> only works for managed tables</li>
<li>Only the RELY constraint is allowed on external tables</li>
<li>Some Materialized View features only work on managed tables</li>
</ul>
<h5 id="Managed-tables-内部表"><a href="#Managed-tables-内部表" class="headerlink" title="Managed tables 内部表"></a>Managed tables 内部表</h5><p>A managed table is stored under the <a href="https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.metastore.warehouse.dir" target="_blank" rel="noopener">hive.metastore.warehouse.dir</a> path property, by default in a folder path similar to <code>/user/hive/warehouse/databasename.db/tablename/</code>. The default location can be overridden by the <code>location</code> property during table creation. If a managed table or partition is dropped, the data and metadata associated with that table or partition are deleted. If the PURGE option is not specified, the data is moved to a trash folder for a defined duration.</p>
<p><span style="color:red">Use managed tables when Hive should manage the lifecycle of the table, or when generating temporary tables.</span></p>
<p>管理表的主要问题是只能用 Hive 访问，不方便和其他系统共享数据。例如，有一份由 Pig 或其他工具创建并且主要由这一工具使用的数据，同时希望使用 Hive 在这份数据上执行一些查询，可是并没有给予 Hive 对数据的所有权，这时就不能使用管理表了。我们可以创建一个外部表指向这份数据，而并不需要对其具有所有权。</p>
<h5 id="External-tables-外部表"><a href="#External-tables-外部表" class="headerlink" title="External tables 外部表"></a>External tables 外部表</h5><p>An external table describes the metadata / schema on external files. External table files can be accessed and managed by processes outside of Hive. External tables can access data stored in sources such as Azure Storage Volumes (ASV) or remote HDFS locations. If the structure or partitioning of an external table is changed, an <a href="https://cwiki.apache.org/confluence/display/Hive/Managed+vs.+External+Tables#Managedvs.ExternalTables-RecoverPartitions(MSCKREPAIRTABLE" target="_blank" rel="noopener">MSCK REPAIR TABLE table_name</a>) statement can be used to refresh metadata information.</p>
<p><span style="color:red">Use external tables when files are already present or in remote locations, and the files should remain even if the table is dropped.</span></p>
<p>外部表方便对已有数据的集成。因为表是外部的，所以 Hive 并不认为其完全拥有这个表的数据。在对外部表执行删除操作时，只是删除掉描述表的元数据信息，并不会删除表数据。</p>
<h5 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h5><ul>
<li>内部表数据由Hive自身管理，外部表数据由HDFS管理；</li>
<li>内部表数据存储的位置是hive.metastore.warehouse.dir（默认：/user/hive/warehouse），外部表数据的存储位置由自己制定；</li>
<li>删除内部表会直接删除元数据（metadata）及存储数据；删除外部表仅仅会删除元数据，HDFS上的文件并不会被删除；</li>
<li>对内部表的修改会将修改直接同步给元数据，而对外部表的表结构和分区进行修改，则需要修复（MSCK REPAIR TABLE table_name;）</li>
</ul>
<h4 id="3-4-Partitioned-Tables"><a href="#3-4-Partitioned-Tables" class="headerlink" title="3.4 Partitioned Tables"></a><span id="jump3.4">3.4 Partitioned Tables</span></h4><p>另外关于分区表的内容见 <a href="#jump4.4">4.4 分区表（Partitioned Tables）</a></p>
<p>可以使用 PARTITIONED BY 子句创建分区表。 一个表可以具有一个或多个分区列，并为分区列中的每个不同值组合创建一个单独的数据目录。 此外，可以使用CLUSTERED BY列对表或分区进行存储，并且可以通过SORT BY列在该存储区中对数据进行排序（tables or partitions can be bucketed using CLUSTERED BY columns, and data can be sorted within that bucket via SORT BY columns. ）。 这样可以提高某些查询的性能。</p>
<blockquote>
<p>更多关于bucket 的内容见 <a href="#jump4.5">4.5 分桶表（Bucket Tables） </a></p>
</blockquote>
<p>如果在创建分区表时收到以下错误消息：“ FAILED: Error in semantic analysis: Column repeated in partitioning columns”，则表示您试图将分区列包含在表本身的数据中。 您可能确实定义了该列。 但是，您创建的分区将创建一个可查询的伪列，因此您必须将表列重命名为其他名称（用户不应在其上查询！）。</p>
<p>(You probably really do have the column defined. However, the partition you create makes a pseudocolumn on which you can query, so you must rename your table column to something else (that users should not query on!).)</p>
<p>例如，假设原始未分区表具有三列：id，date和name。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">id int,</span><br><span class="line">date date,</span><br><span class="line">name varchar</span><br></pre></td></tr></table></figure>
<p>现在您要按日期分区。 您的Hive定义可以使用“ dtDontQuery”作为列名，以便可以将“ date”用于分区（和查询）。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table table_name ( </span><br><span class="line">	id int,</span><br><span class="line">	dtDontQuery string,</span><br><span class="line">	name string</span><br><span class="line">)</span><br><span class="line">partitioned by (date string)</span><br></pre></td></tr></table></figure>
<p>现在，您的用户仍将查询<code>where date =&#39;...&#39;</code>，但第二列dtDontQuery将保留原始值。</p>
<h4 id="3-5-法一：直接建表法"><a href="#3-5-法一：直接建表法" class="headerlink" title="3.5 法一：直接建表法"></a>3.5 法一：直接建表法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> table_name(col_name data_type);</span><br></pre></td></tr></table></figure>
<h5 id="3-5-1-例子：创建内部表"><a href="#3-5-1-例子：创建内部表" class="headerlink" title="3.5.1 例子：创建内部表"></a>3.5.1 例子：创建内部表</h5><p>如下：根据上述文件内容(见<a href="#jump3.1">3.1 row format</a>)，创建一个表t1</p>
<h6 id="1-创建表"><a href="#1-创建表" class="headerlink" title="1. 创建表"></a>1. 创建表</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> t1(</span><br><span class="line">    <span class="keyword">id</span>      <span class="built_in">int</span>,</span><br><span class="line">    <span class="keyword">name</span>    <span class="keyword">string</span>,</span><br><span class="line">    hobby   <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;,</span><br><span class="line">    <span class="keyword">add</span>     <span class="keyword">map</span>&lt;<span class="keyword">String</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p> <img src="/2020/01/12/Hive介绍/1603599880662.png" alt="1603599880662"></p>
<h6 id="2-查看表的描述"><a href="#2-查看表的描述" class="headerlink" title="2.查看表的描述"></a>2.查看表的描述</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc t1;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603599824805.png" alt="1603599824805"></p>
<h6 id="3-插入数据"><a href="#3-插入数据" class="headerlink" title="3. 插入数据"></a><span id="jump3.5.1.3">3. 插入数据</span></h6><p>注：一般很少用insert （不是insert overwrite）语句，因为就算就算插入一条数据，也会调用MapReduce，这里我们选择Load Data的方式。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA [LOCAL] INPATH &apos;filepath&apos; [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]</span><br></pre></td></tr></table></figure>
<p>Hive 3.0之前的加载操作是纯复制/移动操作，将数据文件移动到与Hive表相对应的位置</p>
<ul>
<li><em>filepath</em> can be:<ul>
<li>a relative path, such as project/data1</li>
<li>an absolute path, such as /user/hive/project/data1</li>
<li>a full URI with scheme and (optionally) an authority, such as hdfs://namenode:9000/user/hive/project/data1</li>
</ul>
</li>
<li>The target being loaded to can be a table or a partition. If the table is partitioned, then one must specify a specific partition of the table by specifying values for all of the partitioning columns.</li>
<li><em>filepath</em> 可以指向文件（在这种情况下，Hive会将文件移至表中），也可以是目录（在这种情况下，Hive会将目录中的所有文件移至表中）。 In either case, <em>filepath</em> addresses a set of files.</li>
<li>如果指定了关键字 LOCAL，则<ul>
<li>load命令将在本地文件系统中查找文件路径。 如果指定的是相对路径，它将相对于用户的当前工作目录进行解释。 用户也可以为本地文件指定完整的URI - for example: <code>file:///user/hive/project/data1</code></li>
<li>the load command will try to copy all the files addressed by <em>filepath</em> to the target filesystem. The target file system is inferred by looking at the location attribute of the table. The copied data files will then be moved to the table.</li>
</ul>
</li>
<li>如果未指定关键字 LOCAL，则Hive将使用文件路径的完整URI（如果已指定），或将应用以下规则：<ul>
<li>If scheme or authority are not specified, Hive will use the scheme and authority from the hadoop configuration variable <code>fs.default.name</code> that specifies the Namenode URI.</li>
<li>If the path is not absolute, then Hive will interpret it relative to <code>/user/&lt;username&gt;</code></li>
<li>Hive will <em>move</em> the files addressed by <em>filepath</em> into the table (or partition)</li>
</ul>
</li>
<li>如果使用了 OVERWRITE 关键字，then the contents of the target table (or partition) will be deleted and replaced by the files referred to by filepath； 否则，filepath指向的文件将被添加到表中。</li>
</ul>
<p>创建一个文件粘贴上述记录，并上载即可，如下图：</p>
<p><img src="/2020/01/12/Hive介绍/1603600131112.png" alt="1603600131112"></p>
<p>然后上载</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/home/hadoop/Desktop/data&apos; overwrite into table t1;</span><br></pre></td></tr></table></figure>
<p>查看表内容：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from t1;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603600188322.png" alt="1603600188322"></p>
<h6 id="4-查看文件位置"><a href="#4-查看文件位置" class="headerlink" title="4. 查看文件位置"></a>4. 查看文件位置</h6><p>t1表在哪儿呢？在我们之前配置的默认路径里（/user/hive/warehouse）</p>
<p><img src="/2020/01/12/Hive介绍/1603609902727.png" alt="1603609902727"></p>
<p>通过命令行获取位置信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted table_name;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603610044780.png" alt="1603610044780"></p>
<h6 id="5-删除内部表"><a href="#5-删除内部表" class="headerlink" title="5. 删除内部表"></a>5. 删除内部表</h6><p><img src="/2020/01/12/Hive介绍/1603610161316.png" alt="1603610161316"></p>
<p><img src="/2020/01/12/Hive介绍/1603610193337.png" alt="1603610193337"></p>
<p>观察HDFS上的文件，发现t1已经不在了</p>
<p><img src="/2020/01/12/Hive介绍/1603610402205.png" alt="1603610402205"></p>
<ul>
<li></li>
</ul>
<h5 id="3-5-2-例子：创建外部表"><a href="#3-5-2-例子：创建外部表" class="headerlink" title="3.5.2 例子：创建外部表"></a>3.5.2 例子：创建外部表</h5><h6 id="1-创建表-1"><a href="#1-创建表-1" class="headerlink" title="1. 创建表"></a>1. 创建表</h6><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> t2(</span><br><span class="line">    <span class="keyword">id</span>      <span class="built_in">int</span></span><br><span class="line">   ,<span class="keyword">name</span>    <span class="keyword">string</span></span><br><span class="line">   ,hobby   <span class="built_in">array</span>&lt;<span class="keyword">string</span>&gt;</span><br><span class="line">   ,<span class="keyword">add</span>     <span class="keyword">map</span>&lt;<span class="keyword">String</span>,<span class="keyword">string</span>&gt;</span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span></span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">','</span></span><br><span class="line">collection items <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'-'</span></span><br><span class="line"><span class="keyword">map</span> <span class="keyword">keys</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">':'</span></span><br><span class="line">location <span class="string">'/user/t2'</span></span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603600496450.png" alt="1603600496450"></p>
<h6 id="2-装载数据"><a href="#2-装载数据" class="headerlink" title="2. 装载数据"></a>2. 装载数据</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">load data local inpath &apos;/home/hadoop/Desktop/data&apos; overwrite into table t2;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603600549196.png" alt="1603600549196"></p>
<h6 id="3-查看文件位置"><a href="#3-查看文件位置" class="headerlink" title="3. 查看文件位置"></a>3. 查看文件位置</h6><p>在/user/目录下，可以看到t2文件</p>
<p><img src="/2020/01/12/Hive介绍/1603609992170.png" alt="1603609992170"></p>
<p>通过命令行获得位置信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">desc formatted table_name;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603610068333.png" alt="1603610068333"></p>
<h6 id="4-删除外部表"><a href="#4-删除外部表" class="headerlink" title="4. 删除外部表"></a>4. 删除外部表</h6><p><img src="/2020/01/12/Hive介绍/1603610449476.png" alt="1603610449476"></p>
<p><img src="/2020/01/12/Hive介绍/1603610471246.png" alt="1603610471246"></p>
<p>观察HDFS上的文件，t2仍然存在</p>
<p><img src="/2020/01/12/Hive介绍/1603610518016.png" alt="1603610518016"></p>
<p>因而删除外部表仅仅会删除元数据。</p>
<p>重新创建外部表t2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create external table t2(</span><br><span class="line">    id      int</span><br><span class="line">   ,name    string</span><br><span class="line">   ,hobby   array&lt;string&gt;</span><br><span class="line">   ,add     map&lt;String,string&gt;</span><br><span class="line">)</span><br><span class="line">row format delimited</span><br><span class="line">fields terminated by &apos;,&apos;</span><br><span class="line">collection items terminated by &apos;-&apos;</span><br><span class="line">map keys terminated by &apos;:&apos;</span><br><span class="line">location &apos;/user/t2&apos;</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p><img src="/2020/01/12/Hive介绍/1603610616445.png" alt="1603610616445"></p>
<p>不往里面插入数据，我们select * 看看结果</p>
<p><img src="/2020/01/12/Hive介绍/1603610644871.png" alt="1603610644871"></p>
<p>可见数据仍然在！</p>
<h4 id="3-6-法二：查询建表法（Create-Table-As-Select-CTAS-）"><a href="#3-6-法二：查询建表法（Create-Table-As-Select-CTAS-）" class="headerlink" title="3.6 法二：查询建表法（Create Table As Select (CTAS)）"></a>3.6 法二：查询建表法（Create Table As Select (CTAS)）</h4><p>通过AS 查询语句完成建表：<strong>将子查询的结果存在新表里，有数据</strong><br>一般用于中间表。</p>
<p>可以通过一个create-table-as-select（CTAS）语句中的查询结果来创建和填充表。 CTAS创建的表是原子表，这意味着在填充所有查询结果之前，其他用户不会看到该表。因此，其他用户要么看到包含完整查询结果的表，要么根本看不到表。</p>
<p>CTAS有两部分，SELECT部分可以是HiveQL支持的任何SELECT语句 ( <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select" target="_blank" rel="noopener">SELECT statement</a>)； CREATE部分从SELECT部分获取结果模式，并使用其他表属性（例如SerDe和存储格式）创建<strong>目标表</strong>。( The CREATE part of the CTAS takes the resulting schema from the SELECT part and creates the target table with other table properties such as the SerDe and storage format.)</p>
<p>从Hive 3.2.0开始，CTAS语句可以为目标表定义分区规范。(can define a partitioning specification for the target table (<a href="https://issues.apache.org/jira/browse/HIVE-20241" target="_blank" rel="noopener">HIVE-20241</a>)).</p>
<p>CTAS具有以下限制：</p>
<ul>
<li><p>目标表不能是外部表。</p>
</li>
<li><p>目标表不能是列表存储表 (list bucketing table)。</p>
</li>
</ul>
<p>例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE new_key_value_store</span><br><span class="line">   ROW FORMAT SERDE &quot;org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe&quot;</span><br><span class="line">   STORED AS RCFile</span><br><span class="line">   AS</span><br><span class="line">SELECT (key % 1024) new_key, concat(key, value) key_value_pair</span><br><span class="line">FROM key_value_store</span><br><span class="line">SORT BY new_key, key_value_pair;</span><br></pre></td></tr></table></figure>
<p>上面的CTAS语句使用从SELECT语句结果得到的schema（new_key DOUBLE，key_value_pair STRING）创建目标表new_key_value_store。如果SELECT语句未指定列别名，则列名将自动分配给_col0，_col1和_col2等。此外，新目标表是使用特定的SerDe和存储格式创建的，独立于the source tables in the SELECT statement.</p>
<p>Starting with <a href="https://issues.apache.org/jira/browse/HIVE-1180" target="_blank" rel="noopener">Hive 0.13.0</a>, the SELECT statement can include one or more common table expressions (CTEs), as shown in the <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select#LanguageManualSelect-SelectSyntax" target="_blank" rel="noopener">SELECT syntax</a>. For an example, see <a href="https://cwiki.apache.org/confluence/display/Hive/Common+Table+Expression#CommonTableExpression-CTEinViews,CTAS,andInsertStatements" target="_blank" rel="noopener">Common Table Expression</a>.</p>
<p>能够<strong>从一个表选择数据到另一个表</strong>是Hive最强大的特性之一。Hive在执行查询时处理数据从源格式到目标格式的转换。(Being able to select data from one table to another is one of the most powerful features of Hive. Hive handles the conversion of the data from the source format to the destination format as the query is being executed.)</p>
<p>根据例子我们建一张表：t3</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table t3 as</span><br><span class="line">select</span><br><span class="line">    id,</span><br><span class="line">    name</span><br><span class="line">from t2</span><br><span class="line">;</span><br></pre></td></tr></table></figure>
<p>会执行MapReduce过程。<br>查看表结构及内容，发现是有数据的，并且由于没有指定外部表和location，该表在默认位置，即是内部表。</p>
<p><img src="/2020/01/12/Hive介绍/1603613699566.png" alt="1603613699566"></p>
<h4 id="3-7-法三：like建表法"><a href="#3-7-法三：like建表法" class="headerlink" title="3.7 法三：like建表法"></a>3.7 法三：like建表法</h4><p><strong>会创建结构完全相同的表，但是没有数据。</strong><br>常用于中间表.</p>
<p>LIKE形式的CREATE TABLE允许您精确地<strong> </strong>。(The LIKE form of CREATE TABLE allows you to copy an existing table definition exactly (without copying its data). )</p>
<p>与CTAS相比，以下语句创建了一个新的empty_key_value_store表，它的定义在表名以外的所有细节上与现有key_value_store完全匹配。 新表不包含任何行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE empty_key_value_store</span><br><span class="line">LIKE key_value_store [TBLPROPERTIES (property_name=property_value, ...)];</span><br></pre></td></tr></table></figure>
<p>在Hive 0.8.0之前，CREATE TABLE LIKE view_name将复制该视图。 在Hive 0.8.0和更高版本中，CREATE TABLE LIKE view_name通过使用view_name schema（字段(fields)和分区列(partition columns)）, 使用SerDe和文件格式的默认值来创建一个表。</p>
<p>注：上面语句中如果不使用 EXTERNAL 关键字，若源表是外部表的话，生成的新表也将是外部表；若源表是内部表的话，生成的新表也将是内部表。若语句中包含 EXTERNAL 关键字且源表是内部表的话，生成的新表将是外部表。即使在这种场景下，LOCATION 子句同样是可选的。</p>
<p>例子：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create table t4 like t2;</span><br></pre></td></tr></table></figure>
<p>可以发现，不会执行MapReduce，且表结构和t2完全一样，但是没有数据。</p>
<p><img src="/2020/01/12/Hive介绍/1603614353762.png" alt="1603614353762"></p>
<h3 id="4-Hive中表的类型"><a href="#4-Hive中表的类型" class="headerlink" title="4. Hive中表的类型"></a>4. Hive中表的类型</h3><p>Hive中有5种表：内部表，外部表，临时表，分区表，桶表（分桶表）</p>
<h4 id="4-1-内部表（Managed-Table）"><a href="#4-1-内部表（Managed-Table）" class="headerlink" title="4.1 内部表（Managed Table）"></a><span id="jump4.1">4.1 内部表（Managed Table）</span></h4><p>关于内部表的其他内容见 <a href="#jump3.3">3.3 内部表与外部表</a><br>数据默认存储在/user/hive/warehouse，由Hive自身管理，删除内部表会同时删除存储数据和元数据。</p>
<p><strong>建表：</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">// 建表方式一</span><br><span class="line">create table t1(</span><br><span class="line">    id	INT,</span><br><span class="line">    name STRING,</span><br><span class="line">    age INT,</span><br><span class="line">    gfs ARRAY&lt;STRING&gt;,</span><br><span class="line">    address MAP&lt;STRING,STRING&gt;,</span><br><span class="line">    info STRUCT&lt;country:String,province:String,shi:String&gt;</span><br><span class="line">)</span><br><span class="line">ROW FORMAT DELIMITED </span><br><span class="line">FIELDS TERMINATED BY &apos; &apos; </span><br><span class="line">COLLECTION ITEMS TERMINATED BY &apos;,&apos;</span><br><span class="line">MAP KEYS TERMINATED BY &apos;:&apos; </span><br><span class="line">LINES TERMINATED BY &apos;\n&apos;</span><br><span class="line">LOCATION &quot;/test&quot;;//可以设置源数据的位置，若不设置默认就在Hive的工作目录区</span><br><span class="line"></span><br><span class="line">// 建表方式二</span><br><span class="line">create table gfstbl1 like gfstbl;只是创建表结构</span><br><span class="line"></span><br><span class="line">// 建表方式三</span><br><span class="line">create table gfstbl2 AS SELECT id,name,gfs,address from gfstbl; </span><br><span class="line">  会创建相应的表结构，并且插入数据，相当于完整的赋值</span><br></pre></td></tr></table></figure>
<p>关于建表的更详细介绍见 <a href="#jump3">3. Hive建表语句</a></p>
<p><strong>加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/root/gfs.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> gfstbl;</span><br></pre></td></tr></table></figure>
<p>更详细介绍见 3.5 法一：直接建表法中的 <a href="#jump3.5.1.3">3.插入数据</a></p>
<p><strong>查看表描述信息：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DESCRIBE</span> [<span class="keyword">EXTENDED</span>|FORMATTED] table_name</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DESCRIBE FORMATTED gfstbl;</span><br></pre></td></tr></table></figure>
<p>DESCRIBE显示列的列表（the list of columns），包括给定表的分区列（partition columns）。 如果指定了EXTENDED关键字，则它将以Thrift序列化形式显示表的所有元数据。 这通常只在调试时有用，而不适用于一般使用。 如果指定了FORMATTED关键字，则它将以表格格式显示元数据。</p>
<p><strong><span id="jump4.1.insert">插入数据的其他方式：</span></strong></p>
<p>Syntax:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Standard syntax:</span><br><span class="line">INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1 FROM from_statement;</span><br><span class="line">INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1 FROM from_statement;</span><br><span class="line"> </span><br><span class="line">Hive extension (multiple inserts):</span><br><span class="line">FROM from_statement</span><br><span class="line">INSERT OVERWRITE TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...) [IF NOT EXISTS]] select_statement1</span><br><span class="line">[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] select_statement2]</span><br><span class="line">[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2] ...;</span><br><span class="line">FROM from_statement</span><br><span class="line">INSERT INTO TABLE tablename1 [PARTITION (partcol1=val1, partcol2=val2 ...)] select_statement1</span><br><span class="line">[INSERT INTO TABLE tablename2 [PARTITION ...] select_statement2]</span><br><span class="line">[INSERT OVERWRITE TABLE tablename2 [PARTITION ... [IF NOT EXISTS]] select_statement2] ...;</span><br><span class="line"> </span><br><span class="line">Hive extension (dynamic partition inserts):</span><br><span class="line">INSERT OVERWRITE TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement;</span><br><span class="line">INSERT INTO TABLE tablename PARTITION (partcol1[=val1], partcol2[=val2] ...) select_statement FROM from_statement;</span><br></pre></td></tr></table></figure>
<p>解释：</p>
<ul>
<li>INSERT OVERWRITE将覆盖表或分区中的任何现有数据<ul>
<li>unless <code>IF NOT EXISTS</code> is provided for a partition (as of Hive <a href="https://issues.apache.org/jira/browse/HIVE-2612" target="_blank" rel="noopener">0.9.0</a>).</li>
<li>As of Hive 2.3.0 (<a href="https://issues.apache.org/jira/browse/HIVE-15880" target="_blank" rel="noopener">HIVE-15880</a>), if the table has <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-listTableProperties" target="_blank" rel="noopener">TBLPROPERTIES</a> (“auto.purge”=”true”) the previous data of the table is not moved to Trash when INSERT OVERWRITE query is run against the table. This functionality is applicable only for managed tables (see <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-ManagedandExternalTables" target="_blank" rel="noopener">managed tables</a>) and is turned off when “auto.purge” property is unset or set to false.</li>
</ul>
</li>
<li>INSERT INTO将追加到表或分区，保持现有数据不变。<ul>
<li>As of Hive <a href="https://issues.apache.org/jira/browse/HIVE-6406" target="_blank" rel="noopener">0.13.0</a>, a table can be made <strong>immutable</strong> by creating it with <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-CreateTable" target="_blank" rel="noopener">TBLPROPERTIES (“immutable”=”true”)</a>. The default is “immutable”=”false”.<br>INSERT INTO behavior into an immutable table is disallowed if any data is already present, although INSERT INTO still works if the immutable table is empty.<br>如果表中已经存在任何数据，则不允许在不可变表中执行INSERT INTO行为，但如果不可变表为空，则插入INTO仍然可以工作。 INSERT OVERWRITE 的行为不受“不可变”表属性的影响。The behavior of INSERT OVERWRITE is not affected by the “immutable” table property.<br>不可变表可以防止由于脚本错误地多次运行而将数据加载到表中的意外更新。The first insert into an immutable table succeeds and successive inserts fail, resulting in only one set of data in the table, instead of silently succeeding with multiple copies of the data in the table.</li>
</ul>
</li>
<li>可以对表或分区进行插入。If the table is partitioned, then one must specify a specific partition of the table by specifying values for all of the partitioning columns. If <a href="https://cwiki.apache.org/confluence/display/Hive/Configuration+Properties#ConfigurationProperties-hive.typecheck.on.insert" target="_blank" rel="noopener">hive.typecheck.on.insert</a> is set to true, these values are validated, converted and normalized to conform to their column types (Hive <a href="https://issues.apache.org/jira/browse/HIVE-5297" target="_blank" rel="noopener">0.12.0</a> onward). </li>
<li>可以在同一查询中指定多个插入子句（也称为多表插入）。</li>
<li>The output of each of the select statements is written to the chosen table (or partition). Currently the OVERWRITE keyword is mandatory and implies that the contents of the chosen table or partition are replaced with the output of corresponding select statement.</li>
<li>The output format and serialization class is determined by the table’s metadata (as specified via DDL commands on the table).</li>
<li>As of Hive <a href="https://issues.apache.org/jira/browse/HIVE-9353" target="_blank" rel="noopener">1.1.0</a> the TABLE keyword is optional.</li>
<li>As of Hive <a href="https://issues.apache.org/jira/browse/HIVE-9481" target="_blank" rel="noopener">1.2.0</a> each INSERT INTO T can take a column list like INSERT INTO T (z, x, c1).  See Description of <a href="https://issues.apache.org/jira/browse/HIVE-9481" target="_blank" rel="noopener">HIVE-9481</a> for examples.</li>
</ul>
<p><strong>Notes</strong></p>
<ul>
<li>Multi Table Inserts minimize the number of data scans required. Hive can insert data into multiple tables by scanning the input data just once (and applying different query operators) to the input data. 多表插入可最大程度地减少所需的数据扫描次数。 Hive可以通过只扫描一次输入数据（并应用不同的查询运算符）到输入数据来将数据插入到多个表中。</li>
<li>Starting with <a href="https://issues.apache.org/jira/browse/HIVE-1180" target="_blank" rel="noopener">Hive 0.13.0</a>, the select statement can include one or more common table expressions (CTEs) as shown in the <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Select#LanguageManualSelect-SelectSyntax" target="_blank" rel="noopener">SELECT syntax</a>. For an example, see <a href="https://cwiki.apache.org/confluence/display/Hive/Common+Table+Expression#CommonTableExpression-CTEinViews,CTAS,andInsertStatements" target="_blank" rel="noopener">Common Table Expression</a>.</li>
</ul>
<p>例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">insert into rest select count(*) from table;</span><br><span class="line">		</span><br><span class="line">习惯写法 from提前  减少SQL代码的冗余</span><br><span class="line">from day_hour_table</span><br><span class="line">insert into rest </span><br><span class="line">select count(*) ;</span><br></pre></td></tr></table></figure>
<h4 id="4-2-外部表（External-Table）"><a href="#4-2-外部表（External-Table）" class="headerlink" title="4.2 外部表（External Table）"></a><span id="jump4.2">4.2 外部表（External Table）</span></h4><p>更多关于外部表的内容见 <a href="#jump3.3">3.3 内部表与外部表</a></p>
<p>数据存储位置由用户自己指定，<strong>由HDFS管理，删除外部表时仅仅会删除元数据，存储数据不会受到影响。</strong></p>
<ul>
<li><p>适用情形：<br>当一份日志需要多个小组一起分析，分析完了之后创建的表就可以删除了。但是普通的表删除的同时也会把数据删除，这样就会影响到其他小组的分析，而且日志数据也不能随便删除。所以，需要外部表，删除外部表，不会删除对应的HDFS上的数据。</p>
</li>
<li><p>对比外部表和内部表区别<br>删除外部表，数据不会有任何改变，只是mysql中的元数据被修改，但是删除内部表（管理表），数据就会被删除。</p>
</li>
</ul>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">external</span> <span class="keyword">table</span> wc_external (</span><br><span class="line">    word1 <span class="keyword">STRING</span>, </span><br><span class="line">    word2 <span class="keyword">STRING</span></span><br><span class="line">) </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">' '</span> </span><br><span class="line">location <span class="string">'/test/external'</span>; location可加可不加，不加location默认是在hive的工作目录区</span><br></pre></td></tr></table></figure>
<blockquote>
<p>总结：hive内部表和外部表的区别<br>    1）创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径， 不对数据的位置做任何改变。<br>    2）删除表时：在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据</p>
</blockquote>
<h4 id="4-3-临时表（Temporary-Table）"><a href="#4-3-临时表（Temporary-Table）" class="headerlink" title="4.3 临时表（Temporary Table）"></a>4.3 临时表（Temporary Table）</h4><p>在当前会话期间存在，会话结束后自动销毁。</p>
<ul>
<li>适用情形<br>临时分析，在关闭hive客户端后，临时表就会消失。主要用于存储不重要中间结果集，不重要的表。</li>
</ul>
<p>临时表具有以下限制：</p>
<ul>
<li>不支持分区列。</li>
<li>不支持创建索引。</li>
</ul>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">TEMPORARY</span> <span class="keyword">table</span> ttabc(<span class="keyword">id</span> <span class="built_in">Int</span>,<span class="keyword">name</span> <span class="keyword">String</span>) 临时表的声明周期是一次会话</span><br><span class="line">进入hive shell 创建一张表，关闭shell后，表丢失，临时表不支持分区</span><br></pre></td></tr></table></figure>
<p><strong>建表并加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">TEMPORARY</span> <span class="keyword">table</span> dept_tmp(  </span><br><span class="line">    deptno <span class="built_in">int</span>,  </span><br><span class="line">    dname <span class="keyword">string</span>,</span><br><span class="line">    loc <span class="keyword">string</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  </span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">'/opt/datas/dept.txt'</span> <span class="keyword">into</span> <span class="keyword">table</span> dept_tmp;</span><br></pre></td></tr></table></figure>
<p><strong>查看location信息：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">desc formatted dept_tmp;</span><br><span class="line">Location:               hdfs://172.19.199.187:8020/tmp/hive/hadoop/68174383-f427-4629-9707-0ab1c9b07726/_tmp_space.db/d872efec-1294-48b0-9071-31cf98d46400    </span><br><span class="line">Table Type:             MANAGED_TABLE</span><br></pre></td></tr></table></figure>
<h4 id="4-4-分区表（Partitioned-Table）"><a href="#4-4-分区表（Partitioned-Table）" class="headerlink" title="4.4 分区表（Partitioned Table）"></a><span id="jump4.4">4.4 分区表（Partitioned Table）</span></h4><p>另外关于分区表的内容见 <a href="#jump3.4">3.4 Partitioned Tables</a></p>
<p>将数据按照某个字段或者关键字分成多个子目录来存储，防止暴力扫描全表。</p>
<ul>
<li><p>适用情形</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from logs where date = &apos;20171209&apos;</span><br></pre></td></tr></table></figure>
<ul>
<li>普通表执行流程：对全表的数据进行查询，然后进行过滤操作。</li>
<li>分区表执行流程：直接加载对应文件路径下的数据。</li>
</ul>
<p>适用于大数据量，可以通过分区快速定位需要查询的数据，<strong>分区表的作用主要是提高查询检索的效率 。</strong></p>
</li>
</ul>
<p><strong>静态分区表：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> day_hour_table (<span class="keyword">id</span> <span class="built_in">int</span>, <span class="keyword">content</span> <span class="keyword">string</span>) partitioned <span class="keyword">by</span> (dt <span class="built_in">int</span>,<span class="keyword">hour</span> <span class="built_in">int</span>) </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\t'</span> ;</span><br></pre></td></tr></table></figure>
<p><strong>加载数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- insert单条插入的方式往分区表中插入数据：</span></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">9</span>,<span class="keyword">hour</span>=<span class="number">1</span>) <span class="keyword">values</span>(<span class="number">1</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">9</span>,<span class="keyword">hour</span>=<span class="number">2</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">8</span>,<span class="keyword">hour</span>=<span class="number">1</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> day_hour_table <span class="keyword">partition</span>(dt=<span class="number">8</span>,<span class="keyword">hour</span>=<span class="number">2</span>) <span class="keyword">values</span>(<span class="number">3</span>,<span class="string">"a2 bc"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- load批量插入的方式往分区表中插入数据：</span></span><br><span class="line"><span class="keyword">load</span> <span class="keyword">data</span> <span class="keyword">local</span> inpath <span class="string">"/root/ceshi"</span> <span class="keyword">into</span> <span class="keyword">table</span> day_table <span class="keyword">partition</span> (dt=<span class="number">10</span>,<span class="keyword">hour</span>=<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p><strong>删除Hive分区表中的分区：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_table <span class="keyword">DROP</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10</span>,<span class="keyword">hour</span>=<span class="number">10</span>);</span><br></pre></td></tr></table></figure>
<p><strong>创建\添加分区：</strong></p>
<p>Syntax:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> table_name <span class="keyword">ADD</span> [<span class="keyword">IF</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span>] <span class="keyword">PARTITION</span> partition_spec [LOCATION <span class="string">'location'</span>]</span><br><span class="line">[, <span class="keyword">PARTITION</span> partition_spec [LOCATION <span class="string">'location'</span>], ...];</span><br><span class="line"></span><br><span class="line">partition_spec:</span><br><span class="line">	  : (partition_column = partition_col_value, partition_column = partition_col_value, ...)</span><br></pre></td></tr></table></figure>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 创建一个空分区：</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10000</span>, <span class="keyword">hour</span>=<span class="number">2000</span>);</span><br><span class="line"><span class="comment">-- 然后将数据上传到空分区对应的目录下，分区表中就会显示数据</span></span><br><span class="line">HDFS dfs -put ........</span><br><span class="line"><span class="comment">-- 创建一个空分区并且将空分区指向数据位置：</span></span><br><span class="line"><span class="keyword">ALTER</span> <span class="keyword">TABLE</span> day_hour_table <span class="keyword">ADD</span> <span class="keyword">PARTITION</span> (dt=<span class="number">10000</span>, <span class="keyword">hour</span>=<span class="number">2000</span>) location <span class="string">"/test"</span></span><br></pre></td></tr></table></figure>
<p><strong>动态分区表：</strong></p>
<p>动态分区表和静态分区表建表语句相同，插入数据的方式不同</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition=<span class="literal">true</span>;</span><br><span class="line"><span class="keyword">set</span> hive.exec.dynamic.partition.mode=nonstrict;</span><br></pre></td></tr></table></figure>
<p>动态分区可以根据数据本身的特征自动来划分分区，<code>load data …</code> 只是将数据上传到HDFS指定目录，所以我们需要使用from insert的方式插入数据，hive才会根据分区设置自动将数据进行分区。（详细内容见👇）</p>
<p><strong>动态分区插入（Dynamic Partition Inserts）</strong></p>
<blockquote>
<p>参考 <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML</a></p>
</blockquote>
<p>在动态分区插入中，用户可以提供部分分区规范，这意味着只需在PARTITION子句中指定分区列名列表 ( specifying the list of partition column names)。列值是可选的 (The column values are optional)。如果给定一个分区列值 (partition column value)，我们称其为静态分区，否则为动态分区。每个动态分区列都有一个来自select语句的相应输入列。这意味着动态分区的创建由输入列的值决定。动态分区列必须在SELECT语句的列中最后指定，并且按照它们在PARTITION()子句中出现的顺序指定。</p>
<blockquote>
<p>In the dynamic partition inserts, users can give partial partition specifications, which means just specifying the list of partition column names in the PARTITION clause. The column values are optional. If a partition column value is given, we call this a static partition, otherwise it is a dynamic partition. Each dynamic partition column has a corresponding input column from the select statement. This means that the dynamic partition creation is determined by the value of the input column. The dynamic partition columns must be <strong>specified last</strong> among the columns in the SELECT statement and <strong>in the same order</strong> in which they appear in the PARTITION() clause.</p>
</blockquote>
<p>As of Hive 3.0.0 (<a href="https://issues.apache.org/jira/browse/HIVE-19083" target="_blank" rel="noopener">HIVE-19083</a>) there is no need to specify dynamic partition columns. Hive will automatically generate partition specification if it is not specified.</p>
<style>
table th:first-of-type {
    width: 220px;
}
table th:nth-of-type(2) {
    width: 70px;
}
</style>

<div class="table-container">
<table>
<thead>
<tr>
<th>Configuration property</th>
<th>Default</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>hive.exec.dynamic.partition</code></td>
<td><code>true</code></td>
<td>Needs to be set to <code>true</code> to enable dynamic partition inserts</td>
</tr>
<tr>
<td><code>hive.exec.dynamic.partition.mode</code></td>
<td><code>strict</code></td>
<td>In <code>strict</code> mode, the user must specify at least one static partition in case the user accidentally overwrites all partitions, in <code>nonstrict</code> mode all partitions are allowed to be dynamic</td>
</tr>
<tr>
<td><code>hive.exec.max.dynamic.partitions.pernode</code></td>
<td>100</td>
<td>Maximum number of dynamic partitions allowed to be created in each mapper/reducer node</td>
</tr>
<tr>
<td><code>hive.exec.max.dynamic.partitions</code></td>
<td>1000</td>
<td>Maximum number of dynamic partitions allowed to be created in total</td>
</tr>
<tr>
<td><code>hive.exec.max.created.files</code></td>
<td>100000</td>
<td>Maximum number of HDFS files created by all mappers/reducers in a MapReduce job</td>
</tr>
<tr>
<td><code>hive.error.on.empty.partition</code></td>
<td><code>false</code></td>
<td>Whether to throw an exception if dynamic partition insert generates empty results</td>
</tr>
</tbody>
</table>
</div>
<p>例：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM page_view_stg pvs</span><br><span class="line">INSERT OVERWRITE TABLE page_view PARTITION(dt=&apos;2008-06-08&apos;, country)</span><br><span class="line">       SELECT pvs.viewTime, pvs.userid, pvs.page_url, pvs.referrer_url, null, null, pvs.ip, pvs.cnt</span><br></pre></td></tr></table></figure>
<p>在这里，country 分区将由SELECT子句的最后一列（即pvs.cnt）动态创建。Note that the name is not used. 在 nonstrict 模式下，the <code>dt</code> partition could also be dynamically created.</p>
<p>关于 INSERT 的语法见 4.1 内部表（Managed Table）中的<a href="#jump4.1.insert">插入数据的其他方式</a>部分.</p>
<h4 id="4-5-分桶表（Bucked-Tables）"><a href="#4-5-分桶表（Bucked-Tables）" class="headerlink" title="4.5 分桶表（Bucked Tables）"></a><span id="jump4.5">4.5 分桶表（Bucked Tables）</span></h4><p>将数据按照某个字段和桶的数量，对指定字段进行取模运算，拆分成多个小文件来存储，模相同的存储在同一个小文件中，提高join以及抽样的效率。</p>
<ul>
<li>适用情形<br>数据有严重的数据倾斜，分布不均匀，但是相对来说每个桶中的数据量会比较平均。桶与桶之间做join等查询的时候，会有优化。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing=<span class="literal">true</span>; </span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> emp_bu(  </span><br><span class="line">    empno <span class="built_in">int</span>,  </span><br><span class="line">    ename <span class="keyword">string</span>,</span><br><span class="line">    job <span class="keyword">string</span>,  </span><br><span class="line">    mgr <span class="built_in">int</span>,</span><br><span class="line">    hiredate <span class="keyword">string</span>,  </span><br><span class="line">    sal <span class="keyword">double</span>,  </span><br><span class="line">    comm <span class="keyword">double</span>,  </span><br><span class="line">    deptno <span class="built_in">int</span></span><br><span class="line">)</span><br><span class="line">CLUSTERED <span class="keyword">BY</span>(deptno) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS</span><br><span class="line"><span class="keyword">row</span> <span class="keyword">format</span> <span class="keyword">delimited</span>  </span><br><span class="line"><span class="keyword">fields</span> <span class="keyword">terminated</span> <span class="keyword">by</span> <span class="string">'\t'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> overwrite <span class="keyword">table</span> emp_bu_2 <span class="keyword">select</span> * <span class="keyword">from</span> emp;</span><br></pre></td></tr></table></figure>
<p>分桶表是对列值取哈希值的方式，将不同数据放到不同文件中存储，由列值的哈希值除以桶的个数来决定每条数据划分在哪个桶中。对于hive中每一个表、分区都可以进一步进行分桶。</p>
<p>For an int, it’s easy, <code>hash_int(i) == i</code>. 例如基于user_id进行分桶时， if user_id were an int, and there were 10 buckets, we would expect all user_id’s that end in 0 to be in bucket 1, all user_id’s that end in a 1 to be in bucket 2, etc. </p>
<p><strong>建表：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> psnbucket( </span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span>, </span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">STRING</span>, </span><br><span class="line">    age <span class="built_in">INT</span></span><br><span class="line">) </span><br><span class="line">CLUSTERED <span class="keyword">BY</span> (age) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<p><strong>插入数据：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">table</span> psnbucket <span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span>, age <span class="keyword">from</span> original;</span><br></pre></td></tr></table></figure>
<p><strong>分桶表+分区表：</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> psnbucket_partition( </span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">INT</span>, </span><br><span class="line">    <span class="keyword">name</span> <span class="keyword">STRING</span>, </span><br><span class="line">    age <span class="built_in">INT</span></span><br><span class="line">) </span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(height <span class="keyword">DOUBLE</span>) </span><br><span class="line">CLUSTERED <span class="keyword">BY</span> (age) <span class="keyword">INTO</span> <span class="number">4</span> BUCKETS </span><br><span class="line"><span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span> </span><br><span class="line"><span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">','</span>;</span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>参考 <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL+BucketedTables</a></p>
</blockquote>
<p>Bucketed tables are fantastic in that they allow much more efficient <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Sampling" target="_blank" rel="noopener">sampling</a> than do non-bucketed tables, and they may later allow for time saving operations such as mapside joins. However, the bucketing specified at table creation is not enforced when the table is written to, and so it is possible for the table’s metadata to advertise properties which are not upheld by the table’s actual layout. This should obviously be avoided. Here’s how to do it right.</p>
<p>First, <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-Create/Drop/TruncateTable" target="_blank" rel="noopener">table creation</a>:</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> user_info_bucketed(user_id <span class="built_in">BIGINT</span>, firstname <span class="keyword">STRING</span>, lastname <span class="keyword">STRING</span>)</span><br><span class="line"><span class="keyword">COMMENT</span> <span class="string">'A bucketed copy of user_info'</span></span><br><span class="line">PARTITIONED <span class="keyword">BY</span>(ds <span class="keyword">STRING</span>)</span><br><span class="line">CLUSTERED <span class="keyword">BY</span>(user_id) <span class="keyword">INTO</span> <span class="number">256</span> BUCKETS;</span><br></pre></td></tr></table></figure>
<p>Note that we specify a column (user_id) to base the bucketing.<br>Then we populate the table</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">set</span> hive.enforce.bucketing = <span class="literal">true</span>;  <span class="comment">-- (<span class="doctag">Note:</span> Not needed in Hive 2.x onward)</span></span><br><span class="line">FROM user_id</span><br><span class="line"><span class="keyword">INSERT</span> OVERWRITE <span class="keyword">TABLE</span> user_info_bucketed</span><br><span class="line"><span class="keyword">PARTITION</span> (ds=<span class="string">'2009-02-25'</span>)</span><br><span class="line"><span class="keyword">SELECT</span> userid, firstname, lastname <span class="keyword">WHERE</span> ds=<span class="string">'2009-02-25'</span>;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>Version 0.x and 1.x only</strong><br>The command <code>set hive.enforce.bucketing = true;</code> allows the correct number of reducers and the cluster by column to be automatically selected based on the table. Otherwise, you would need to set the number of reducers to be the same as the number of buckets as in <code>set mapred.reduce.tasks = 256;</code> and have a <code>CLUSTER BY ...</code> clause in the select.</p>
</blockquote>
<p>What can go wrong? As long as you use the syntax above and <code>set hive.enforce.bucketing = true</code> (for Hive 0.x and 1.x), the tables should be populated properly. Things can go wrong if the bucketing column type is different during the insert and on read, or if you manually cluster by a value that’s different from the table definition.</p>
<p><strong>Bucketed Sorted Tables</strong></p>
<blockquote>
<p>参考<br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-TemporaryTables" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-TemporaryTables</a></p>
</blockquote>
<p>例：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> page_view(viewTime <span class="built_in">INT</span>, userid <span class="built_in">BIGINT</span>,</span><br><span class="line">     page_url <span class="keyword">STRING</span>, referrer_url <span class="keyword">STRING</span>,</span><br><span class="line">     ip <span class="keyword">STRING</span> <span class="keyword">COMMENT</span> <span class="string">'IP Address of the User'</span>)</span><br><span class="line"> <span class="keyword">COMMENT</span> <span class="string">'This is the page view table'</span></span><br><span class="line"> PARTITIONED <span class="keyword">BY</span>(dt <span class="keyword">STRING</span>, country <span class="keyword">STRING</span>)</span><br><span class="line"> CLUSTERED <span class="keyword">BY</span>(userid) SORTED <span class="keyword">BY</span>(viewTime) <span class="keyword">INTO</span> <span class="number">32</span> BUCKETS</span><br><span class="line"> <span class="keyword">ROW</span> <span class="keyword">FORMAT</span> <span class="keyword">DELIMITED</span></span><br><span class="line">   <span class="keyword">FIELDS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\001'</span></span><br><span class="line">   COLLECTION ITEMS <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\002'</span></span><br><span class="line">   <span class="keyword">MAP</span> <span class="keyword">KEYS</span> <span class="keyword">TERMINATED</span> <span class="keyword">BY</span> <span class="string">'\003'</span></span><br><span class="line"> <span class="keyword">STORED</span> <span class="keyword">AS</span> SEQUENCEFILE;</span><br></pre></td></tr></table></figure>
<p>In the example above, the page_view table is bucketed (clustered by) userid and within each bucket the data is sorted in increasing order of viewTime. Such an organization allows the user to do efficient sampling on the clustered column - in this case userid. The sorting property allows internal operators to take advantage of the better-known data structure while evaluating queries, also increasing efficiency. MAP KEYS and COLLECTION ITEMS keywords can be used if any of the columns are lists or maps.</p>
<p>CLUSTERED BY和SORTED BY创建命令不会影响将数据插入表的方式，而只会影响数据的读取方式。 这意味着用户必须注意正确地插入数据，方法是将reducer的数量指定为等于存储桶的数量，并在查询中使用CLUSTER BY和SORT BY命令。</p>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/Hive/" rel="tag"># Hive</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/01/12/笔试知识点/" rel="next" title="笔试知识点">
                <i class="fa fa-chevron-left"></i> 笔试知识点
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/01/13/视图View/" rel="prev" title="视图View">
                视图View <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.gif" alt="qypx">
            
              <p class="site-author-name" itemprop="name">qypx</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">103</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">10</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">46</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/qypx" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
            </div>
          


          
          

          
          

          


          <!-- 新增的内容 -->
          <!-- require APlayer -->
          <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css">
          <script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script>
          <!-- require MetingJS -->
          <script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

          <meting-js server="netease" type="playlist" id="4870130923" list-folded="true" order="random">
          </meting-js>
          <!-- 新增的内容end -->

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-什么是Hive？"><span class="nav-text">1.什么是Hive？</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Hive的原理"><span class="nav-text">2.Hive的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Hive建表语句"><span class="nav-text">3.Hive建表语句</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-row-format"><span class="nav-text">3.1 row format</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-file-format（HDFS文件存放的格式）"><span class="nav-text">3.2 file format（HDFS文件存放的格式）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-内部表与外部表"><span class="nav-text">3.3 内部表与外部表</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Feature-comparison"><span class="nav-text">Feature comparison</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#Managed-tables-内部表"><span class="nav-text">Managed tables 内部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#External-tables-外部表"><span class="nav-text">External tables 外部表</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#区别"><span class="nav-text">区别</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-4-Partitioned-Tables"><span class="nav-text">3.4 Partitioned Tables</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-5-法一：直接建表法"><span class="nav-text">3.5 法一：直接建表法</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#3-5-1-例子：创建内部表"><span class="nav-text">3.5.1 例子：创建内部表</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-创建表"><span class="nav-text">1. 创建表</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-查看表的描述"><span class="nav-text">2.查看表的描述</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-插入数据"><span class="nav-text">3. 插入数据</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-查看文件位置"><span class="nav-text">4. 查看文件位置</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#5-删除内部表"><span class="nav-text">5. 删除内部表</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3-5-2-例子：创建外部表"><span class="nav-text">3.5.2 例子：创建外部表</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-创建表-1"><span class="nav-text">1. 创建表</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-装载数据"><span class="nav-text">2. 装载数据</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-查看文件位置"><span class="nav-text">3. 查看文件位置</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-删除外部表"><span class="nav-text">4. 删除外部表</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-6-法二：查询建表法（Create-Table-As-Select-CTAS-）"><span class="nav-text">3.6 法二：查询建表法（Create Table As Select (CTAS)）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-7-法三：like建表法"><span class="nav-text">3.7 法三：like建表法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Hive中表的类型"><span class="nav-text">4. Hive中表的类型</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-内部表（Managed-Table）"><span class="nav-text">4.1 内部表（Managed Table）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-外部表（External-Table）"><span class="nav-text">4.2 外部表（External Table）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-临时表（Temporary-Table）"><span class="nav-text">4.3 临时表（Temporary Table）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-分区表（Partitioned-Table）"><span class="nav-text">4.4 分区表（Partitioned Table）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-分桶表（Bucked-Tables）"><span class="nav-text">4.5 分桶表（Bucked Tables）</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2019 &mdash; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qypx</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  


  

  



<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left"},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
